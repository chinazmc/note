# ES 写入优化记录，从3000/s到8000/s
#### 背景  

- 基于[elasticsearch](https://so.csdn.net/so/search?q=elasticsearch&spm=1001.2101.3001.7020)-5.6.0
- 机器配置：3个云[ecs](https://so.csdn.net/so/search?q=ecs&spm=1001.2101.3001.7020)节点，16G,4核，机械硬盘

优化前，写入速度平均`3000条/s`，一遇到压测，写入速度骤降，甚至es直接频率gc、oom等；优化后，写入速度平均`8000条/s`，遇到压测，能在压测结束后30分钟内消化完数据，各项指标回归正常。

#### 生产配置

这里我先把自己优化的结果贴出来，后面有参数的详解：

[elasticsearch.yml中增加如下设置](https://blog.csdn.net/youanyyou/article/details/124743194)

```yml
indices.memory.index_buffer_size: 20% 
indices.memory.min_index_buffer_size: 96mb 
# Search pool 
thread_pool.search.size: 5 
thread_pool.search.queue_size: 100 
# 这个参数慎用！强制修改cpu核数，以突破写线程数限制 
# processors: 16 
# Bulk pool 
#thread_pool.bulk.size: 16 
thread_pool.bulk.queue_size: 300 
# Index pool 
#thread_pool.index.size: 16 
thread_pool.index.queue_size: 300 
indices.fielddata.cache.size: 40% 
discovery.zen.fd.ping_timeout: 120s 
discovery.zen.fd.ping_retries: 6 
discovery.zen.fd.ping_interval: 30s
```

[索引优化配置：](https://blog.csdn.net/youanyyou/article/details/124743194)

```curl
PUT /_template/elk
{      
	"order": 6,      
	"template": "logstash-*",    #这里配置模板匹配的Index名称      
	"settings": {        
		"number_of_replicas" : 0,    #副本数为0,需要查询性能高可以设置为1        
		"number_of_shards" :   6,    #分片数为6, 副本为1时可以设置成5         
		"refresh_interval": "30s",         
		"index.translog.durability": "async",        
		"index.translog.sync_interval": "30s"       
	}
}
```

#### 优化参数详解

**精细设置全文域：** string类型字段默认会分词，不仅会额外占用资源，而且会影响创建索引的速度。所以，把不需要分词的字段设置为`not_analyzed`

**禁用_all字段:** 对于日志和apm数据，目前没有场景会使用到

**副本数量设置为0:** 因为我们目前日志数据和apm数据在es只保留最近7天的量，全量日志保存在hadoop，可以根据需要通过spark读回到es – 况且副本数量是可以随时修改的，区别分片数量

**使用es自动生成id：** es对于自动生成的id有优化，避免了版本查找。因为其生成的id是唯一的

**设置index.refresh_interval：** 索引刷新间隔，默认为1s。因为不需要如此高的实时性，我们修改为30s – 扩展学习：刷新索引到底要做什么事情

**设置段合并的线程数量：**

```go
curl -XPUT 'your-es-host:9200/nginx_log-2018-03-20/_settings' -d '
{    
	"index.merge.scheduler.max_thread_count" : 1
}'
```

段合并的计算量庞大，而且还要吃掉大量磁盘I/O。合并在后台定期操作，因为他们可能要很长时间才能完成，尤其是比较大的段。

机械磁盘在并发I/O支持方面比较差，所以我们需要降低每个索引并发访问磁盘的线程数。这个设置允许`max_thread_count + 2`个线程同时进行磁盘操作，也就是设置为1允许三个线程

1.设置异步刷盘事务日志文件：

```go
"index.translog.durability": "async",
"index.translog.sync_interval": "30s"
```

对于日志场景，能够接受部分数据丢失。同时有全量可靠日志存储在hadoop，丢失了也可以从hadoop恢复回来

2.elasticsearch.yml中增加如下设置：

```go
indices.memory.index_buffer_size: 20%
indices.memory.min_index_buffer_size: 96mb
```

已经索引好的文档会先存放在内存缓存中，等待被写到到段(segment)中。缓存满的时候会触发段刷盘(吃i/o和cpu的操作)。默认最小缓存大小为48m，不太够，最大为堆内存的10%。对于大量写入的场景也显得有点小。

> 扩展学习：数据写入流程是怎么样的(具体到如何构建索引)？

1.设置index、merge、bulk、search的线程数和队列数。例如以下elasticsearch.yml设置：

```go
# Search pool
thread_pool.search.size: 5
thread_pool.search.queue_size: 100
# 这个参数慎用！强制修改cpu核数，以突破写线程数限制
# processors: 16
# Bulk pool
thread_pool.bulk.size: 16
thread_pool.bulk.queue_size: 300
# Index pool
thread_pool.index.size: 16
thread_pool.index.queue_size: 300
```

2.设置filedata cache大小，例如以下elasticsearch.yml配置：

```go
indices.fielddata.cache.size: 15%
```

filedata cache的使用场景是一些聚合操作(包括排序),构建filedata cache是个相对昂贵的操作。所以尽量能让他保留在内存中

然后日志场景聚合操作比较少，绝大多数也集中在半夜，所以限制了这个值的大小，默认是不受限制的，很可能占用过多的堆内存

> 扩展学习：什么是filedata？构建流程是怎样的？为什么要用filedata？（what、how、why）

1.设置节点之间的故障检测配置，例如以下elasticsearch.yml配置：

```go
discovery.zen.fd.ping_timeout: 120s
discovery.zen.fd.ping_retries: 6
discovery.zen.fd.ping_interval: 30s
```

大数量写入的场景，会占用大量的网络带宽，很可能使节点之间的心跳超时。并且默认的心跳间隔也相对过于频繁（1s检测一次）

此项配置将大大缓解节点间的超时问题。
# [Hbase为什么写比读快](https://www.cnblogs.com/guoyu1/p/13934002.html)
## **为何HBase速度很快？**

HBase能提供实时计算服务主要原因是由其架构和底层的数据结构决定的， 即由LSM-Tree(Log-Structured Merge-Tree) + HTable(region分区) + Cache决定——客户端可以直接定位到要查数据所在的HRegion server服务器，然后直接在服务器的一个region上查找要匹配的数据，并且这些数据部分是经过cache缓存的。

前面说过HBase会将数据保存到内存中，在内存中的数据是有序的，如果内存空间满了，会刷写到HFile中，而在HFile中保存的内容也是有序的。当数据写入HFile后，内存中的数据会被丢弃。

HFile文件为磁盘顺序读取做了优化，按页存储。下图展示了在内存中多个块存储并归并到磁盘的过程，合并写入会产生新的结果块，最终多个块被合并为更大块。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190103224413150.png)

多次刷写后会产生很多小文件，后台线程会合并小文件组成大文件，这样磁盘查找会限制在少数几个数据存储文件中。HBase的写入速度快是因为它其实并不是真的立即写入文件中，而是先写入内存，随后异步刷入HFile。所以在客户端看来，写入速度很快。另外，写入时候将随机写入转换成顺序写，数据写入速度也很稳定。

而读取速度快是因为它使用了 **LSM树型结构**，而不是B或B+树。磁盘的顺序读取速度很快，但是相比而言，寻找磁道的速度就要慢很多。HBase的存储结构导致它需要磁盘寻道时间在可预测范围内，并且读取与所要查询的rowkey连续的任意数量的记录都不会引发额外的寻道开销。比如有5个存储文件，那么最多需要5次磁盘寻道就可以。而关系型数据库，即使有索引，也无法确定磁盘寻道次数。而且，HBase读取首先会在 **缓存（BlockCache）中查找**，它采用了 **LRU（最近最少使用算法）**，如果缓存中没找到，会从内存中的MemStore中查找，只有这两个地方都找不到时，才会加载HFile中的内容，而上文也提到了读取HFile速度也会很快，因为节省了寻道开销。

什么是LSM树呢？[B树、B+树、LSM树以及其典型应用场景_惜暮-CSDN博客_lsm树和b+树](https://blog.csdn.net/u010853261/article/details/78217823 "B树、B+树、LSM树以及其典型应用场景_惜暮-CSDN博客_lsm树和b+树")  
什么是LRU？[LruCache算法（最近最少使用算法）_赵雷-CSDN博客](https://blog.csdn.net/qq_39238370/article/details/78067066 "LruCache算法（最近最少使用算法）_赵雷-CSDN博客")  
[LRU最近最少使用算法 - YoZane - 博客园](https://www.cnblogs.com/yuanzhenliu/p/5659397.html "LRU最近最少使用算法 - YoZane - 博客园")  
可以去了解一下

**举例：**

A：如果快速查询（从磁盘读数据），hbase是根据rowkey查询的，只要能快速的定位rowkey, 就能实现快速的查询，主要是以下因素：  
1、hbase是可划分成多个region，你可以简单的理解为关系型数据库的多个分区。  
2、键是排好序了的  
3、按列存储的

首先，能快速找到行所在的region(分区)，假设表有10亿条记录，占空间1TB, 分列成了500个region, 1个region占2个G. 最多读取2G的记录，就能找到对应记录；

其次，是按列存储的，其实是列族，假设分为3个列族，每个列族就是666M， 如果要查询的东西在其中1个列族上，1个列族包含1个或者多个HStoreFile，假设一个HStoreFile是128M， 该列族包含5个HStoreFile在磁盘上. 剩下的在内存中。

再次，是排好序了的，你要的记录有可能在最前面，也有可能在最后面，假设在中间，我们只需遍历2.5个HStoreFile共300M

最后，每个HStoreFile(HFile的封装)，是以键值对（key-value）方式存储，只要遍历一个个数据块中的key的位置，并判断符合条件可以了。 一般key是有限的长度，假设跟value是1:19（忽略HFile上其它块），最终只需要15M就可获取的对应的记录，按照磁盘的访问100M/S，只需0.15秒。 加上块缓存机制（LRU原则），会取得更高的效率。

B：实时查询  
实时查询，可以认为是从内存中查询，一般响应时间在1秒内。HBase的机制是数据先写入到内存中，当数据量达到一定的量（如128M），再写入磁盘中， 在内存中，是不进行数据的更新或合并操作的，只增加数据，这使得用户的写操作只要进入内存中就可以立即返回，保证了HBase I/O的高性能。

```prettyprint
<span style="color:#000000"><span style="background-color:#282c34"><code> 实时查询，即反应根据当前时间的数据，可以认为这些数据始终是在内存的，保证了数据的实时响应。</code></span></span>
```

# HBase最佳实践－写性能优化策略

 [2016年12月10日](http://hbasefly.com/2016/12/10/hbase-parctice-write/)  [范欣欣](http://hbasefly.com/author/libisthanksgmail-com/)  [HBase](http://hbasefly.com/category/hbase/)

上一篇文章主要介绍了HBase读性能优化的基本套路，本篇文章来说道说道如何诊断HBase写数据的异常问题以及优化写性能。和读相比，HBase写数据流程倒是显得很简单：数据先顺序写入HLog，再写入对应的缓存Memstore，当Memstore中数据大小达到一定阈值（128M）之后，系统会异步将Memstore中数据flush到HDFS形成小文件。

HBase数据写入通常会遇到两类问题，一类是写性能较差，另一类是数据根本写不进去。这两类问题的切入点也不尽相同，如下图所示：
![[Pasted image 20240110154135.png]]
### **写性能优化切入点**  

#### **1. 是否需要写WAL？WAL是否需要同步写入？**  

优化原理：数据写入流程可以理解为一次顺序写WAL+一次写缓存，通常情况下写缓存延迟很低，因此提升写性能就只能从WAL入手。WAL机制一方面是为了确保数据即使写入缓存丢失也可以恢复，另一方面是为了集群之间异步复制。默认WAL机制开启且使用同步机制写入WAL。首先考虑业务是否需要写WAL，通常情况下大多数业务都会开启WAL机制（默认），但是对于部分业务可能并不特别关心异常情况下部分数据的丢失，而更关心数据写入吞吐量，比如某些推荐业务，这类业务即使丢失一部分用户行为数据可能对推荐结果并不构成很大影响，但是对于写入吞吐量要求很高，不能造成数据队列阻塞。这种场景下可以考虑关闭WAL写入，写入吞吐量可以提升2x~3x。退而求其次，有些业务不能接受不写WAL，但可以接受WAL异步写入，也是可以考虑优化的，通常也会带来1x～2x的性能提升。

优化推荐：根据业务关注点在WAL机制与写入吞吐量之间做出选择

其他注意点：对于使用Increment操作的业务，WAL可以设置关闭，也可以设置异步写入，方法同Put类似。相信大多数Increment操作业务对WAL可能都不是那么敏感～

#### **2. Put是否可以同步批量提交？**  

优化原理：HBase分别提供了单条put以及批量put的API接口，使用批量put接口可以减少客户端到RegionServer之间的RPC连接数，提高写入性能。另外需要注意的是，批量put请求要么全部成功返回，要么抛出异常。

优化建议：使用批量put进行写入请求

#### **3. Put是否可以异步批量提交？**  

优化原理：业务如果可以接受异常情况下少量数据丢失的话，还可以使用异步批量提交的方式提交请求。提交分为两阶段执行：用户提交写请求之后，数据会写入客户端缓存，并返回用户写入成功；当客户端缓存达到阈值（默认2M）之后批量提交给RegionServer。需要注意的是，在某些情况下客户端异常的情况下缓存数据有可能丢失。

优化建议：在业务可以接受的情况下开启异步批量提交

使用方式：setAutoFlush(false)

#### **4. Region是否太少？**  

优化原理：当前集群中表的Region个数如果小于RegionServer个数，即Num(Region of Table) < Num(RegionServer)，可以考虑切分Region并尽可能分布到不同RegionServer来提高系统请求并发度，如果Num(Region of Table) > Num(RegionServer)，再增加Region个数效果并不明显。

优化建议：在Num(Region of Table) < Num(RegionServer)的场景下切分部分请求负载高的Region并迁移到其他RegionServer；

#### **5. 写入请求是否不均衡？**  

优化原理：另一个需要考虑的问题是写入请求是否均衡，如果不均衡，一方面会导致系统并发度较低，另一方面也有可能造成部分节点负载很高，进而影响其他业务。分布式系统中特别害怕一个节点负载很高的情况，一个节点负载很高可能会拖慢整个集群，这是因为很多业务会使用Mutli批量提交读写请求，一旦其中一部分请求落到该节点无法得到及时响应，就会导致整个批量请求超时。因此不怕节点宕掉，就怕节点奄奄一息！

优化建议：检查RowKey设计以及预分区策略，保证写入请求均衡。

#### **6. 写入KeyValue数据是否太大？**  

KeyValue大小对写入性能的影响巨大，一旦遇到写入性能比较差的情况，需要考虑是否由于写入KeyValue数据太大导致。KeyValue大小对写入性能影响曲线图如下：
![[Pasted image 20240110154855.png]]
图中横坐标是写入的一行数据（每行数据10列）大小，左纵坐标是写入吞吐量，右坐标是写入平均延迟（ms）。可以看出随着单行数据大小不断变大，写入吞吐量急剧下降，写入延迟在100K之后急剧增大。

说到这里，有必要和大家分享两起在生产线环境因为业务KeyValue较大导致的严重问题，一起是因为大字段业务写入导致其他业务吞吐量急剧下降，另一起是因为大字段业务scan导致RegionServer宕机。

**案件一：大字段写入导致其他业务吞吐量急剧下降**

部分业务反馈集群写入忽然变慢、数据开始堆积的情况，查看集群表级别的数据读写QPS监控，发现问题的第一个关键点：业务A开始写入之后整个集群其他部分业务写入QPS都几乎断崖式下跌，初步怀疑黑手就是业务A。

下图是当时业务A的写入QPS（事后发现脑残忘了截取其他表QPS断崖式下跌的惨象），但是第一感觉是QPS并不高啊，凭什么去影响别人！
![[Pasted image 20240110155052.png]]
于是就继续查看其他监控信息，首先确认系统资源（主要是IO）并没有到达瓶颈，其次确认了写入的均衡性，直至看到下图，才追踪到影响其他业务写入的第二个关键点：RegionServer的handler（配置150）被残暴耗尽：
![[Pasted image 20240110155118.png]]
对比上面两张图，是不是发现出奇的一致，那就可以基本确认是由于该业务写入导致这台RegionServer的handler被耗尽，进而其他业务拿不到handler，自然写不进去。那问题来了，为什么会这样？正常情况下handler在处理完客户端请求之后会立马释放，唯一的解释是这些请求的延迟实在太大。

试想，我们去汉堡店排队买汉堡，有150个窗口服务，正常情况下大家买一个很快，这样150个窗口可能只需要50个服务。假设忽然来了一批大汉，要定制超大汉堡，好了，所有的窗口都工作起来，而且因为大汉堡不好制作导致服务很慢，这样必然会导致其他排队的用户长时间等待，直至超时。

可回头一想这可是写请求啊，怎么会有这么大的请求延迟！和业务方沟通之后确认该表主要存储语料库文档信息，都是平均100K左右的数据，是不是已经猜到了结果，没错，就是因为这个业务KeyValue太大导致。KeyValue太大会导致HLog文件写入频繁切换、flush以及compaction频繁触发，写入性能急剧下降。

目前针对这种较大KeyValue写入性能较差的问题还没有直接的解决方案，好在社区已经意识到这个问题，在接下来即将发布的下一个大版本HBase 2.0.0版本会针对该问题进行深入优化，详见[HBase MOB](https://issues.apache.org/jira/browse/HBASE-11339)，优化后用户使用HBase存储文档、图片等二进制数据都会有极佳的性能体验。

**案件二：大字段scan导致RegionServer宕机**

案件现场：有段时间有个0.98集群的RegionServer经常频繁宕机，查看日志是由于”java.lang.OutOfMemoryError: Requested array size exceeds VM limit”

原因分析：通过查看源码以及相关文档，确认该异常发生在scan结果数据回传给客户端时由于数据量太大导致申请的array大小超过JVM规定的最大值（ Interge.Max_Value-2）。造成该异常的两种最常见原因分别是：

- 表列太宽（几十万列或者上百万列），并且scan返回没有对列数量做任何限制，导致一行数据就可能因为包含大量列而数据超过array大小阈值
- KeyValue太大，并且scan返回没有对返回结果大小做任何限制，导致返回数据结果大小超过array大小阈值

有的童鞋就要提问啦，说如果已经对返回结果大小做了限制，在表列太宽的情况下是不是就可以不对列数量做限制呢。这里需要澄清一下，如果不对列数据做限制，数据总是一行一行返回的，即使一行数据大小大于设置的返回结果限制大小，也会返回完整的一行数据。在这种情况下，如果这一行数据已经超过array大小阈值，也会触发OOM异常。

解决方案：目前针对该异常有两种解决方案，其一是升级集群到1.0，问题都解决了。其二是要求客户端访问的时候对返回结果大小做限制(scan.setMaxResultSize(2*1024*1024))、并且对列数量做限制(scan.setBatch(100))，当然，0.98.13版本以后也可以对返回结果大小在服务器端进行限制，设置参数hbase.server.scanner.max.result.size即可

### **写异常问题检查点**  

上述几点主要针对写性能优化进行了介绍，除此之外，在一些情况下还会出现写异常，一旦发生需要考虑下面两种情况（GC引起的不做介绍）：

#### **Memstore设置是否会触发Region级别或者RegionServer级别flush操作？**  

问题解析：以RegionServer级别flush进行解析，HBase设定一旦整个RegionServer上所有Memstore占用内存大小总和大于配置文件中upperlimit时，系统就会执行RegionServer级别flush，flush算法会首先按照Region大小进行排序，再按照该顺序依次进行flush，直至总Memstore大小低至lowerlimit。这种flush通常会block较长时间，在日志中会发现“Memstore is above high water mark and block 7452 ms”，表示这次flush将会阻塞7s左右。

问题检查点：

- Region规模与Memstore总大小设置是否合理？如果RegionServer上Region较多，而Memstore总大小设置的很小（JVM设置较小或者upper.limit设置较小），就会触发RegionServer级别flush。集群规划相关内容可以参考文章《[HBase最佳实践－集群规划](http://hbasefly.com/2016/08/22/hbase-practise-cluster-planning/)》

- 列族是否设置过多，通常情况下表列族建议设置在1～3个之间，最好一个。如果设置过多，会导致一个Region中包含很多Memstore，导致更容易触到高水位upperlimit

#### **Store中HFile数量是否大于配置参数blockingStoreFile?**  

问题解析：对于数据写入很快的集群，还需要特别关注一个参数：hbase.hstore.blockingStoreFiles，此参数表示如果当前hstore中文件数大于该值，系统将会强制执行compaction操作进行文件合并，合并的过程会阻塞整个hstore的写入。通常情况下该场景发生在数据写入很快的情况下，在日志中可以发现”Waited 3722ms on a compaction to clean up ‘too many store  files“

问题检查点：

- 参数设置是否合理？hbase.hstore.compactionThreshold表示启动compaction的最低阈值，该值不能太大，否则会积累太多文件，一般建议设置为5～8左右。hbase.hstore.blockingStoreFiles默认设置为7，可以适当调大一些。

### **写性能还能再提高么？**  

上文已经从写性能优化以及写异常诊断两个方面对HBase中数据写入可能的问题进行了详细的解释，相信在0.98版本的基础上对写入来说已经是最好的解决方案了。但是有些业务可能依然觉得不够快，毕竟”更快”是所有存储系统活着的动力，那还有提高空间吗？当然，接下来简单介绍HBase之后版本对写性能优化的两点核心改进：

####  **Utilize Flash storage for WAL(HBASE-12848)**

这个特性意味着可以将WAL单独置于SSD上，这样即使在默认情况下（WALSync），写性能也会有很大的提升。需要注意的是，该特性建立在HDFS 2.6.0+的基础上，HDFS以前版本不支持该特性。具体可以参考官方jira：[https://issues.apache.org/jira/browse/HBASE-12848](https://issues.apache.org/jira/browse/HBASE-12848)

#### **Multiple WALs(HBASE-14457)**

该特性也是对WAL进行改造，当前WAL设计为一个RegionServer上所有Region共享一个WAL，可以想象在写入吞吐量较高的时候必然存在资源竞争，降低整体性能。针对这个问题，社区小伙伴（阿里巴巴大神）提出Multiple WALs机制，管理员可以为每个Namespace下的所有表设置一个共享WAL，通过这种方式，写性能大约可以提升20%～40%左右。具体可以参考官方jira：[https://issues.apache.org/jira/browse/HBASE-14457](https://issues.apache.org/jira/browse/HBASE-14457)
# [HBase读写性能优化](https://www.cnblogs.com/sx66/p/12607893.html)

一个系统上线之后，开发和调优将会一直伴随在系统的整个生命周期中，HBase也不例外。下面我们要学习如何进行HBase读写性能调优，以获取最大的读写效率。

![](https://img2020.cnblogs.com/blog/1651153/202003/1651153-20200331195458474-1679043513.png)

**HBase写入优化**  
**客户端优化**  
**批量写**  
采用批量写，可以减少客户端到RegionServer之间的RPC的次数，提高写入性能。批量写请求要么全部成功返回，要么抛出异常。

HTable.put(List&lt;Put&gt;);

  
**异步批量提交**  
如果业务可以接受异常情况下丢失少量数据，可以使用异步批量提交方式提交请求。

用户提交写请求之后，数据会先写入客户端缓存，并返回用户写入成功（此时数据并为提交到RegionServer），当客户端缓存达到阈值（默认2M，可通过hbase.client.write.buffer配置）时才会批量提交给RegionServer。需要注意的是，在某些情况下客户端异常的情况下缓存数据有可能丢失。

HTable.setWriteBufferSize(writeBufferSize); // 设置缓存大小  
HTable.setAutoFlush(false);

  
**多线程并发写**  
客户端开启多个HTable写线程，每个写线程负责一个HTable对象的flush操作，这样结合定时flush和写buffer，可以即保证在数据量小的时候，数据可以在较短时间内被flush，同时又保证在数据量大的时候，写buffer一满就即使进行flush。

**使用BulkLoad写入**  
在HBase中数据都是以HFile形式保存在HDFS中的，当有大量数据需要写入到HBase的时候，可以采用BulkLoad方式完成。

使用MapReduce或者Spark直接生成HFile格式的数据文件，然后再通过RegionServer将HFile数据文件移动到相应的Region上去。

**写数据表设计调优**  
**COMPRESSION**  
配置数据的压缩算法，这里的压缩是HFile中block级别的压缩。对于可以压缩的数据，配置压缩算法可以有效减少磁盘的IO，从而达到提高性能的目的。但是并不是所有数据都可以进行有效压缩，如图片，因为图片一般是已经压缩后的数据，所以压缩效果有限。常用的压缩算法是SNAPPY，因为它有较好的压缩和解压速度和可以接受的压缩率。

**IN_MEMORY**  
配置表的数据优先缓存在内存中，这样可以有效提升读取的性能。适合小表，而且需要频繁进行读取操作的。

**预分区**  
在HBase中数据是分布在各个Region中的，每个Region都负责一个起始RowKey和结束Rowkey的范围，在向HBase中写数据的时候，会根据RowKey请求到对应的Region上，如果写请求都集中在某一个Region或某几个Region上的时候，性能肯定不如写请求均匀分布在各个Region上好。默认情况下，创建的HBase的只有一个Region分区，会随着数据量的变大，进行split，拆分成多个Region，最开始的性能肯定会很不好

建议在设计HBase的的时候，进行预分区，并设计一个良好的Rowkey生成规则（关于RowKey设计，可以参考《一篇文章带你快速搞懂HBase RowKey设计》），尽量将数据分散到各个Region上，那样在进行HBase的读写的时候，对性能会有很好的改善。

**合理设置WAL存储级别**  
数据在写入HBase的时候，先写WAL，再写入缓存。通常情况下写缓存延迟很低，WAL机制一方面是为了确保数据即使写入缓存后数据丢失也可以通过WAL恢复，另一方面是为了集群之间的复制。默认WAL机制是开启的，并且使用的是同步机制写WAL。

如果业务不特别关心异常情况下部分数据的丢失，而更关心数据写入吞吐量，可考虑关闭WAL写，这样可以提升2~3倍数据写入的吞吐量。

如果业务不能接受不写WAL，但是可以接受WAL异步写入，这样可以带了1~2倍性能提升。

HBase中可以通过设置WAL的持久化等级决定是否开启WAL机制、以及HLog的落盘方式。

WAL的持久化等级分为如下四个等级：

1. SKIP_WAL：只写缓存，不写HLog日志。这种方式因为只写内存，因此可以极大的提升写入性能，但是数据有丢失的风险。在实际应用过程中并不建议设置此等级，除非确认不要求数据的可靠性。
2. ASYNC_WAL：异步将数据写入HLog日志中。
3. SYNC_WAL：同步将数据写入日志文件中，需要注意的是数据只是被写入文件系统中，并没有真正落盘，默认。
4. FSYNC_WAL：同步将数据写入日志文件并强制落盘。最严格的日志写入等级，可以保证数据不会丢失，但是性能相对比较差。

同样，除了在创建表的时候直接设置WAL存储级别，也可以通过客户端设置WAL持久化等级，代码：

put.setDurability(Durability.SYNC_WAL);

  
**HBase读取优化**  
**客户端优化**  
**批量get请求**  
使用批量请求，可以减少RPC的次数，显著提高吞吐量。需要注意的是，批量get请求要么成功返回所有请求数据，要么抛出异常。

Result[] re= table.get(List&lt;Get&gt; gets);

  
**合理设置scan缓存大小**  
一次scan可能会返回大量数据，但是实际客户端发起一次scan请求，并不会将所有数据一次性加载到本地，而是分成多次RPC请求进行加载，这样设计一方面是因为大量数据请求可能会导致网络带宽严重消耗进而影响其他业务，另一方面是有可能因为数据量太大导致客户端发生OOM。所以采用先加载一部分数据到本地，然后进行遍历，每次加载一部分数据，如此往复，直至所有数据加载完成。数据加载到本地就存放在scan缓存中，默认100。

增大scan的缓存，可以让客户端减少一次scan的RPC次数，从而从整体上提升数据读取的效率。

scan.setCaching(int caching); //大scan可以设置为1000

  
**指定请求列族或者列名**  
HBase是列族数据库，同一列族的数据存储在一块，不同列族是分开存储的，如果一个表由多个列族，只是根据RowKey而不指定列族进行检索的话，不同列族的数据需要独立进行检索，性能必然会比指定列族的查询差的多。

此外指定请求的列的话，不需要将整个列族的所有列的数据返回，这样就减少了网路IO。

scan.addColumn();

  
**设置只读Rowkey过滤器**  
在只需要Rowkey数据时，可以为Scan添加一个只读取Rowkey的filter（FirstKeyOnlyFilter或KeyOnlyFilter）。

**关闭ResultScanner**  
在使用table.getScanner之后，记得关闭，否则它会和服务器端一直保持连接，资源无法释放，从而导致服务端的某些资源不可用。

scanner.close();

  
**离线计算访问HBase建议禁用缓存**  
当离线访问HBase时，往往会对HBase表进行扫描，此时读取的数据没有必要存放在BlockCache中，否则会降低扫描的效率。

scan.setBlockCache(false);  
建议在对HBase表进行扫描时禁用缓存。

对于频繁查询HBase的应用场景不需要禁用缓存，并且可以考虑在应用程序和HBase之间加一层缓存系统（如Redis），先查询缓存，缓存没有命中再去查询HBase。

**读数据表设计调优**  
**COMPRESSION**  
同写性能优化COMPRESSION部分。

**BLOCKSIZE**  
配置HFile中block块的大小，不同的block大小，可以影响HBase读写数据的效率。越大的block块，配置压缩算法，压缩的效率就越好；但是由于HBase的读取数据时以block块为单位的，所以越大的block块，对于随机读的情况，性能可能会比较差，如果要提升写入的性能，一般扩大到128kb或者256kb，可以提升写数据的效率，也不会影响太大的随机读性能。

**DATA_BLOCK_ENCODING**  
配置HFile中block块的编码方法。当一行数据中存在多个列时，一般可以配置为"FAST_DIFF"，可以有效的节省数据存储的空间，从而提升性能。

**BloomFilter**  
优化原理：BloomFilter主要用来过滤不存在待检索RowKey或者Row-Col的HFile文件，避免无用的IO操作。它会告诉你在这个HFile文件中是否可能存在待检索的KeyValue，如果不存在，就可以不用小号IO打开文件进行seek。通过设置BloomFilter可以提升读写的性能。

BloomFilter是一个列族级别的配置属性，如果列族设置了BloomFilter，那么HBase会在生成StoreFile时包含一份BloomFilter的结构的数据，称为MetaBlock（一旦写入就无法更新）。MetaBlock和DataBlock（真实的KeyValue数据）一起由LRUBlockCache维护，所以开启了BloomFilter会有一定的存储即内存cache开销。

HBase利用BloomFilter可以节省必须读磁盘过程，可以提高随机读（get）的性能，但是对于顺序读（scan）而言，设置BloomFilter是没有作用的（0.92版本以后，如果设置了BloomFilter为ROWCOL，对于执行了qualifier的scan有一定的优化）

BloomFilter取值有两个，ROW和ROWCOL，需要根据业务来确定具体使用哪种。

- 如果业务大多数随机查询仅仅使用row作为查询条件，BloomFilter一定要设置为ROW。
- 如果大多数随机查询使用row+col作为查询条件，BloomFilter需要设置为ROWCOL。
- 如果不确定业务查询类型，设置为ROW。‘

**预分区**  
同写性能优化预分区部分。

**HBase服务端调优**  
**GC_OPTS**  
HBase是利用内存完成读写操作。提高HBase内存可以有效提高HBase性能。GC_OPTS主要需要调整HeapSize和NewSize的大小。调整HeapSize大小的时候，建议将Xms和Xmx设置成相同的值，这样可以避免JVM动态调整HeapSize大小的时候影响性能。调整NewSize大小的时候，建议把其设置为HeapSize大小的1/9。

当HBase集群规模越大，Region数量越多时，可以适当调大HMaster的GC_OPTS参数

RegionServer需要比HMaster更大的内存，在内存充足的情况下，HeapSize可以相对设置大一些。

HMaster的HeapSize为4G的时候，HBase集群可以支持100000个Region的规模。根据经验值，单个RegionServer的HeapSize不建议超过20GB。

1. # HMaster、RegionServer GC_OPTS配置如下：
2. HMaster: -Xms2G -Xmx2G -XX:NewSize=256M -XX:MaxNewSize=256M
3. RegionServer: -Xms4G -Xmx4G -XX:NewSize=512M -XX:MaxNewSize=512M

**RegionServer并发请求处理数量**  
hbase.regionserver.handler.count表示RegionServer在同一时刻能够并发处理多少请求。如果设置过高会导致激烈的线程竞争，如果设置过小，请求将会在RegionServer长时间等待，降低处理能力。应该根据资源情况，适当增加处理线程数。

_建议根据CPU的使用情况，可以设置为100至300之间的值。_

**控制MemStore的大小**  
hbase.hregion.memstore.flush.size默认值128M，单位字节，一旦有MemStore超过该值将被flush，如果regionserver的jvm内存比较充足(16G以上)，可以调整为256M。在内存足够put负载大情况下可以调整增大。

**BlockCache优化**  
BlockCache作为读缓存，合理设置对于提高读性能非常重要。默认情况下，BlockCache和MemStore的配置各占40%，可以根据集群业务进行修正，比如读多写少业务可以将BlockCache占比调大。另外BlockCache的策略也很重要，不同策略对读性能来说影响并不大，但是对GC的影响 却很显著。

HBase缓存区大小，主要影响查询性能。根据查询模式以及查询记录分布情况来决定缓存区的大小。如果采用随机查询使得缓存区的命中率较低，可以适当降低缓存大小。

1. hfile.block.cache.size，默认0.4，用来提高读性能
2. hbase.regionserver.global.memstore.size，默认0.4，用来提高写性能

**控制HFile个数**  
MemStore在flush之前，会进行StoreFile的文件数量校验（通过hbase.hstore.blockingStoreFiles参数配置），如果大于设定值，系统将会强制执行Compaction操作进行文件合并，在合并的过程中会阻塞MemStore的数据写入，等待其他线程将StoreFile进行合并。通常情况下发生在数据写入很快的情况下。

hbase.hstore.compactionThreshold表示启动Compaction的最低阈值，该值不能太大，否则会积累太多文件，一般建议设置为5～8左右。

hbase.hstore.blockingStoreFiles默认设置为7，可以适当调大一些。

**Split优化**  
hbase.hregion.max.filesize表示HBase中Region的文件总大小的最大值。当Region中的文件大于该参数时，将会导致Region分裂。

- 如果该参数设置过小时，可能会导致Split操作频繁
- 如果该参数设置过大时，会导致Compaction操作需要处理的文件个数增大，影响Compaction执行效率

**Compaction优化**  
hbase.hstore.compaction.min当一个Store中文件超过该值时，会进行Compaction，适当增大该值，可以减少文件被重复执行Compaction。但是如果过大，会导致Store中文件数过多而影响读取的性能。

hbase.hstore.compaction.max控制一次Compaction操作时的文件数据量的最大值。

hbase.hstore.compaction.max.size如果一个HFile文件的大小大于该值，那么在Minor Compaction操作中不会选择这个文件进行Compaction操作，除非进行Major Compaction操作。这个值可以防止较大的HFile参与Compaction操作。在禁止Major Compaction后，一个Store中可能存在几个HFile，而不会合并成为一个HFile，这样不会对数据读取造成太大的性能影响。

_原则是：尽量要减小Compaction的次数和Compaction的执行时间_

**总结**  
在HBase使用过程中，要想获取好的读写性能，可以从以下几个方面进行优化：
# Reference
http://hbasefly.com/2016/12/10/hbase-parctice-write/
https://www.cnblogs.com/sx66/p/12607893.html
https://cloud.tencent.com/developer/article/2009495
https://www.cnblogs.com/guoyu1/p/13934002.html