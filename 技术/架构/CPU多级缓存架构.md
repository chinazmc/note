
**1、基本概念**

> 现代CPU为了提升执行效率，减少CPU与内存的交互(交互影响CPU效率)，一般在CPU上集成了多级缓存架构，常见的为三级缓存结构。于是当从内存中读取数据时，并不是只读自己想要的部分。而是读取足够的字节来填入高速缓存行。根据不同的 CPU ，高速缓存行大小不同。如 X86 是 32BYTES ，而 ALPHA 是 64BYTES 。并且始终在第 32 个字节或第 64 个字节处对齐。这样，当 CPU 访问相邻的数据时，就不必每次都从内存中读取，提高了速度。 因为访问内存要比访问高速缓存用的时间多得多。

**1.1、总线**

前端总线（FSB）就是负责将CPU连接到内存的一座桥，前端总线频率则直接影响CPU与内存数据交换速度，如果FSB频率越高，说明这座桥越宽，可以同时通过的车辆越多，这样CPU处理的速度就更快。目前PC机上CPU前端总线频率有533MHz、800MHz、1066MHz、1333MHz、1600MHz等几种，前端总线频率越高，CPU与内存之间的数据传输量越大。  
前端总线——Front Side Bus（FSB），是将CPU连接到北桥芯片的总线。选购主板和CPU时，要注意两者搭配问题，一般来说，前端总线是由CPU决定的，如果主板不支持CPU所需要的前端总线，系统就无法工作。

**1.2、频率与降频**

只支持1333内存频率的cpu和主板配1600内存条就会降频。核心数跟ddr2和ddr3没关系，核心数是cpu本身的性质，cpu是四核的就是四核的，是双核的就是双核的。如果cpu只支持1333，而主板支持1600，那也会降频；cpu支持1600而主板只支持1333那不仅内存会降频，而且发挥不出cpu全部性能。  
另外如果是较新的主板cpu，已经采用新的qpi总线，而不是以前的fsb总线。以前的fsb总线一般是总线为多少就支持多高的内存频率。而qpi总线的cpu集成了内存控制器，5.0gt/s的cpu可能只支持1333内存频率，但是总线带宽相当于1333内存的内存带宽的两倍，这时候，组成1333双通道，内存速度就会翻倍，相当于2666的内存频率。

**1.3、cache line**

Cache Line可以简单的理解为CPU Cache中的最小缓存单位。目前主流的CPU Cache的Cache Line大小都是64Bytes。假设我们有一个512字节的一级缓存，那么按照64B的缓存单位大小来算，这个一级缓存所能存放的缓存个数就是512/64 = 8个。

**2、CPU多级缓存架构**

  

![](https://pic4.zhimg.com/80/v2-d7d831f9b4fb63707c456fe72b4f7f33_720w.webp)

  

- L1 Cache，分为数据缓存和指令缓存，逻辑核独占
    
- L2 Cache，物理核独占，逻辑核共享
    
- L3 Cache，所有物理核共享
    

级别越小的缓存，越接近CPU， 意味着速度越快且容量越少。

- 存储器存储空间大小：内存>L3>L2>L1>寄存器；
    
- 存储器速度快慢排序：寄存器>L1>L2>L3>内存；
    

> L1是最接近CPU的，它容量最小，速度最快，每个核上都有一个L1 Cache(准确地说每个核上有两个L1 Cache， 一个存数据 L1d Cache， 一个存指令 L1i Cache)；
> 
> L2 Cache 更大一些，例如256K，速度要慢一些，一般情况下每个核上都有一个独立的L2 Cache；二级缓存就是一级缓存的缓冲器：一级缓存制造成本很高因此它的容量有限，二级缓存的作用就是存储那些CPU处理时需要用到、一级缓存又无法存储的数据。
> 
> L3 Cache是三级缓存中最大的一级，例如12MB，同时也是最慢的一级，在同一个CPU插槽之间的核共享一个L3 Cache。三级缓存和内存可以看作是二级缓存的缓冲器，它们的容量递增，但单位制造成本却递减。
> 
> 当CPU运作时，它首先去L1寻找它所需要的数据，然后去L2，然后去L3。如果三级缓存都没找到它需要的数据，则从内存里获取数据。寻找的路径越长，耗时越长。所以如果要非常频繁的获取某些数据，保证这些数据在L1缓存里。这样速度将非常快。下表表示了CPU到各缓存和内存之间的大概速度：

![](https://pic4.zhimg.com/80/v2-24089a982010de0c0abd33e14e9cd05f_720w.webp)

**3、多核CPU多级缓存一致性协议MESI**

1. CPU1 读取了一个字节，以及它和它相邻的字节被读入 CPU1 的高速缓存。
    
2. CPU2 做了上面同样的工作。这样 CPU1 ， CPU2 的高速缓存拥有同样的数据。
    
3. CPU1 修改了那个字节，被修改后，那个字节被放回 CPU1 的高速缓存行。但是该信息并没有被写入 RAM 。
    
4. CPU2 访问该字节，但由于 CPU1 并未将数据写入 RAM ，导致了数据不同步。
    

为了解决这个问题，芯片设计者制定了一个规则。当一个 CPU 修改高速缓存行中的字节时，计算机中的其它 CPU 会被通知，它们的高速缓存将视为无效。于是，在上面的情况下， CPU2 发现自己的高速缓存中数据已无效， CPU1 将立即把自己的数据写回 RAM ，然后 CPU2 重新读取该数据。 可以看出，高速缓存行在多处理器上会导致一些不利。

多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。

MESI 是指4中状态的首字母。每个Cache line有4个状态，可用2个bit表示，它们分别是：

```text
缓存行（Cache line）:缓存存储数据的单元，一般为64Byte。
```

![](https://pic1.zhimg.com/80/v2-e69746e86cbc9b37f2ffe3988c680730_720w.webp)

注意： 对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的，而S状态可能是非一致的。如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其它缓存不会广播他们作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行。

从上面的意义看来E状态是一种投机性的优化：如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务。

**3.2、MESI状态转换**

  

![](https://pic1.zhimg.com/80/v2-6343e9fc33d81de22147e6c04892d588_720w.webp)

1.触发事件

触发事件描述本地读取（Local read）本地cache读取本地cache数据本地写入（Local write）本地cache写入本地cache数据远端读取（Remote read）其他cache读取本地cache数据远端写入（Remote write）其他cache写入本地cache数据

2.cache分类：  
前提：所有的cache共同缓存了主内存中的某一条数据。

本地cache:指当前cpu的cache。  
触发cache:触发读写事件的cache。  
其他cache:指既除了以上两种之外的cache。  
注意：本地的事件触发 本地cache和触发cache为相同。

![](https://pic1.zhimg.com/80/v2-edfa35feb821029a1d0eabd76a885f60_720w.webp)

下图示意了，当一个cache line的调整的状态的时候，另外一个cache line 需要调整的状态。

![](https://pic3.zhimg.com/80/v2-539b9b4dff0616d37fb1b999cfad8496_720w.webp)

  

**3.3、多核缓存协同操作**

假设有三个CPU A、B、C，对应三个缓存分别是cache a、b、 c。在主内存中定义了x的引用值为0。

![](https://pic3.zhimg.com/80/v2-66fa80f62eda5d989764cb4cc38cb38e_720w.webp)

**单核读取**

那么执行流程是：  
CPU A发出了一条指令，从主内存中读取x。  
从主内存通过bus读取到缓存中（远端读取Remote read）,这是该Cache line修改为E状态（独享）.

![](https://pic1.zhimg.com/80/v2-b0dd8175687e3e5772cfb1f0eb888f38_720w.webp)

**双核读取**

那么执行流程是：  
CPU A发出了一条指令，从主内存中读取x。  
CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。  
CPU B发出了一条指令，从主内存中读取x。  
CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。  

![](https://pic2.zhimg.com/80/v2-8d581430997d0f595b6eaeb68bbc66ad_720w.webp)

**修改数据**

那么执行流程是：  
CPU A 计算完成后发指令需要修改x.  
CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)  
CPU A 对x进行赋值。

![](https://pic2.zhimg.com/80/v2-dbe01a8bad3a8be7247ca5b1d63a1225_720w.webp)

**同步数据**

那么执行流程是：

CPU B 发出了要读取x的指令。  
CPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）  
CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）。  

![](https://pic1.zhimg.com/80/v2-8bb3505bcd4a402ef0fc023b842d3338_720w.webp)

**MESI优化和他们引入的问题**

缓存的一致性消息传递是要时间的，这就使其切换时会产生延迟。当一个缓存被切换状态时其他缓存收到消息完成各自的切换并且发出回应消息这么一长串的时间中CPU都会等待所有缓存响应完成。可能出现的阻塞都会导致各种各样的性能问题和稳定性问题。

**CPU切换状态阻塞解决-存储缓存（Store Bufferes）**

比如你需要修改本地缓存中的一条信息，那么你必须将I（无效）状态通知到其他拥有该缓存数据的CPU缓存中，并且等待确认。等待确认的过程会阻塞处理器，这会降低处理器的性能。应为这个等待远远比一个指令的执行时间长的多。

**Store Bufferes**

为了避免这种CPU运算能力的浪费，Store Bufferes被引入使用。处理器把它想要写入到主存的值写到缓存，然后继续去处理其他事情。当所有失效确认（Invalidate Acknowledge）都接收到时，数据才会最终被提交。 这么做有两个风险

Store Bufferes的风险 第一、就是处理器会尝试从存储缓存（Store buffer）中读取值，但它还没有进行提交。这个的解决方案称为Store Forwarding，它使得加载的时候，如果存储缓存中存在，则进行返回。 第二、保存什么时候会完成，这个并没有任何保证。

```text
value = 3；void exeToCPUA(){  value = 10;
  isFinsh = true;
}void exeToCPUB(){  if(isFinsh){    //value一定等于10？！
    assert value == 10;
  }
}
```

试想一下开始执行时，CPU A保存着finished在E(独享)状态，而value并没有保存在它的缓存中。（例如，Invalid）。在这种情况下，value会比finished更迟地抛弃存储缓存。完全有可能CPU B读取finished的值为true，而value的值不等于10。

即isFinsh的赋值在value赋值之前。

这种在可识别的行为中发生的变化称为重排序（reordings）。注意，这不意味着你的指令的位置被恶意（或者好意）地更改。

它只是意味着其他的CPU会读到跟程序中写入的顺序不一样的结果。

**3.4、硬件内存模型**

执行失效也不是一个简单的操作，它需要处理器去处理。另外，存储缓存（Store Buffers）并不是无穷大的，所以处理器有时需要等待失效确认的返回。这两个操作都会使得性能大幅降低。为了应付这种情况，引入了失效队列。它们的约定如下：

- 对于所有的收到的Invalidate请求，Invalidate Acknowlege消息必须立刻发送
    
- Invalidate并不真正执行，而是被放在一个特殊的队列中，在方便的时候才会去执行。
    
- 处理器不会发送任何消息给所处理的缓存条目，直到它处理Invalidate。 即便是这样处理器已然不知道什么时候优化是允许的，而什么时候并不允许。 干脆处理器将这个任务丢给了写代码的人。这就是内存屏障（Memory Barriers）。
    

> 写屏障 Store Memory Barrier(a.k.a. ST, SMB, smp_wmb)是一条告诉处理器在执行这之后的指令之前，应用所有已经在存储缓存（store buffer）中的保存的指令。
> 
>   
> 
> 读屏障Load Memory Barrier (a.k.a. LD, RMB, smp_rmb)是一条告诉处理器在执行任何的加载前，先应用所有已经在失效队列中的失效操作的指令。

```text
void executedOnCpu0() {    
	value = 10;    //在更新数据之前必须将所有存储缓存（store buffer）中的指令执行完毕。
    storeMemoryBarrier();
    finished = true;
}
void executedOnCpu1() {    
	while(!finished);    //在读取之前将所有失效队列中关于该数据的指令执行完毕。
    loadMemoryBarrier();
    assert value == 10;
}
```

# Reference
https://zhuanlan.zhihu.com/p/370057417