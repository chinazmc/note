# 进程线程协程
进程具有的特征：

- 动态性：进程是程序的一次执行过程，是临时的，有生命期的，是动态产生，动态消亡的；
- 并发性：任何进程都可以同其他进程一起并发执行；
- 独立性：进程是系统进行资源分配和调度的一个独立单位；
- 结构性：进程由程序、数据和进程控制块三部分组成。

线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由线程ID、当前指令指针(PC)、寄存器和堆栈组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。

在一个进程中，当一个线程任务执行几毫秒后，会由操作系统的内核（负责管理各个任务）进行调度，通过硬件的计数器中断处理器，让该线程强制暂停并将该线程的寄存器放入内存中，通过查看线程列表决定接下来执行哪一个线程，并从内存中恢复该线程的寄存器，最后恢复该线程的执行，从而去执行下一个任务。  
上述过程中，任务执行的那一小段时间叫做时间片，任务正在执行时的状态叫运行状态，被暂停的线程任务状态叫做就绪状态，意为等待下一个属于它的时间片的到来。

  这种方式保证了每个线程轮流执行，由于CPU的执行效率非常高，时间片非常短，在各个任务之间快速地切换，给人的感觉就是多个任务在“同时进行”，这也就是我们所说的并发(别觉得并发有多高深，它的实现很复杂，但它的概念很简单，就是一句话：多个任务同时执行)。

1. 线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；
2. 一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线；
3. 进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见；
4. 调度和切换：线程上下文切换比进程上下文切换要快得多。

协程，英文Coroutines，是一种基于线程之上，但又比线程更加轻量级的存在，这种由程序员自己写程序来管理的轻量级线程叫做『用户空间线程』，具有对内核来说不可见的特性。
## 协程的特点

1. 线程的切换由操作系统负责调度，协程由用户自己进行调度，因此减少了上下文切换，提高了效率。
2. 线程的默认Stack大小是1M，而协程更轻量，接近1K。因此可以在相同的内存中开启更多的协程。
3. 由于在同一个线程上，因此可以避免竞争关系而使用锁。
4. 适用于被阻塞的，且需要大量并发的场景。但不适用于大量计算的多线程，遇到此种情况，更好实用线程去解决。

  
# 计网五层的作用和对应的协议  
应用层
传输层 (tcp,udp)
网络层  (ip,arp)
数据链路层
物理层

# ping原理
ping 是基于 `ICMP` 协议工作的，所以要明白 ping 的工作，首先我们先来熟悉 **ICMP 协议**。

> ICMP 是什么？

ICMP 全称是 **Internet Control Message Protocol**，也就是**互联网控制报文协议**。

里面有个关键词 —— **控制**，如何控制的呢？

网络包在复杂的网络传输环境里，常常会遇到各种问题。当遇到问题的时候，总不能死的不明不白，没头没脑的作风不是计算机网络的风格。所以需要传出消息，报告遇到了什么问题，这样才可以调整传输策略，以此来控制整个局面。

> ICMP 功能都有啥？

`ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**

在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**。
ICMP 报文是封装在 IP 包里面，它工作在网络层，是 IP 协议的助手。


Linux 操作相关 如何查看cpu占用 top命令中idle字段的解释 如何查看端口占用 如何查看文件操作权限 ls -al 中 每行前10个字符的意思 如何更改文件权限

go 相关 介绍一下协程，协程和线程的关系 MPG模型 一个main函数内用go 开启多个协程，现在一个协程panic了，main函数会怎样？为什么？用户态和内核态
会panic



# linux怎么管理内存？扯虚拟内存格式，malloc，缺页中断，页表，换出算法（FIFO、LRU、CLOCK）等等。  
Linux管理内存的主要目标是充分利用可用的物理内存，并为每个进程提供虚拟内存空间。这样可以让进程认为它拥有连续的地址空间，并且不会相互干扰。以下是一些与Linux内存管理相关的概念和机制：

1. 虚拟内存格式： Linux使用虚拟内存格式将进程的逻辑地址空间映射到物理内存或磁盘上的交换空间。每个进程拥有其私有的虚拟地址空间，从0x00000000到0xFFFFFFFF（32位系统）或0x0000000000000000到0x00007FFFFFFFFFFF（64位系统）。虚拟内存格式由页（page）组成，通常是4KB的大小。虚拟内存空间被分为多个页，并且每个页可以映射到物理内存或磁盘上的交换空间。
    
2. malloc： `malloc` 是C/C++等编程语言中用于动态分配内存的函数。通过 `malloc` 分配的内存块位于进程的堆（heap）中，堆是进程的虚拟地址空间的一部分。
    
3. 缺页中断： 当进程访问虚拟内存中的一个页，但该页当前不在物理内存中时，就会发生缺页中断。此时，操作系统负责将该页从磁盘上的交换空间加载到物理内存中，并更新页表，然后重新执行导致缺页中断的指令。
    
4. 页表： 页表是一种数据结构，用于将进程的虚拟地址映射到物理内存地址。它记录了每个虚拟页对应的物理页的位置。当进程访问虚拟地址时，操作系统使用页表来确定对应的物理地址。
    
5. 换出算法： 当物理内存不足以容纳所有活动进程使用的页时，操作系统需要将某些页置换（换出）到磁盘上的交换空间，以便为其他页腾出空间。常见的换出算法包括FIFO（先进先出）、LRU（最近最少使用）和CLOCK（时钟）等。
    
    - FIFO：选择最早进入物理内存的页进行换出。
    - LRU：选择最近最少使用的页进行换出。
    - CLOCK：使用类似时钟的算法，将物理内存中的页组织成一个环形链表，根据页面是否被访问过来确定换出的页。

总的来说，Linux管理内存通过虚拟内存格式和页表来实现进程间的隔离，使用缺页中断和换出算法来处理物理内存不足的情况。这样可以实现更高效的内存利用，并保证每个进程有独立的地址空间。


# 11.限流有哪几种方式？我扯了阿里sentinel的令牌桶、漏斗、冷启动、自适应限流（bbr、cpu load），为什么bbr公式能做到自适应限流？当时没想明白这个问题问什么，然后说了可以根据结果来做调整。  
  
限流是一种用于控制流量的策略，可以防止系统被过多的请求或数据流量压垮，保护系统的稳定性和可靠性。除了提到的阿里Sentinel的限流方式，还有其他几种常见的限流方式：

1. 固定窗口计数限流：在固定的时间窗口内，限制请求或数据流量的数量。例如，每秒钟只允许处理10个请求。
    
2. 滑动窗口计数限流：类似于固定窗口计数限流，但是窗口的滑动是连续的，可以更精确地控制流量。
    
3. 漏桶算法（Leaky Bucket）：将请求或数据流量视为水流，用一个固定容量的桶来缓冲流量。请求到来时，先放入桶中，桶中有空闲容量时才允许处理请求；如果桶满了，则拒绝请求或进行其他处理。
    
4. 令牌桶算法（Token Bucket）：与漏桶算法类似，但是令牌桶算法以固定的速率往桶中放入令牌，每个请求需要消耗一个令牌才能被处理，如果桶中没有足够的令牌，则请求被拒绝或进行其他处理。
    
5. BBR（Bottleneck Bandwidth and Round-trip propagation time）：BBR是一种由Google开发的拥塞控制算法，它可以根据网络状况来自适应地限制发送数据的速率，以避免网络拥塞。
    

为什么BBR公式能做到自适应限流？ BBR算法之所以能实现自适应限流，是因为它基于对网络带宽和传播时延的动态估计来调整数据发送的速率。BBR算法使用反馈信息（例如，网络延迟和带宽利用率）来计算出网络的带宽容量和传播时延，并根据这些信息动态地调整数据的发送速率。

BBR算法的公式中包含了对网络带宽的估计，以及对网络传播时延的测量。通过实时收集和计算这些指标，BBR可以根据网络状况来调整数据发送的速率，从而达到自适应限流的效果。这使得BBR算法可以根据网络的实际情况，动态地控制流量，提高网络性能并减少拥塞的可能性。


问：stack里面保存什么？  
答：method栈帧，pc，局部变量。  
问：局部变量是什么？应该不会保存在stack里面吧？  
答：java分配对象内存是在堆里面的，你可以理解为一个指针。  
问：协程怎么停顿？  
答：抛异常造成suspend，保存现场。  
问：协程为什么高效？  
答：避免内核中线程的上下文切换、协程数据更轻量。  
问：还有吗？等了一会我没思路，然后面试官自己说了其实还有一个，线程是可以随时发生上下文切换的，而协程是需要在固定位置显式切换的，所以保存上下文更轻量。  
答：哦哦哦，对，没想到。  
  
2.用户访问A服务，A服务需要调用B服务，但是B服务的处理耗时在不断上涨，问A服务的关键指标（cpu、io、mem等）会怎么变化？  
听到问题后，我直接原地爆炸，头皮发麻，只能用dubbo的思维去硬扯，其实没太分析出来，可能分析出来5 6成吧，尴尬。  
面试官继续问：你都是分析同步调用，那异步调用呢？  
更爆炸了，当时陷入了java rpc线程的思路死循环中，异步调用不是一样吗？除非说A服务需要同时调用B C服务，可以用异步同时调用B C服务再get来达到并发调用的效果，但是指标应该是一样的？  
然后我扯了一句，太细了，打了句哈哈，我们线上遇到这样的问题都是直接扩容解决的。面试官反问为什么扩容能解决，然后我说了句处理固定数量qps的请求，如果多个应用一起扛的话，每个应用能够均摊，如果B服务也能顶住的话，其实可以不被B服务影响吞吐量。  
其实后面细想，面试官真的是在问这个吗？协程协程，抓住协程跟线程的区别，这题就迎刃而解了，为什么协程高效？因为完全异步调用时协程能够接受在调用处停顿啊，线程做不到。其实问题是承上启下的，当时没get到他的点，太可惜了。  
  

# 什么是平衡二叉树
可以是空树
假如不是空树，任何一个结点的左子树和右子树都是平衡二叉树，且高度之差小于等于1

# set的使用场景 有序set的使用场景

有序且去重的场景

1、 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。

2、用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。

## 反射 反射的弊端

**优点：**运行期类型的判断，动态类加载，动态代理使用反射。

**缺点：**性能是一个问题，反射相当于一系列解释操作，通知jvm要做的事情，性能比直接的java代码要慢很多。

## 进程调度算法

先来先服务 时间片轮转算法 短作业优先 最短剩余时间 高响应比 优先级

## 进程间怎么通信

管道 有名管道 套接字 **消息队列** 信号量

## 线程间通信

主要分为共享内存和消息传递

volatile关键字 wait/notify机制

## 事务隔离级别
 
隔离级别 脏读（Dirty Read） 不可重复读 幻读（Phantom Read）

未提交读（Read uncommitted） 可能 可能 可能

已提交读（Read committed） 不可能 可能 可能

可重复读（Repeatable read） 不可能 不可能 可能

可串行化（Serializable ） 不可能 不可能 不可能

## MyISAM和InnoDB差别

MyISAM不支持事务，InnoDB支持。MyISAM不支持行锁，只支持表锁，InnoDB支持行锁。

InnoDB没有保存具体的行数，所以在统计行数的时候回扫描全表，MyISAM有保存。

myisam的索引以表名+.MYI文件分别保存。innodb的索引和数据一起保存在表空间里。

## LINUX kill命令

**在Linux/unix下，中止一个Java进程有两种方式，一种是kill -9 pid，一种是kill -15 pill（默认）。**

SIGNKILL（9） 的效果是立即杀死进程. 该信号**不能被阻塞, 处理和忽略**。

SIGNTERM（15） 的效果是**正常退出进程**，退出前可以被**阻塞或回调处理**。并且它是Linux**缺省**的程序中断信号(默认是15)。

## TCP四次挥手的TIME_WAIT

在第三次挥手的时候，服务端发FIN给客户端，然后客户端再发ACK命令给客户端，然后进入TIME_WAIT状态，2MSL之后，进入CLOSED状态，**从客户端的角度来说，第四次挥手是为了告诉服务端，我收到了你的FIN信号，一切正常，等待2MSL是为了确保服务端收到了ACK，如果因为网络波动导致服务端没收到ACK，那么服务端会重传FIN信号。从服务端的角度老说，第四次挥手能确保客户端收到FIN信号。**

## TCP UDP

TCP面向连接，UDP是无连接的，TCP能通过校验和，重传控制等，保证可靠传输，UDP不能保证可靠传输，但UDP实时性高且UDP对资源需要的少。

## TCP 如何保证数据传输的可靠性

校验和 确认应答+序列号 超时重传 流量控制 拥塞控制

## TCP3次握手的过程，为什么要3次 ，SYN攻击

## 大文件为什么越下载越快？

滑动窗口，慢启动算法，越传越快。

前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下：

1）收到一个ACK时，cwnd = cwnd + 1/cwnd

2）当每过一个RTT时，cwnd = cwnd + 1

这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。

## Innodb 自增主键

上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。

如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。

## HTTP 无状态 无连接

**无连接的含义**是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。为请求时建连接、请求完释放连接，以尽快将资源释放出来服务其他客户端，可以加KeepAlive弥补无连接的问题

**无状态**是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。 可以通过Cookie和Session来弥补这个问题。

## Cookie 和 Session

cookie 是一种发送到客户浏览器的文本串句柄，并保存在客户机硬盘上，可以用来在某个WEB站点会话间持久的保持数据。

Session的本质上也是cookie，但是不同点是存在服务器上的。这就导致，你如果使用cookie，你关闭浏览器之后，就丢掉Cookie了，但是如果关掉浏览器，重新打开之后，发现还有相应的信息，那就说明用的是Session。因为cookie是存在本地的，所以也会有相应的安全问题，攻击者可以去伪造他，填写相应的字段名，就能登录你的账户，还有如果cookie的有效期很长的话，也不安全。

session 由服务器产生，对于客户端，只存储session id在cookie中。

## LRU算法是如何实现的？

双向链表加 哈希表

## 数组中出现次数最高的K个数

map+优先队列

先用map统计每个数的出现次数，然后维护 一个大小为K的优先队列（堆）。

## volatile 内存屏障

CPU有可能会把相应代码的CPU指令进行一次重排序，这虽然能提高运行的效率，但是也可能会影响一些数据的可见性，而volatile通过 内存屏障 这个指令，来保证了相应代码块的执行顺序。内存屏障还会强制更新一次CPU缓存。加载最新的内容。

## 快排的优化

快排有三个步骤：

1. 选择基准
    
2. 分割操作
    
3. 递归地对两个序列快速排列，直到序列为空或只有一个元素。
    

所以可以针对这三个方面做优化

**选择基准**:最理想的基准就是，每次划分都能分成登长的两个子序列。**最坏的情况** 就是基准是最大最小值。

可以选的基准有：固定位置，随机位置，三数取中。

三数取中是指 取 最左 最右 中间元素 三个数的中间值。

**其他优化方式**：

1. 当排序序列分割到一定大小的时候，可以使用插入排序
    
2. 如果有key相等的元素，可以聚在一起，下次排序的时候，就不用对相等的元素再排序了
    
3. 优化递归操作
    
4. 多线程
    

## Mysql 的 redo undo

Undo日志记录某数据**被修改前**的值，可以用来在事务失败时进行**回滚**；Redo日志记录某数据块**被修改后**的值，可以用来恢复未写入data file的已成功事务更新的数据。

## 死锁的四个条件 和预防

互斥，不可剥夺，循环等待，请求和保持

预防，检测，避免死锁，接触死锁

## 银行家算法

## 多路IO模型 NIO

在多路复用IO模型中，会有一个**线程（Java中的Selector）**不断去**轮询**多个socket的状态，只有当socket真正有**读写事件**时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要**使用一个线程就可以管理多个socket**，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。

## 五种网络IO模型

阻塞IO 非阻塞IO 多路IO复用，信号驱动IO（不常用），异步IO，

前四种都是**同步IO**

像listen()、send()、recv()这些接口都是阻塞的，一问一答型的。这就给网络编程带来了一个问题，如果在调用send的时候，线程将被阻塞，在此期间，无法执行任何运算或相应任何的网络请求。于是有了多路IO模型，一个socket可以多次accept多次，比如Java中的selcetor 不断轮询多喝socket的状态，只有当socket真正有读写事件的时候，才会调用实际的IO读写操作，还有想Golang里的select+多个channel，这样只需要一个线程就可以管理多个socket，能减少大量资源占用。

**非阻塞IO模型**

在非阻塞IO模型中，用户进程不需要主动询问对方是否准备好数据与否，比如进程发出read操作，如果对方没有准备好，会返回一个error，这表示对方没有准备好，但是进程并不会阻塞在这一步，而是继续执行，等对方准备好数据后，再去调用它。

**异步IO**

异步IO是真正意义上的非阻塞IO，用户进程发起read操作后，立刻就可以开始做其他事，而另一方面，当他收到一个异步请求时，会立即返回一个值，所以不会对用户进程产生任何阻塞，等数据准备完后，再将数据拷贝到用户内存，当这一切都完成后，再给用户进程发送一个signal，告诉他read操作完成了。

**非阻塞IO和异步IO的区别**

虽然非阻塞IO在大多时间内不会被阻塞，但是它要求进程去主动监察对方数据是不是准备好了，一旦准备好了，会再次要求进程调用接收函数将数据拷贝过来。而异步IO完全不管这些，就像吧IO操作外包掉，等他人做完再发信号通知，这个期间内，进程不要检查也不用主动的去拷贝。

Golang里的Sync包

互斥锁：Mutex，读写锁:RWMutex. WaitGoup,Cond实现一个条件变量，Once 使对象只执行一次。

## Java线程的6种状态及切换

初始：新建一个线程对象

运行：调用了start后就是运行状态

阻塞：线程被锁阻塞

等待，进入该状态的线程需要等待其他线程做出一些动作（通知或者唤醒

超时等待：

终止：

## 虚拟内存

虚拟内存使得应用程序认为它拥有连续的可用内存，这样一来，就在逻辑层面上扩大了内存容量。但是实际上，只是把比较常用的内存片段取出来了而已，还有部分资源是放在磁盘存储器上的。需要的时候再进行数据交换。

调度方式有，分页式，段式，段页式。比较流行方式是段页式，他结合了前两者的优点，以页为单位替换，以段为单位使用。

常见的替换替换算法有4种，随机算法，先进先出算法，LRU算法，最优算法。 比较常使用的是LRU算法，他在redis里也有使用，当redis的内存满了的时候就是使用LRU算法替换掉旧内存。

#  linux查内存，查cpu命令  

  
在Linux中，你可以使用以下命令来查看内存和CPU的信息：

1. 查看内存信息：
    
    - `free`: 显示系统内存的使用情况，包括总内存、已使用内存、空闲内存、缓冲区和缓存等信息。
        
    - `top`: 实时显示系统的资源使用情况，包括内存的总量、已用量、空闲量、缓冲区和缓存的使用情况，以及进程占用的内存等。可以按'M'键来按内存使用量排序。
        
    - `htop`: 类似于top命令，但是提供了更多的交互式功能和更直观的展示方式。
        
2. 查看CPU信息：
    
    - `top`: 在top命令中，你可以看到CPU的使用情况，包括CPU的使用率、各个进程的CPU占用情况等。可以按'P'键按CPU使用率排序。
        
    - `htop`: 类似于top命令，可以显示CPU的使用情况，并提供更多的交互式功能和展示方式。
        
    - `mpstat`: 显示多核CPU的使用情况，包括每个CPU核心的使用率、用户态和内核态使用率等。
        
    - `lscpu`: 显示CPU的详细信息，包括CPU的型号、架构、核心数、线程数等。
        
    - `nproc`: 显示CPU的核心数。
        
    - `cat /proc/cpuinfo`: 查看CPU的详细信息，包括每个CPU核心的信息。
        
    
    以上命令中，`top`和`htop`是实时监控命令，可以在命令行下直接运行并查看实时的内存和CPU使用情况。其他命令则是查看系统硬件和CPU信息的静态命令。你可以根据需要选择合适的命令来查看内存和CPU的信息。


# 一个数组nums，一个target，在数组中寻找target，如果数组中存在，则返回target的下标。若数组中不存在，则返回target应该插入位置的下标
```go
package main

func searchInsert(nums []int, target int) int {
    left, right := 0, len(nums)-1
    for left <= right {
        mid := left + (right-left)/2
        if nums[mid] == target {
            return mid
        } else if nums[mid] < target {
            left = mid + 1
        } else {
            right = mid - 1
        }
    }
    return left
}

```

# 2、MySQL 索引在什么情况下会失效？

（1）当使用like关键字时，如果查询条件以%开头，索引无效；当like前缀没有%，后缀有%时，索引依然有效。

（2）当使用or关键字时，or语句前后没有同时使用索引或当or关键字左右查询字段只有一个是索引，该索引失效，只有当or左右查询字段均为索引时，才会生效。

（3）使用组合索引时，如果查询条件不包括该组合索引全部字段或查询条件不是该组合索引左边第一个字段时，索引失效。

（4）数据类型出现隐式转化。如某个索引字段的数据类型为varchar，查询内容为123，如不加引号的话可能会自动转换为int型，使索引无效，产生全表扫描。

（5）在索引字段上使用not及运算符

（6）对索引字段进行计算操作、字段上使用函数，索引失效。



# 5、MySQL 主从同步怎么搞的？分哪几个过程？如果有一台新机器要加到从机里，怎么个过程。

6、乐观锁与悲观锁的区别？

# 7、binlog 日志是 master 推的还是 salve 来拉的？
mysql 的主从复制是 master 给 slave 主动发消息

# 9、redis 主从同步是怎样的过程？
因此，主服务器的复制积压缓冲区里面会保存着一部分最近传播的写命令，并且复制积压缓冲区会为**队列中的每个字节记录相应的复制偏移量**

当从服务器重新连上主服务器时，从服务器会通过PSYNC命令将自己的复制偏移量offset发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作：

❑如果offset偏移量之后的数据（也即是偏移量offset+1开始的数据）仍然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作。

❑相反，如果offset偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整重同步操作。

回到之前图15-9展示的断线后重连接例子：

❑当从服务器A断线之后，它立即重新连接主服务器，并向主服务器发送PSYNC命令，报告自己的复制偏移量为10086。

❑主服务器收到从服务器发来的PSYNC命令以及偏移量10086之后，主服务器将检查偏移量10086之后的数据是否存在于复制积压缓冲区里面，结果发现这些数据仍然存在，于是主服务器向从服务器发送+CONTINUE回复，表示数据同步将以部分重同步模式来进行。

❑接着主服务器会将复制积压缓冲区10086偏移量之后的所有数据（偏移量为10087至10119）都发送给从服务器。

❑从服务器只要接收这33字节的缺失数据，就可以回到与主服务器一致的状态

Redis为复制积压缓冲区设置的默认大小为1MB，如果主服务器需要执行大量写命令，又或者主从服务器断线后重连接所需的时间比较长，那么这个大小也许并不合适。如果复制积压缓冲区的大小设置得不恰当，那么PSYNC命令的复制重同步模式就不能正常发挥作用，因此，正确估算和设置复制积压缓冲区的大小非常重要。

复制积压缓冲区的最小大小可以根据公式second\*write_size_per_second来估算：

□ 其中second为从服务器断线后重新连接上主服务器所需的平均时间（以秒计算）。

□ 而write_size_per_second则是主服务器平均每秒产生的写命令数据量（协议格式的写命令的长度总和）。

例如，如果主服务器平均每秒产生1 MB的写数据，而从服务器断线之后平均要5秒才能重新连接上主服务器，那么复制积压缓冲区的大小就不能低于5MB。为了安全起见，**可以将复制积压缓冲区的大小设为2\*second\*write_size_per_second，这样可以保证绝大部分断线情况都能用部分重同步来处理。（优化点）**
# redis 从节点可以提供服务吗
主从和哨兵是可以提供读
cluster不可以提供，但是可以通过readonly来提供

# 15、http与https的区别？

（1）HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的ssl加密传输协议

（2）HTTP 和 HTTPS 使用的是完全不同的连接方式用的端口也不一样,前者是80,后者是443。

（3）HTTP 的连接很简单,是无状态的

（4）HTTPS 协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议 要比 HTTP 协议安全

（5）HTTPS 内容传输经过完整性校验

（6）HTTPS 内容经过对称加密，每个连接生成一个唯一的加密密钥

（7）HTTPS 第三方无法伪造服务端（客户端）身份

16、raft算法和zk选主算法；

17、Kafka 选主怎么做的？

18、kafka 与 rabbitmq区别；

19、kafka 分区怎么同步的？

20、kafka 怎么保证不丢消息的？

21、kafka 为什么可以扛住这么高的qps？

22、http各种返回码，401和406啥区别？

23、redis哨兵和集群；

24、kafka partition broker consumer consumer group topic 等都是啥关系？

26、手撕代码。牛客题霸上的原题，可以去看看：NC58 找到搜索二叉树中两个错误的节点。

27、两个单向链表，返回求和后的链表结构，例如2->3->1->5，和3->6，结果返回2->3->5->1

# 微信登录流程：
![[Pasted image 20230723214506.png]]

# 为什么快速排序一般都比归并的好用
归并排序和快速排序都是利用分治的思想
归并排序非常稳定，时间复杂度都是nlogn,但不是原地排序，快速排序虽然最坏情况下是n的二次方，但是平均时间下为nlogn，是原地排序算法

堆排比较的几乎都不是相邻元素，对cache极不友好，这才是很少被采用的原因。

数学上的时间复杂度不代表实际运行时的情况

### 什么场景下归并排序比快排高效？

  当对链表结构的数据进行排序时，归并排序反而比快排高效。由于链接列表单元通常散布在整个内存中，因此访问相邻的链接列表单元不会带来任何位置上的好处。因此，Quicksort巨大的性能优势之一就被吃光了。同样，就地工作的好处不再适用，因为合并排序的链表算法不需要任何额外的辅助存储空间。

  也就是说，快速排序在链表上仍然非常快。合并排序往往会更快，因为它可以将列表更均匀地分成两半，并且每次迭代完成合并的工作要比分区步骤少。

# 算法
#### [102. 二叉树的层序遍历](https://leetcode.cn/problems/binary-tree-level-order-traversal/)

二叉树的非递归前序中序后序遍历
#### [328. 奇偶链表](https://leetcode.cn/problems/odd-even-linked-list/)
#### [82. 删除排序链表中的重复元素 II](https://leetcode.cn/problems/remove-duplicates-from-sorted-list-ii/)
#### [51. N 皇后](https://leetcode.cn/problems/n-queens/)
#### [46. 全排列](https://leetcode.cn/problems/permutations/)
#### [剑指 Offer II 022. 链表中环的入口节点](https://leetcode.cn/problems/c32eOV/


还没有掌握的题目：
#### [221. 最大正方形](https://leetcode.cn/problems/maximal-square/)
