> 上家公司把我调到 xx 岗，该岗位与我自己的职业规划有很大偏差，我希望做的是 yy 方向。（这个 yy 最好是你面试的这个岗位的方向）

> 由于身体不好/身体哪里受伤所以修养了一段时间，或者家人哪里需要帮忙等等，算是问到 gap 的时候不会太踩雷的一个答案。

虽然可以通过tidb的快照表来做，但是快照表每日都要检查多次，很麻烦。因为有可能数据延迟太大，之前的数据是不准的。


# 项目描述
SuiVision是基于Sui的浏览器和分析平台，功能丰富，页面清晰，允许用户快速掌握Sui的链上数据。用户可以浏览和搜索交易、账户、对象、包、验证节点、NFT、数据状态等信息。
项目地址：https://suivision.xyz/
# 技术架构
Golang,Redis,Gin,Kafka,Grafana,Prometheus
# 行动
- 数据同步与处理：设计并实现了高效数据同步模块，负责从Sui链获取和处理链上数据，确保数据的实时更新和一致性。利用kafka进行数据分发，减少了对链上数据的请求量。
- 数据统计与展示：开发并维护了SuiVision的数据统计和展示功能，使用Gin框架构建API，并且合理使用redis缓存，为前端提供高效的数据接口。
- 系统优化与稳定性建设：通过使用Kafka实现异步消息队列，优化了数据处理流程，提高了系统的可扩展性和响应速度。采用Grafana和Prometheus进行系统监控，实时跟踪应用性能指标，并根据监控数据进行系统调优，确保平台的高可用性和稳定性。
- 负责会员支付系统的需求开发和重构。
# 遇到的困难
- 系统故障最小化：Sui区块链处于快速发展阶段，偶尔会出现链上数据请求出现大规模延迟的情况，当链上故障发生时，需要保证SuiVision故障最小化。经过调研，采用kafka分发加快同步效率，通过redis位图记录同步状态，并且根据延迟情况来使用降级策略。
- 大规模数据查询性能：SuiVision需要在海量数据上按照不同时间周期，不同维度进行统计。经过调用，采用clickhouse来加快查询的效率

# 结果
- 在Sui区块链不稳定与竞争对手网站处于不可用的时间段，SuiVision依然处于可用状态
- 数据统计的时候，将查询统计效率从一个小时优化到数秒级别。


# 背景
苏打优选电商平台是一家专注于为企业提供福利方案的电商平台。我们合作的企业可以通过苏打优选电商平台为他们的员工提供优惠券和代金券。这些券可以让员工在苏打优选电商平台上购买各种各样的商品，从而提高他们的员工满意度。  
# 角色
- 数据异构同步系统负责人
- 订单系统后端开发
- 商品查询中台后端开发
# 技术架构
Golang,ElasticSearch,Redis,Gin,HBase,Nsq,Kubernetes,Kafka,Mysql,Grpc,Docker

# 行动

- 负责数据异构同步系统：公司对于中间件数据的写入主要是监听MySQL的binlog来进行处理和写入，我们通过阿里云的DTS服务从kafka中消费数据，来写入HBase，Redis，ElasticSearch，Kafka等中间件。
- 系统优化和性能调优：针对系统性能问题，进行了多方位优化，包括但不限于SQL优化、代码优化、并发控制、内存管理等方面。通过引入缓存技术如Redis，优化了数据访问速度和系统响应时间。
- 参与团队建设和技术分享：积极参与团队内部的技术分享和交流，组织团队成员学习新技术和解决方案，提升团队整体技术水平。
- 商品数据查询和缓存优化：作为核心开发者之一，我专注于优化商品数据的查询性能和系统响应速度。通过合理运用Redis缓存，降低了对数据库的频繁查询。同时，充分利用Elasticsearch的搜索功能，通过优化查询设计和索引设置，提供了快速而准确的商品搜索结果，提升了用户体验和系统的竞争力。
- 订单系统设计和开发：我负责订单下单流程和查询流程，通过saga分布式事务来保证全局的最终一致性，通过订单数据冷热分离和分库分表来承载庞大的订单数据，通过ElasticSearch来进行对订单的数据的过滤，并通过Redis和HBase来构建多级缓存加速查询,通过Nsq进行延时消息处理。
- 商城装修和显示处理：我负责商城页面的装修和显示处理工作。通过组件化改造和模块化处理，提供了便于用户个性化改造的商城界面，并通过Nsq实现了管理系统和业务系统的逻辑解耦合。
- 系统架构设计和可伸缩性优化：除了接口开发和数据存储优化，我积极参与了系统架构设计工作，以确保系统具备良好的可伸缩性和稳定性。通过全面评估业务需求和预测系统负载，参与设计了高可用的分布式架构，并合理划分模块和服务，实现了水平扩展和负载均衡。在数据库方面，通过优化索引设计和查询性能，提升了数据库的查询效率和吞吐量，确保系统在高负载情况下的稳定运行。

# 遇到的挑战
- 异构数据同步慢而且一致性差：系统初期多表同步业务处理速度慢，消费速度慢，导致线上经常出现数据错误，消息堆积等情况。所以核心目标是保证数据一致性的前提下提高多个业务线的同步速度。最终通过调整Kafka分区策略以及HBase版本机制和Redis任务队列以及增量修复，全量修复来解决问题。
# 结果
- 将同步效率从每秒数百条消息提升到每秒数千条消息，性能提升了十几倍，满足了日常需求。
