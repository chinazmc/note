#  思考题：概率 p 生成 0，1-p 生成 1，如何 1/2 概率生成 1
  
这道题想等概率产生0、1，就需要找到两个独立事件，这个两个独立事件发生的概率相同，已知随机数生成器可以以p产生0，以1-p产生1，所以有下面4个独立事件，用随机数生成器产生00，01，10，11，各自的概率分别为p\*p，p*(1-p)，(1-p)\*p，(1-p)\*(1-p)可以发现生成01，10的概率相同，因此只保留这两种情况敏感词舍弃，然后将01映射为0，10映射为1，则等概率0，1随机数生成器可得到

# es索引的过程
写操作执行的过程：
1. 客户端向Node1 发送索引文档请求
2. Node1 根据文档ID(\_id字段)计算出该文档应该属于shard0，然后请求路由到Node3的P0分片上
3. Node3在P0上执行了请求。如果请求成功，则将请求并行的路由至Node1，Node2的R0上。当所有的Replicas报告成功后，Node3向请求的Node(Node1)发送成功报告，Node1再报告至Client。

当客户端收到执行成功后，操作已经在Primary shard和所有的replica shards上执行成功了

读操作执行的流程：
读操作步骤：

1.客户端发送Get请求到NODE1。  
2.NODE1使用文档的_id决定文档属于shard 0.shard 0的所有拷贝存在于所有3个节点上。这次，它将请求路由至NODE2。  
3.NODE2将文档返回给NODE1，NODE1将文档返回给客户端。 对于读请求，请求节点(NODE1)将在每次请求到来时都选择一个不同的replica。  
shard来达到负载均衡。使用轮询策略轮询所有的replica shards。

更新操作执行的流程：
1.客户端发送更新操作请求至NODE1  
2.NODE1将请求路由至NODE3，Primary shard所在的位置  
3.NODE3从P0读取文档，改变_source字段的JSON内容，然后试图重新对修改后的数据在P0做索引。如果此时这个文档已经被其他的进程修改了，那么它将重新执行3步骤，这个过程如果超过了retry_on_conflict设置的次数，就放弃。  
4.如果NODE3成功更新了文档，它将并行的将新版本的文档同步到NODE1和NODE2的replica shards重新建立索引。一旦所有的replica  
shards报告成功，NODE3向被请求的节点(NODE1)返回成功，然后NODE1向客户端返回成功。

写到磁盘的倒序索引是不变的：自从写到磁盘就再也不变。 这会有很多好处：

不需要添加锁。如果你从来不用更新索引，那么你就不用担心多个进程在同一时间改变索引。  
一旦索引被内核的文件系统做了Cache，它就会待在那因为它不会改变。只要内核有足够的缓冲空间，绝大多数的读操作会直接从内存而不需要经过磁盘。这大大提升了性能。  
其他的缓存(例如fiter cache)在索引的生命周期内保持有效，它们不需要每次数据修改时重构，因为数据不变。  
写一个单一的大的倒序索引可以让数据压缩，减少了磁盘I/O的消耗以及缓存索引所需的RAM。  

> 当然，索引的不变性也有缺点。如果你想让新修改过的文档可以被搜索到，你必须重新构建整个索引。这在一个index可以容纳的数据量和一个索引可以更新的频率上都是一个限制。

2.6.2动态更新索引

## 如何在不丢失不变形的好处下让倒序索引可以更改？答案是：使用不只一个的索引。 新添额外的索引来反映新的更改来替代重写所有倒序索引的方案。  
Lucene引进了per-segment搜索的概念。一个segment是一个完整的倒序索引的子集，所以现在index在Lucene中的含义就是一个segments的集合，每个segment都包含一些提交点(commit  point)。见Figure16。新的文档建立时首先在内存建立索引buffer，见Figure17。然后再被写入到磁盘的segment，见Figure18。

![](https://pic3.zhimg.com/80/v2-a6c436d2d45cdc5ff144586a2dd4be36_720w.webp)

![](https://pic1.zhimg.com/80/v2-6306ed09c11ba0c69929f9a9e8c5dfd8_720w.webp)

一个per-segment的工作流程如下：

1.新的文档在内存中组织，见Figure17。  
2.每隔一段时间，buffer将会被提交：  
一个新的segment(一个额外的新的倒序索引)将被写到磁盘 一个新的提交点(commit  point)被写入磁盘，将包含新的segment的名称。 磁盘fsync，所有在内核文件系统中的数据等待被写入到磁盘，来保障它们被物理写入。  
3.新的segment被打开，使它包含的文档可以被索引。  
4.内存中的buffer将被清理，准备接收新的文档。

> 当一个新的请求来时，会遍历所有的segments。词条分析程序会聚合所有的segments来保障每个文档和词条相关性的准确。通过这种方式，新的文档轻量的可以被添加到对应的索引中。

删除和更新

## segments是不变的，所以文档不能从旧的segments中删除，也不能在旧的segments中更新来映射一个新的文档版本。取之的是，每一个提交点都会包含一个.del文件，列举了哪一个segmen的哪一个文档已经被删除了。  
当一个文档被”删除”了，它仅仅是在.del文件里被标记了一下。被”删除”的文档依旧可以被索引到，但是它将会在最终结果返回时被移除掉。

文档的更新同理：当文档更新时，旧版本的文档将会被标记为删除，新版本的文档在新的segment中建立索引。也许新旧版本的文档都会本检索到，但是旧版本的文档会在最终结果返回时被移除。

## 在上述的per-segment搜索的机制下，新的文档会在分钟级内被索引，但是还不够快。  
瓶颈在磁盘。将新的segment提交到磁盘需要fsync来保障物理写入。但是fsync是很耗时的。它不能在每次文档更新时就被调用，否则性能会很低。  
现在需要一种轻便的方式能使新的文档可以被索引，这就意味着不能使用fsync来保障。  
在ES和物理磁盘之间是内核的文件系统缓存。之前的描述中,Figure19,Figure20，在内存中索引的文档会被写入到一个新的segment。但是现在我们将segment首先写入到内核的文件系统缓存，这个过程很轻量，然后再flush到磁盘，这个过程很耗时。但是一旦一个segment文件在内核的缓存中，它可以被打开被读取。

> translog日志提供了一个所有还未被flush到磁盘的操作的持久化记录。当ES启动的时候，它会使用最新的commit   point从磁盘恢复所有已有的segments，然后将重现所有在translog里面的操作来添加更新，这些更新发生在最新的一次commit的记录之后还未被fsync。

translog日志也可以用来提供实时的CRUD。当你试图通过文档ID来读取、更新、删除一个文档时，它会首先检查translog日志看看有没有最新的更新，然后再从响应的segment中获得文档。这意味着它每次都会对最新版本的文档做操作，并且是实时的。
## 通过每隔一秒的自动刷新机制会创建一个新的segment，用不了多久就会有很多的segment。segment会消耗系统的文件句柄，内存，CPU时钟。最重要的是，每一次请求都会依次检查所有的segment。segment越多，检索就会越慢。

ES通过在后台merge这些segment的方式解决这个问题。小的segment merge到大的，大的merge到更大的。。。
这个过程也是那些被”删除”的文档真正被清除出文件系统的过程，因为被标记为删除的文档不会被拷贝到大的segment中。

## mysql8的自适应hash索引
我们先回顾下B+树索引和Hash索引： B+树索引是MySQL的默认索引机制，也是大部分 因为可以使用范围搜索，可以很容易对数据进行排序操作，在联合索引中也可以利用部分索引建进行查询。这些情况下，我们都没法使用Hash索引，是因为Hash索引仅能满足=, <>, IN查询，不能使用范围查询，同时因为数据的存储是没有顺序的，所以在ORDER BY的情况下，还需要对数据重新进行排序。而对于联合索引的情况，Hash值是针对联合索引建合并后一起来计算Hash值，因此无法对单独的一个键或者几个索引键进行查询。 好了，默认使用B+树作为索引是因为B+树存在着以上的优点，那为什么还需要自适当Hash索引呢？这里，需要了解Hash索引的特点，因为Hash索引结构的特点，导致它的检索数据效率非常高，通常只需要O(1)的复杂度，也就是一次就可以完成数据的检索。虽然Hash索引的使用场景有很多限制，但是优点也很明显，所以MySQL提供了一个自适当Hash索引的功能（Adaptive Hash index）。注意，这里的自适应指的是不需要人工来制定，而是系统根据情况来自动完成的。 那什么情况下才会使用自适应Hash索引呢？如果某个数据经常会访问到，当满足一定条件的时候，就会将这个数据页的地址存放到Hash表中。这样下次查询的时候，就可以直接找到这个页面的所在位置。需要说明的是： 1）自适应哈希索引只保存热数据（经常被使用到的数据），并非全表数据。因此数据量并不会很大，可以让自适应Hash放到缓冲池中，也就是InnoDB buffer pool，进一步提升查找效率。 2）InnoDB中的自适应Hash相当于是“索引的索引”，采用Hash索引存储的是B+树索引中的页面的地址。这也就是为什么可以称自适应Hash为索引的索引。 采用自适应Hash索引目的是可以根据SQL的查询条件加速定位到叶子节点，特别是当B+树比较深的时候，通过自适应Hash索引可以提高数据的检索效率。 3）自适应Hash采用Hash函数映射到一个哈希表中，所以对于字典类型的数据查找非常方便 哈希表是数组+链表的形式。通过Hash函数可以计算索引键值所对应的bucket（桶）的位置，如果产生Hash冲突，如果产生哈希冲突，就需要遍历链表来解决。 4）是否开启了自适应Hash，可以通过innodb_adaptive_hash_index变量来查看，比如：mysql> show variables like '%adaptive_hash_index'; 所以，总结下InnoDB本身不支持Hash，但是提供自适应Hash索引，不需要用户来操作，而是存储引擎自动完成的。自适应Hash也是InnoDB三大关键特性之一，另外两个分别是插入缓冲（Insert Buffer）和二次写(Double Write)。
1、原理过程

 ![](https://images2017.cnblogs.com/blog/1113510/201708/1113510-20170830183917780-959160821.png)

　　Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热数据，建立哈希索引可以带来速度的提升，则：

　　1、自适应hash索引功能被打开

mysql> show variables like '%ap%hash_index';
+----------------------------+-------+
| Variable_name              | Value |
+----------------------------+-------+
| innodb_adaptive_hash_index | ON    |
+----------------------------+-------+
1 row in set (0.01 sec)

　　2、经常访问的二级索引数据会自动被生成到hash索引里面去(最近连续被访问三次的数据)，自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。

2、特点

　　1、无序，没有树高

　　2、降低对二级索引树的频繁访问资源

　　　　索引树高<=4，访问索引：访问树、根节点、叶子节点

　　3、自适应

3、缺陷

　　1、hash自适应索引会占用innodb buffer pool；

　　2、自适应hash索引只适合搜索等值的查询，如select * from table where index_col='xxx'，而对于其他查找类型，如范围查找，是不能使用的；

　　3、极端情况下，自适应hash索引才有比较大的意义，可以降低逻辑读。

**三、监控与关闭**

1、状态监控

mysql> show engine innodb status\G
……
Hash table size 34673, node heap has 0 buffer(s)
0.00 hash searches/s, 0.00 non-hash searches/s

　　1、34673：字节为单位，占用内存空间总量

　　2、通过hash searches、non-hash searches计算自适应hash索引带来的收益以及付出，确定是否开启自适应hash索引

2、限制

　　1、只能用于等值比较，例如=， <=>，in

　　2、无法用于排序

　　3、有冲突可能

　　4、MySQL自动管理，人为无法干预。

3、自适应哈希索引的控制

　　由于innodb不支持hash索引，但是在某些情况下hash索引的效率很高，于是出现了adaptive hash index功能，但是通过上面的状态监控，可以计算其收益以及付出，控制该功能开启与否。

　　默认开启，建议关掉，意义不大。可以通过 set global innodb_adaptive_hash_index=off/on 关闭和打开该功能。

## 有7克，2克砝码各一个，天平一只，如何只用这些物品3次将140的盐分为50、90克各一份？
  
1、将140克盐放天平两边平分两份各70克；

2、将一份70克盐平分两份各35克；

3、将7克和2克砝码各方天平一侧，取一份35克盐向天平两端加知道左右平衡，此时与7克砝码一侧为15克盐，与2克砝码一侧为20克盐；

4、此时20克盐加70克盐为90克，剩余合并为50克。

## 找出两个大文件交集
使用hash函数将第一个文件的所有整数映射到1000个文件中，每个文件有1000万个整数，大约40M内存，

内存可以放下，把1000个文件记为 a1,a2,a3.....a1000,用同样的hash函数映射第二个文件到1000个文件中，这1000个文件记为b1,b2,b3......b1000，由于使用的是相同的hash函数，所以两个文件中一样的数字会被分配到文件下标一致的文件中，分别对a1和b1求交集，a2和b2求交集，ai和bi求交集，最后将结果汇总，即为两个文件的交集

## 布隆过滤器（Bloom Filter）（给两个文件，分别有100亿个字符串，我们只要1g的内存，如何找到两个文件的交集？分别给出精确算法和近似算法？）
给两个文件，分别有100亿个字符串，我们只要1g的内存，如何找到两个文件的交集？分别给出精确算法和近似算法？
精确算法：
  我们可以创建1000个文件，运用哈希函数先将文件1的字符串保存在对应的文件中，之后再文件2中取元素，通过哈希函数计算出哈希地址，去对应的文件里面找是否有与之相同的字符串。
近似算法：
  我们可以使用位图的方法，通过一个函数将一个元素映射成一个位矩阵中的一个点，这样一来，我们只要看看这个点是不是1就知道集合里有没有它了。 但是有可能两个字符串对应的整数是一样的，对于这种情况我们可以设置更多的哈希函数，对应更多的地址，这样更加精确。
![[Pasted image 20230710163557.png]]

1.  已经从 sync.Pool Get 的值，在 poolClean 时虽说将 pool.local 置成了nil，Get 到的值依然是有效的，是被 GC 标记为黑色的，不会被 GC回收，当 Put 后又重新加入到 sync.Pool 中
2.  在第一个 GC 周期内 Put 到 sync.Pool 的数值，在第二个 GC 周期没有被 Get 使用，就会被放在 local.victim 中。如果在 第三个 GC 周期仍然没有被使用就会被 GC 回收。
## 只 Get 不 Put 会内存泄露吗？

使用其他的池，如连接池，如果取连接使用后不放回连接池，就会出现连接池泄露，**是不是 sync.Pool 也有这个问题呢？**

通过上面的流程图，可以看出来 Pool.Get 的时候会尝试从当前 private，shared，其他的 p 的 shared 获取或者 victim 获取，如果实在获取不到时，才会调用 New 函数来获取，New 出来的内容本身还是受系统 GC 来控制的。所以如果我们提供的 New 实现不存在内存泄露的话，那么 sync.Pool 是不会内存泄露的。当 New 出来的变量如果不再被使用，就会被系统 GC 给回收掉。

如果不 Put 回 sync.Pool，会造成 Get 的时候每次都调用的 New 来从堆栈申请空间，达不到减轻 GC 压力。

字段 `pad` 主要是防止 `false sharing`，董大的[《什么是 cpu cache》](https://www.jianshu.com/p/dc4b5562aad2)里讲得比较好：

> 现代 cpu 中，cache 都划分成以 cache line (cache block) 为单位，在 x86_64 体系下一般都是 64 字节，cache line 是操作的最小单元。

> 程序即使只想读内存中的 1 个字节数据，也要同时把附近 63 节字加载到 cache 中，如果读取超个 64 字节，那么就要加载到多个 cache line 中。

简单来说，如果没有 pad 字段，那么当需要访问 0 号索引的 poolLocal 时，CPU 同时会把 0 号和 1 号索引同时加载到 cpu cache。在只修改 0 号索引的情况下，会让 1 号索引的 poolLocal 失效。这样，当其他线程想要读取 1 号索引时，发生 cache miss，还得重新再加载，对性能有损。增加一个 `pad`，补齐缓存行，让相关的字段能独立地加载到缓存行就不会出现 `false sharding` 了。
bloom
可以看到误判率大约 1% 多点。你也许会问这个误判率还是有点高啊，有没有办法降低一点？答案是有的。
我们上面使用的布隆过滤器只是默认参数的布隆过滤器，它在我们第一次 add 的时候自动创建。Redis 其实还提供了自定义参数的布隆过滤器，需要我们在 add 之前使用bf.reserve指令显式创建。如果对应的 key 已经存在，bf.reserve会报错。bf.reserve有三个参数，分别是 key, error_rate和initial_size。错误率越低，需要的空间越大。initial_size参数表示预计放入的元素数量，当实际数量超出这个数值时，误判率会上升。
所以需要提前设置一个较大的数值避免超出导致误判率升高。如果不使用 bf.reserve，默认的error_rate是 0.01，默认的initial_size是 100。
每个布隆过滤器对应到 Redis 的数据结构里面就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。
向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就完成了 add 操作。
向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个 key 不存在。如果都是 1，这并不能说明这个 key 就一定存在，只是极有可能存在，因为这些位被置为 1 可能是因为其它的 key 存在所致。如果这个位数组比较稀疏，判断正确的概率就会很大，如果这个位数组比较拥挤，判断正确的概率就会降低。具体的概率计算公式比较复杂，感兴趣可以阅读扩展阅读，非常烧脑，不建议读者细看。
使用时不要让实际元素远大于初始化大小，当实际元素开始超出初始化大小时，应该对布隆过滤器进行重建，重新分配一个 size 更大的过滤器，再将所有的历史元素批量 add 进去 (这就要求我们在其它的存储器中记录所有的历史元素)。因为 error_rate 不会因为数量超出就急剧增加，这就给我们重建过滤器提供了较为宽松的时间。

- MySQL中怎么判断一条sql查询是否是全表扫描？那么type字段什么值才表示当前sql有最优的查询效率？一个sql中有 `between ... and` 时，type是什么值？

- 缓存一致性
- Redis key 统计
- Redis 单线程，io 多路复用
- 算法题 [www.nowcoder.com/practice/35…](https://link.juejin.cn/?target=https%3A%2F%2Fwww.nowcoder.com%2Fpractice%2F35119064d0224c35ab1ab612bffee8df "https://www.nowcoder.com/practice/35119064d0224c35ab1ab612bffee8df")
- Redis slowlog 原理

### 四面(面委)

- 项目为主
- tcp quick_ack 、 nodelay ，socket 编程
- 职业规划
- 为什么换工作

### 五面(GM)

- 项目
- go 协程机制

## 腾讯云

这个来源于网络，这位朋友主要技术方向是k8s、容器、云计算。

有服务上云的实践经历，了解cicd基本流程，求知意向是容 器研发、基础架构研发、运维研发之类的(主要还是研发方向)。

### 项目方向:

项目的话我不多说什么，就是自己的项目细节自己肯定清楚，如果项目中不是自己做的 部分，建议不要在简历上写太多，写清楚自己做了什么，容易被抠细节问，项目一般都会抠细节，特别细的那种!!!

### 语言栈:

因为主要语言栈是go，所以一般都比较少问python。

#### golang

1、gin框架路由怎么实现的，具体正则怎么匹配?限流中间件怎么实现? 2、go的slice 与数组的区别，slice的实现原理，源码? 3、golang的协程调度，gpm模型。协程调度 过程中的锁。 4、golang的channel实现，channel有缓存和无缓存，一般会直接撸码 (三个goroutine顺序打印)。 5、golang的关键字defer、recover、pannic之类的实现 原理。 6、sync包里面的锁、原子操作、waitgroup之类的。 7、make和new的区别， 引用类型和非引用类型，值传递之类的。

#### python

1、python多线程、多进程。 2、python的装饰器怎么实现的?

#### 操作系统

1、进程、线程、协程间的区别以及他们间的切换之类的，有时候会问到语言级别的协 程。 2、io复用、用户态/内核态转换 3、awk命令 4、linux查看端口占用 5、top命 令，free命令中的各个参数表示什么，buff/cache都表示什么?

#### k8s & 容器:

1、简单聊一下什么是云原生、什么是k8s、容器，容器与虚机相比优势。 2、k8s组 件，pod创建的过程，operator是什么? 3、docker是怎么实现的，底层基石 namespace和cgroup。 4、k8s的workload类型，使用场景，statefulset你们是怎么用 的? 5、limit和request，探针，一般怎么排查pod问题，查看上次失败的pod日志。 6、sidecar是什么，怎么实现的? 7、pv，pvc，动态pv怎么实现 8、k8s的声明式api 怎么实现的，informar源码。 9、cicd，发布模式。 10、svc的负载均衡、服务发现， ipvs与iptables。 以上基本是会被问的点(虽然有一些问题我也不是很熟)，另外很多 会被问k8s的网络之类的，因为我比较菜，这块被问的比较少。

#### 计算机网络:

1、tcp三次握手四次挥手，为什么不能是两次握手，三次挥手?握手和挥手过程中的状 态。 2、time_wait作用，为什么是2msl，close_wait作用，time_wait过多怎么办? 3、http请求的过程，浏览器输入网址请求过程?dns解析的详细过程? 4、https与http 的区别，https第一次服务端回传是否加密? 5、tcp与udp区别，tcp怎么保证可靠性。 6、http请求头、分隔符、⻓连接怎么实现

#### 数据库:

1、mysql的事务，事务使用场景。 2、mysql的索引，什么情况下索引失效，聚簇索引 与非聚簇索引，索引的存储b+树与b-树区别。 3、join的内外连接，最左匹配原则。 4、redis的数据结构，hmap怎么实现的，持久化怎么做，go操作redis的方式。 数据库 方向有被问到，我基本没答上来(一般都告诉他只会基础，开发直接使用gorm)。

#### 数据结构与算法:

1、倒排索引和B+树 2、判断链表是否有环，时间复杂度要求0(1) 3、LeetCode上合并 区间的题 4、leetcode的股票买卖的题 5、二叉树的最近公共祖先 6、有序数组合并 7、什么是平衡二叉树、最小堆 8、大文件的top10问题 9、golang实现栈、队列

#### 其他:

1、git 的相关操作，合并commit，合并之类的。 2、场景设计(比较多)

## 小米

### 

1. innodb MVCC实现
2. b+树是怎么组织数据的，数据的顺序一定是从左到右递增的么
3. ⻚分裂伪代码，b+树的倒数底层层可以⻚分裂么
4. 合并k个有序链表
5. redis的hashtable是怎么扩容的
6. select poll epoll，epoll具体是怎么实现的
7. GMP是怎么调度，channel是怎么收发消息的，channel的recq和g是怎么建立关系 的
8. innodb二次写是什么
9. undo里面具体存的是什么
10. b+树节点具体存的是什么
11. mysql一⻚最大能存多少数据
12. myisam和innodb索引上的区别
13. innodb commit之前，redo 的prepare然后binlog commit，然后redo再commit有 什么缺点?5.6之后是怎么优化的? 14. redo和binlog的区别
14. 读锁和写锁区别

### 

1. 蛇形打印二叉树
2. myisam为什么不支持事务，如果要支持事务要怎么做
3. 函数只能返回1-7的随机数，请用这个函数返回1-5，要求平均 4. 聊项目

### 

1. go的协程调度和os的线程调度有什么区别
2. 只有写锁实现读写锁
3. go的调度是怎么实现的
4. go的网络IO为什么快?还有优化空间么
5. epoll为什么这么快，还有优化空间么?如果要你实现一个网络IO应该怎么实现
6. 设计一个每秒80万qps的过滤器
7. 过滤器用redis实现，宕机期间数据怎么恢复
8. 设计一个下单 扣减库存的分布式应用，请求超时了怎么办，一直重试超时了怎么办
9. 数组A1 2和数组B2 3是一个关系圈，A能通过2找到3，数组A1 2和数组B2 3和数组 C 3 5也是一个关系圈，给一个二维数组求关系数

## 小米游戏

### 一、 介绍连接池项目

1. 介绍连接池常用的参数，最大连接数，最小存活数这些意义，为什么要有这些
2. 当链接超过最大连接数怎么处理，等待有空闲连接还是创建一个继续给出，比较两 者的优劣
3. 连接池清理链接的逻辑，如何优化的
4. 当连接池中有一些链接不可用了怎么办，如何保证这些连接的可用
5. 当出现下游某个实例挂掉了，连接池应该怎么处理
6. 对比 mysql redis http 连接池的实现

### 二、 介绍负载均衡算法

7. 介绍平滑负载均衡算法，实现
8. 当出现下游出现不可用，负载均衡算法怎么处理

### 三、 介绍聊天室项目

9. 介绍实现原理的，互相通信的逻辑
10. 聊天室服务端如何把消息下发给用户
11. 介绍websocket包的字段
12. 当有用户掉线怎么处理

### 四、 redis相关

13. redis的数据结构
14. 各个数据结构的操作
15. 各个数据结构的使用场景
16. 如何保证 Redis 的高可用
17. 当有一个key读取的频率非常高怎么办

### 五、 算法相关

18. 介绍快速排序 优先队列的实现

