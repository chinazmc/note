一个数组，不含重复元素，返回该数组所有可能的子集，如input {1,2,3},output {[],[1],[2],[3],[1,2],[1,3],[2,3],[1,2,3]}

```
InnoDB存储引擎的最小存储单元为16k（就像操作系统的最小单元为4k即1页），在这即B+树的一个节点的大小为16k
假设数据库一条数据的大小为1k，则一个节点可
以存储16条数据
而非叶子节点，key一般为主键假设8字节，指针在InnoDB中是6字节，一共为14字节，一个节点可以存储16384/14=1170个索引指针
可以算出一颗高度为2的树（即根节点为存储索
引指针节点，还有1170个叶子节点存储数据）,
每个节点可以存储16条数据，一共1170*16条数据=18720条
高度为3的树，可以存放1170*1170*16=21902400条记录
两千多万条数据，我们只需要B+树为3层的数据结构就可以完成，通过主键查询只需要3次10操作就能查到对应记录。
```

实现一个求中位数的函数 middle(a,b,c)

冒泡算法以及优化

![[Pasted image 20230619210126.png]]
![[Pasted image 20230619210120.png]]


# http状态码502与504区别
502 bad gateway 顾名思义 网关错误 后端服务器tomcat没有起来，应用服务的问题（前提是接入层7层正常的情况下）。

应用服务问题一种是应用本身问题；另一种是因为依赖服务问题比如依赖服务RT高，依赖的服务有大的读取（mysql慢查，http等），以至于调用方超过超时read时间；服务集群压力大时，也会出现502超时（502理解为不可响应或响应不过来，其实还是不可响应）。 
504 gateway time-out 顾名思义 网关超时 一般计算机中的超时就是配置错了，此处一般指nginx做反向代理服务器时，所连接的服务器tomcat无响应导致的。

从网络角度，502已经与后端建立了连接，但超时；504与后端连接未建立，超时。

502检查思路：

1、必现502，应用“挂了”

（1）后端机器上检查：

```go
$ ps -ef |grep java #检查进程是否在

$ sudo netstat -lntp |grep PORT #检查端口有没有起来

$curl -I 127.0.0.1:PORT/health #应用健康检查测试下,Your health check path
```

（2）上面都正常，看下接入层access.log有没有进来。

$ tail -300f access.log |grep xxxx | #grep下你的关键字

$ curl -I 10.10.10.10:80/java_hc #上面都正常情况下，去接入层检查下

2、偶现502

（1）CPU使用率高，QPS增加

考虑有大流量，后端压力导致短暂不可用，考虑临时扩容。

（2）检查应用本身nginx read超时时间配置

    proxy_read_timeout              2s; # vim /opt/nginx/nginx.conf

如果某些正常请求耗时在2s左右，那么会有少量大于2s的请求是502的。可以试着把上面耗时时间调大，看问题是否缓解。优化本身链路请求耗时是根本上的解决办法。

（3）检查接入层nginx read的配置

同（2）

# 输入两个整数 a 和 b，输出他们相除的结果，如果有循环小数用括号表示。如：
a=-1，b=2，输出 “-0.5”
a=1，b=3，输出 “0.(3)”
a=10，b=80，输出 “0.125”
a=-100，b=10，输出 “-10”
```go
package main

import (
	"fmt"
	"strconv"
)

func fractionToDecimal(a, b int) string {
	if a == 0 {
		return "0"
	}

	// 判断结果的符号
	sign := ""
	if (a > 0 && b < 0) || (a < 0 && b > 0) {
		sign = "-"
	}

	a = abs(a)
	b = abs(b)

	// 计算整数部分
	integerPart := strconv.Itoa(a / b)
	remainder := a % b

	// 如果没有小数部分，直接返回整数部分
	if remainder == 0 {
		return sign + integerPart
	}

	// 计算小数部分
	decimalPart := ""
	remainderMap := make(map[int]int)

	for remainder != 0 {
		if index, ok := remainderMap[remainder]; ok {
			// 出现循环小数，加括号
			decimalPart = decimalPart[:index] + "(" + decimalPart[index:] + ")"
			break
		}

		remainderMap[remainder] = len(decimalPart)
		quotient := remainder * 10 / b
		decimalPart += strconv.Itoa(quotient)
		remainder = remainder * 10 % b
	}

	return sign + integerPart + "." + decimalPart
}

// 辅助函数：获取绝对值
func abs(x int) int {
	if x < 0 {
		return -x
	}
	return x
}

func main() {
	fmt.Println(fractionToDecimal(-1, 2))  // 输出: "-0.5"
	fmt.Println(fractionToDecimal(1, 3))   // 输出: "0.(3)"
	fmt.Println(fractionToDecimal(10, 80)) // 输出: "0.125"
	fmt.Println(fractionToDecimal(-100, 10)) // 输出: "-10"
}

```


# 针对富途牛牛论坛，有人注册大量小号发广告，如何用技术手段在不影响用户体验的情况下来解决这个问题？

第一种方法：
使用ip限流，- 实施基于 IP 地址的请求频率限制，使用令牌桶算法或漏桶算法来平滑请求流量。
- 为每个 IP 地址设置一个请求配额，限制在一定时间窗口内的请求次数，超出配额的请求将被拒绝或延迟处理。
- 动态调整请求配额的大小，根据用户行为和信誉评估的结果进行自适应调整。

1. 用户行为分析：
    
    - 分析用户注册行为，识别异常频繁的注册行为，例如短时间内使用相同的 IP 地址或手机号码注册多个账号。（不给注册）
    - 监控用户发帖行为，检测过于频繁的发帖行为，通过设置合理的阈值来触发行为限制或人工审核。

1. 关键词过滤：
    
    - 建立一个广告关键词库，包含常见的广告词汇、招聘信息等。对于帖子的标题、正文和评论，进行关键词匹配和过滤。
    - 考虑使用敏感词过滤算法，例如 DFA（Deterministic Finite Automaton）算法，实现高效的关键词过滤。

ye# mysql 显示前10名发帖最多的用户名字及帖子数量
有下面两张表，user(用户表)和thread(帖子表), 假设有100W用户, 500W帖子, 写一条SQL,  
显示前10名发帖最多的用户名字及帖子数量, 并针对该语句指出如何设计合理的索引字段。  
如何确认你写的sql会用到哪个索引，另外请说明下你写的 sql 是否是最优解。

|表名|字段|
|---|---|
|user|uid, usernmae, password, create_time|
|thread|tid, uid, title, content, create_time|

这个需求用 MySQL 实现的话，无论怎么优化，至少要扫描一次索引树。这算是一个常见场景，我就抛砖引玉。

**常见实现**

常见实现是在 `thread` 表的 `uid` 上建索引, 并通过下面这条 SQL 查出前10名发帖最多的 uid 及帖子数量

```sql
select uid,count(*) as total from thread group by uid order by total desc limit 10;
```

然后通过查到的 uid 获取用户名(uid有索引)

select uid, usernmae from user where uid in (%s, %s, %s);

查出数据后缓存 1 到 2 分钟，性能也还可以。如果要写成一条 SQL 就加个联表查询。

**其他方案**

我见过有这样的实现，可以参考一下： 增加一个统计表，索引为`(total, uid)`, 有人发帖就更新这个表（异步更新），然后前端直接读取这个表

增加一个统计表，索引为(total, uid)，这个思路不错

一条 SQL

```sql
select x.uid, t.username, t.total 
from (
	select uid, count(*) as total 
	from thread 
	group by uid 
	order by total desc 
	limit 10
	) as t 
	inner join user as u 
	on t.uid = u.uid;
```


fu# 梯度费用
请用尽可能少的代码实现一个函数，用于计算用户一个月共计交费多少港元。（代码请写的尽量清晰简洁，我们希望能够看到你的编码风格和习惯） 用户在富途的平台上进行交易，需要交平台使用费。平台使用费的梯度收费方案如下： 每月累计订单数    每笔订单（港元） 梯度1：1-5笔 => 30.00 梯度2：6-20笔 => 15.00 梯度3：21-50笔 => 10.00 梯度4：51笔及以上 => 1.00 假设一个用户，一个月交易了6笔订单，则在梯度1交费共计： 30港元\*5=150港元，在梯度二交费：15港元，一共交费165港元。 使用golang编程语言来写函数
```go
func calculateMonthlyFee(orderCount int) float64 {
    var fee float64

    if orderCount >= 51 {
        fee += float64(orderCount-50) * 1.00
        orderCount = 50
    }
    if orderCount >= 21 {
        fee += float64(orderCount-20) * 10.00
        orderCount = 20
    }
    if orderCount >= 6 {
        fee += float64(orderCount-5) * 15.00
        orderCount = 5
    }
    fee += float64(orderCount) * 30.00

    return fee
    
}

```
# 假设现在需要让你实现一个限频的需求，限制任意一个登录用户任意5分钟内不能发帖超过10次
```go
import (
    "fmt"
    "github.com/go-redis/redis/v8"
    "time"
)

type RateLimiter struct {
    client *redis.Client
}

func (rl *RateLimiter) CheckPostingRate(userID string) bool {
    // 获取当前时间
    now := time.Now()

    // 使用Redis的INCR命令增加用户的发帖计数器
    key := fmt.Sprintf("posting:%s", userID)
    count, err := rl.client.Incr(ctx, key).Result()
    if err != nil {
        panic(err)
    }

    // 设置计数器的过期时间为5分钟
    if count == 1 {
        err := rl.client.Expire(ctx, key, 5*time.Minute).Err()
        if err != nil {
            panic(err)
        }
    }

    // 判断计数器的值是否超过10
    if count > 10 {
        return false
    }

    return true
}

```
在上述代码中，我们使用了Go语言的Redis客户端库 "github.com/go-redis/redis/v8" 来连接和操作Redis数据库。

在 `NewRateLimiter` 函数中，我们创建了一个Redis客户端连接，连接到本地Redis实例。你可以根据实际情况配置Redis的地址、密码和数据库。

在 `CheckPostingRate` 函数中，我们使用Redis的 `INCR` 命令来递增用户的发帖计数器。我们为每个用户创建了一个独立的计数器键，并设置过期时间为5分钟。然后，我们判断计数器的值是否超过10，如果超过则返回false，表示限制发帖；否则返回true，允许发帖。

使用Redis实现限频可以更高效地处理并发请求和计数器更新，并且可以与其他系统进行分布式部署，实现全局的限频控制。


# 假设给定两个int类型的有序数组A和有序数组B，并且每个数组中都可能存在重复的数字，现在要求给出一个算法判断A是否为B的子集（给出思路即可，不用写代码） 例如： 若A为【1， 1， 2， 3】，B为【1， 1， 1， 2， 2， 3】，则A为B的子集 若A为【1， 2， 2， 3】，B为【1， 1，2， 3， 3】，则A不为B的子集

  
可以使用双指针法来判断A是否为B的子集。具体步骤如下：

1. 初始化两个指针，分别指向数组A和数组B的起始位置。
2. 循环比较A和B的元素：
    - 如果A的当前元素等于B的当前元素，则同时向后移动两个指针，继续比较下一个元素。
    - 如果A的当前元素小于B的当前元素，则A不可能是B的子集，返回false。
    - 如果A的当前元素大于B的当前元素，则B的指针向后移动，继续比较A的当前元素与B的下一个元素。
3. 循环结束后，如果A的所有元素都被匹配到了，说明A是B的子集，返回true；否则，返回false。

这种算法的时间复杂度为O(m+n)，其中m和n分别为数组A和数组B的长度。由于算法只进行一次线性遍历，因此是一种高效的解决方案。

需要注意的是，这种解决方案适用于有序数组，如果数组是无序的，则需要先对数组进行排序再进行比较。另外，如果数组中包含重复元素，我们可以通过跳过重复元素的方式优化算法，提前处理重复的部分。


# io多路复用有哪几种
### select

它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。

#### select调用过程
![[Pasted image 20230620212523.png]] （1）使用copy_from_user从用户空间拷贝fd_set到内核空间

（2）注册回调函数__pollwait

（3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll）

（4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。

（5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk->sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。

（6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。

（7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。

（8）把fd_set从内核空间拷贝到用户空间。

  
#### select缺点

select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：

- 单个进程所打开的FD是有限制的，通过 `FD_SETSIZE` 设置，默认1024 ;
    
- 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；
    

> 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

- 对 socket 扫描时是线性扫描，采用轮询的方法，效率较低（高并发）

> 当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

### poll

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， **但是它没有最大连接数的限制**，原因是它是基于链表来存储的.

#### poll缺点

**它没有最大连接数的限制**，原因是它是基于链表来存储的，但是同样有缺点：

- 每次调用 poll ，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；
- 对 socket 扫描是线性扫描，采用轮询的方法，效率较低（高并发时）

### epoll

**epoll可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）
每一个epoll对象都有一个独立的eventpoll结构体，用于存放通过epoll_ctl方法向epoll对象中添加进来的事件。这些事件都会挂载在红黑树中，如此，重复添加的事件就可以通过红黑树而高效的识别出来(红黑树的插入时间效率是lgn，其中n为红黑树元素个数)。

而所有添加到epoll中的事件都会与设备(网卡)驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个回调方法。这个回调方法在内核中叫ep_poll_callback,它会将发生的事件添加到rdlist双链表中。

在epoll中，对于每一个事件，都会建立一个epitem结构体，如下所示：

当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。
![[Pasted image 20230620212630.png]] **从上面的讲解可知：通过红黑树和双链表数据结构，并结合回调机制，造就了epoll的高效。** 讲解完了Epoll的机理，我们便能很容易掌握epoll的用法了。一句话描述就是：三步曲。

- 第一步：epoll_create()系统调用。此调用返回一个句柄，之后所有的使用都依靠这个句柄来标识。
- 第二步：epoll_ctl()系统调用。通过此调用向epoll对象中添加、删除、修改感兴趣的事件，返回0标识成功，返回-1表示失败。
- 第三部：epoll_wait()系统调用。通过此调用收集收集在epoll监控中已经发生的事件。

#### epoll的优点

- 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）；
- 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll；
- 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。

#### epoll缺点

- epoll只能工作在 linux 下

#### epoll LT 与 ET 模式的区别

epoll 有 EPOLLLT 和 EPOLLET 两种触发模式，LT 是默认的模式，ET 是 “高速” 模式。

- LT 模式下，只要这个 fd 还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作；
- ET 模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论 fd 中是否还有数据可读。所以在 ET 模式下，read 一个 fd 的时候一定要把它的 buffer 读完，或者遇到 EAGIN 错误。

epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。

### select/poll/epoll之间的区别

select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。  

epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现
![[Pasted image 20230620212706.png]]
epoll是Linux目前大规模网络并发程序开发的首选模型。在绝大多数情况下性能远超select和poll。目前流行的高性能web服务器Nginx正式依赖于epoll提供的高效网络套接字轮询服务。但是，在并发连接不高的情况下，多线程+阻塞I/O方式可能性能更好。

#### 支持一个进程所能打开的最大连接数

- select：单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32_32，同理64位机器上FD_SETSIZE为32_64），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。
- poll：poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的。
- epoll：虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接。

#### FD剧增后带来的IO效率问题

- select：因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。
- poll：同上
- epoll：因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。

#### 消息传递方式

- select：内核需要将消息传递到用户空间，都需要内核拷贝动作
- poll：同上
- epoll：epoll通过内核和用户空间共享一块内存来实现的。

### 总结

select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。

select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。 

# 操作系统从用户态到内核态，做了什么事情
  当操作系统从用户态切换到内核态时，发生以下事情：

1. 上下文切换：发生用户态到内核态的切换时，操作系统需要保存当前用户进程的上下文信息，包括程序计数器（PC）、寄存器、栈指针等，以便稍后能够正确地恢复用户进程的执行状态。
    
2. 特权级的变更：从用户态切换到内核态，进程的特权级从用户级别（低特权级）切换到内核级别（高特权级）。在内核态下，进程可以访问受限资源和执行特权指令，而在用户态下，进程只能访问受限资源并受到操作系统的保护。
    
3. 执行内核代码：一旦进程进入内核态，操作系统可以执行内核代码来完成特权操作，例如访问受保护的设备、处理中断、执行系统调用等。在内核态下，操作系统可以执行各种关键任务，包括管理内存、调度进程、处理文件系统等。
    
4. 处理请求或事件：当进程切换到内核态后，操作系统可以处理用户进程请求或发生的事件。例如，当进程发起系统调用请求时，操作系统可以执行相应的系统调用函数来满足进程的需求。
    
5. 返回用户态：当操作系统完成所需的任务后，它会将保存的用户进程上下文信息恢复回来，包括程序计数器和寄存器的值，并将控制权返回给用户进程。用户进程从切换回用户态后，可以继续执行其余的指令。
    

总结起来，当操作系统从用户态切换到内核态时，它完成了上下文切换、特权级的变更，执行内核代码来处理请求或事件，并在完成后将控制权返回给用户进程，使其能够继续执行。这种切换允许操作系统执行与特权操作相关的任务，并确保操作系统能够管理和保护系统资源。

# 空struct有什么用
空结构体 struct{} 实例不占据任何的内存空间。
### 实现集合(Set)
### 仅包含方法的结构体
### 不发送数据的信道(channel)


# 实现一个函数，将给定数组中的所有0移动到数组的末尾，同时保持其他元素的顺序不变。使用golang来实现
input [1,0,1] output:[11,0]
```go
func moveZerosToEnd(nums []int) {
    n := len(nums)
    if n <= 1 {
        return
    }

    left := 0
    right := 0

    for right < n {
        if nums[right] != 0 {
            nums[left] = nums[right]
            left++
        }
        right++
    }

    for left < n {
        nums[left] = 0
        left++
    }
}

```

# 判断括号是否完整，“)()” =>false "()"=> true
```go
func isRegularString(input string) bool {
	stack := make([]rune, 0)

	for _, char := range input {
		if char == '(' {
			stack = append(stack, char)
		} else if char == ')' {
			if len(stack) == 0 {
				return false
			}
			stack = stack[:len(stack)-1]
		}
	}

	return len(stack) == 0
}

```

# 什么是大端序和小端序，为什么要有字节序？
### 什么是字节序

**字节序**，又称**端序**或**尾序**（英语中用单词：**Endianness** 表示），在计算机领域中，指[电脑内存](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%25AD%2598%25E5%2582%25A8%25E5%2599%25A8)中或在数字通信链路中，占用多个字节的数据的字节排列顺序。

在几乎所有的平台上，多字节对象都被存储为连续的字节序列。例如在 Go 语言中，一个类型为`int`的变量`x`地址为`0x100`，那么其指针`&x`的值为`0x100`。且`x`的四个字节将被存储在内存的`0x100, 0x101, 0x102, 0x103`位置。

字节的排列方式有两个通用规则:

- 大端序（Big-Endian）将数据的低位字节存放在内存的高位地址，高位字节存放在低位地址。这种排列方式与数据用字节表示时的书写顺序一致，符合人类的阅读习惯。
- 小端序（Little-Endian），将一个多位数的低位放在较小的地址处，高位放在较大的地址处，则称**小端序**。小端序与人类的阅读习惯相反，但更符合计算机读取内存的方式，因为CPU读取内存中的数据时，是从低地址向高地址方向进行读取的。
### 为何要有字节序

很多人会问，为什么会有字节序，统一用大端序不行吗？答案是，计算机电路先处理低位字节，效率比较高，因为计算都是从低位开始的。所以，**计算机的内部处理都是小端字节序。在计算机内部，小端序被广泛应用于现代 CPU 内部存储数据；而在其他场景，比如网络传输和文件存储则使用大端序**。

### Go语言对字节序的处理

Go 语言存储数据时的字节序依赖所在平台的 CPU，处理大小端序的代码位于 `encoding/binary` ,包中的全局变量`BigEndian`用于操作大端序数据，`LittleEndian`用于操作小端序数据，这两个变量所对应的数据类型都实现了`ByteOrder`接口。


# cgocall原理
### 原理概述: Go 调用 C

从 Go 调用 C 函数 f，cgo 生成的代码会调用 `runtime.cgocall(_cgo_Cfunc_f, frame)`, 其中 `_cgo_Cfunc_f` 为由 cgo 编写的并由 gcc 编译的函数。

`runtime.cgocall` 会调用 `entersyscall`，从而不会阻塞其他 goroutine 或垃圾回收器 而后调用 `runtime.asmcgocall(_cgo_Cfunc_f, frame)`。

`runtime.asmcgocall` 会切换到 m.g0 栈(操作系统分配的栈，因此能安全的在运行 gcc 编译的代码) 并调用 `_cgo_Cfunc_f(frame)`。 `_cgo_Cfunc_f` 获取了帧结构中的参数，调用了实际的 C 函数 f，在帧中记录其结果， 并返回到 `runtime.asmcgocall`。 在重新获得控制权后，`runtime.asmcgocall` 会切换回原来的 g (`m.curg`) 的执行栈 并返回 `runtime.cgocall`。 在重新获得控制权后，`runtime.cgocall` 会调用 `exitsyscall`，并阻塞，直到该 m 运行能够在不与 `$GOMAXPROCS` 限制冲突的情况下运行 Go 代码。

# golang的netpoll为什么要用边缘触发而不是水平触发
在 Golang 的 netpoll 中使用边缘触发（Edge-Triggered）而不是水平触发（Level-Triggered）的原因是为了提高性能和减少上下文切换。

边缘触发和水平触发是两种不同的事件触发模式：

1. 边缘触发：当文件描述符上的状态发生变化时，只会触发一次事件通知，而且只有在状态变化时才会触发，如果没有处理完整个状态变化，那么之后不会再次触发事件。
    
2. 水平触发：当文件描述符上的状态处于就绪状态时，会持续触发事件通知，只要状态保持就绪，事件就会不断触发。
    

Golang 的 netpoll 选择使用边缘触发，主要有以下几个原因：

1. 性能：边缘触发模式可以减少事件通知的次数，只在状态变化时触发一次事件。这样可以减少不必要的上下文切换和事件处理开销，提高整体性能。
    
2. 精确性：边缘触发模式在状态变化时才触发事件，能够提供更精确的事件通知。这样可以避免因为水平触发中的事件持续触发而导致事件处理延迟或重复处理的情况。
    
3. 避免阻塞：使用边缘触发模式可以避免应用程序因为事件没有完全处理而一直阻塞在事件循环中。只有在状态变化时才会触发事件通知，应用程序可以处理完当前状态变化的事件后再继续处理其他任务。
    

需要注意的是，边缘触发模式需要确保在每次事件通知后完全处理当前的状态变化，否则可能会导致事件丢失或延迟处理的问题。因此，在使用 netpoll 进行编程时，需要确保能够高效地处理每个事件，以避免性能和功能上的问题。

# ca证书从哪里获取
客户端的话会内置**根证书一般内置在客户端（浏览器或操作系统）中**

证书的签发过程
服务方 S 向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证；
CA 通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等；
如信息审核通过，CA 会向申请者签发认证文件-证书。
证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA 的信息、有效时间、证书序列号等信息的明文，同时包含一个签名（指纹）；
签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA 的私钥对信息摘要进行加密，密文即签名；

# 为什么不用mysql缓存
**7.1. 优点**Query Cache的查询，发生在MySQL接收到客户端的查询请求、查询权限验证之后和查询SQL解析之前。也就是说，当MySQL接收到客户端的查询SQL之后，仅仅只需要对其进行相应的权限验证之后，就会通过Query Cache来查找结果，甚至都不需要经过Optimizer模块进行执行计划的分析优化，更不需要发生任何存储引擎的交互。由于Query Cache是基于内存的，直接从内存中返回相应的查询结果，因此减少了大量的磁盘I/O和CPU计算，导致效率非常高。

**7.2. 缺点**Query Cache的优点很明显，但是也不能忽略它所带来的一些缺点：

- 查询语句的hash计算和hash查找带来的资源消耗。如果将query_cache_type设置为1（也就是ON），那么MySQL会对每条接收到的SELECT类型的查询进行hash计算，然后查找这个查询的缓存结果是否存在。虽然hash计算和查找的效率已经足够高了，一条查询语句所带来的开销可以忽略，但一旦涉及到高并发，有成千上万条查询语句时，hash计算和查找所带来的开销就必须重视了。
- Query Cache的失效问题。如果表的变更比较频繁，则会造成Query Cache的失效率非常高。表的变更不仅仅指表中的数据发生变化，还包括表结构或者索引的任何变化。（任何一行数据的变更都会让表所有的缓存失效）
- 查询语句不同，但查询结果相同的查询都会被缓存，这样便会造成内存资源的过度消耗。查询语句的字符大小写、空格或者注释的不同，Query Cache都会认为是不同的查询（因为他们的hash值会不同）。
- 相关系统变量设置不合理会造成大量的内存碎片，这样便会导致Query Cache频繁清理内存。

# 给定一个正整数数组 arr，求 arr[i] / arr[j] 的最大值，其中 i < j
```go
func MaxDivision1(arr []int) float64 {  
   if len(arr) < 2 {  
      return 0  
   }  
  
   maxResult := float64(arr[0]) / float64(arr[1])  
   maxVal := arr[0]  
  
   for j := 1; j < len(arr); j++ {  
      maxResult = math.Max(maxResult, float64(maxVal)/float64(arr[j]))  
      maxVal = max(maxVal, arr[j])  
   }  
  
   return maxResult  
}
```

# 在linux环境下查看 TCP 连接状态需要用什么命令？
  
在 Linux 环境下，可以使用 `netstat` 或 `ss` 命令来查看 TCP 连接状态。这两个命令都提供了用于显示网络连接和套接字信息的功能。
使用 `netstat` 命令来查看 TCP 连接状态：
Copy code
`netstat -nt`
上述命令会显示当前的 TCP 连接状态信息，包括本地地址、远程地址、连接状态等。
使用 `ss` 命令来查看 TCP 连接状态：
Copy code
`ss -t`
上述命令会显示当前的 TCP 连接状态信息，包括本地地址、远程地址、连接状态等。
这些命令通常需要在具有足够权限的终端或以 root 身份运行。请注意，命令的输出结果可能会很长，你可以结合其他选项来过滤或限制输出内容，例如使用 grep 命令进行过滤。
示例：
perlCopy code
`netstat -nt | grep ESTABLISHED`
上述命令会过滤显示仅处于 "ESTABLISHED" 连接状态的 TCP 连接。
perlCopy code
`ss -t state established`
上述命令会显示仅处于 "ESTABLISHED" 连接状态的 TCP 连接。
请注意，具体命令的使用可能因 Linux 发行版和版本的不同而略有差异，请根据你的环境选择适当的命令。

# 出现大量time_wait的话应用层有什么优化方案？
可以跟golang的http库一样使用连接池

# 缓存同步方案
首先我们是无法保证同一个操作序列是能够完全重放的了

前提是：我们有一个单分片的kafka ，无法实现按消息键分发
结果是：我们需要将binlog分成几大类，例如商品基础信息，库存，上下架，销售价，成本价这几大类来输出这些处理过的消息，然后下游就会使其他兄弟项目，以及redis项目，es项目来获取这些消息来进行处理

过程是：我们会使用多协程来处理kafka的消息，经过简单处理，划分类型后，按照商品id，skuid 通过hash后分发到不同的zset集合中，通过offset来排序，提交到redis后就提交offset

然后会有另外的程序通过多协程来定时拉取这些数据，按照一定的数据来拉取后再进行去重，如果是同个商品有多个类型的话就发送商品基础数据出去，然后下游就可以通过这些数据来进行批量的消费了。

至于补偿逻辑：会通过数据库获取最近一分钟之外，十几分钟之内的变更记录，来进行商品全量数据的跟上面逻辑一样的推送。

为什么要补偿？
因为除了redis会宕机之外，还有就是别人操作数据库的操作，是进行业务处理的时候想不到的，无法推测用户会怎么操作数据库产生出这个binlog的，比如还没有商品，就已经有商品属性了之类的。


1.  raft 中大多数节点提交某条日志后，未包含该日志的某个节点能成为 leader 吗？
是有可能成为leader的，但是如果要求选举的时候，其他人的任期跟你一致的话，是会判断index是否比我高的，不比我高就不投票。


2.  raft 论文中 peer 启动的时候是 follower，可以是 candidate 吗？
follower状态，一般情况下，宕机都是比较少见的，所以不要频繁选举。

1.  raft 如何避免惊群效应？
raft会通过prevote来判断当前集群状态是否有可能选举成功的可能性。

在 Raft 中，惊群效应（Herding Effect）指的是当 Leader 节点出现故障或不可用时，多个 Follower 节点同时检测到这一情况并开始发起选举的现象。这种情况下，多个节点几乎同时成为候选者并尝试成为新的 Leader，导致频繁的选举活动和网络通信开销的增加。

当多个节点同时发起选举时，会产生以下问题：

1. 网络负载增加：由于多个节点同时进行选举，会导致大量的选举请求和响应在网络中传输，增加了网络负载。
    
2. 选举冲突和延迟：由于多个节点同时竞选 Leader，可能会导致选举冲突，延长选举过程的时间。
    
3. 资源浪费：在频繁的选举过程中，节点需要进行大量的计算和通信操作，导致资源的浪费和系统性能的下降。
    

为了解决惊群效应，Raft 使用了随机化选举超时时间来引入一定的随机性。每个节点在成为 Follower 后会启动一个定时器，定时器的超时时间是一个随机的时间段。当超时时间到达时，节点会转变为候选者并发起选举。通过引入随机化的超时时间，节点在不同的时间点启动选举，减少了多个节点同时发起选举的概率，从而降低了惊群效应的影响。

随机化选举超时时间使得选举过程在时间上分散开来，减少了选举的竞争和冲突。同时，Raft 协议还通过优雅退化的机制，即在发起选举的节点发现存在更高任期的节点时立即放弃选举，进一步避免了不必要的选举竞争。

综上所述，惊群效应是指多个节点同时发起选举的现象，通过随机化选举超时时间和优雅退化机制，Raft 协议能够有效降低惊群效应的影响，保证选举的稳定性和性能。

2.  tcp 序号的含义和初始值？是否随机？
在 TCP 协议中，序号（Sequence Number）用于标识 TCP 报文段的字节流顺序。每个 TCP 报文段都有一个序号字段，用于确定报文段在整个字节流中的位置。

序号的初始值是由 TCP 连接的建立阶段确定的，一般情况下是随机选择一个初始序号。在 TCP 连接建立时，通信双方会交换初始序号（ISN，Initial Sequence Number），并根据一定的算法生成一个初始序号。

初始序号的选择很重要，它需要满足以下要求：

1. 唯一性：初始序号必须在一个 TCP 连接中是唯一的，以确保不会与其他连接的序号冲突。
    
2. 随机性：初始序号需要具备一定的随机性，以防止攻击者通过猜测序号来进行恶意操作。
    
3. 可预测性：初始序号应该是可预测的，以便接收方能够正确地验证和处理接收到的报文段。
    

具体的初始序号选择算法可以因实现而异，常见的算法包括使用当前时间戳、随机数生成器或特定的算法函数来生成初始序号。

需要注意的是，序号不是随机递增的，而是按照字节流顺序递增的。每发送一个字节的数据，序号就会递增一次。序号字段的大小为 32 位，因此序号值的范围是 0 到 2^32-1。

总结起来，TCP 序号用于标识报文段的字节流顺序，初始序号是在 TCP 连接建立阶段确定的，一般是随机选择的，并根据一定的算法生成。序号值随着发送的字节递增，范围是 0 到 2^32-1。

1.  socket 编程的几个源语？
在网络编程中，常用的几个基本的 Socket 编程的源语包括：

1. socket()：用于创建一个新的套接字。它接受三个参数：地址族（Address Family），套接字类型（Socket Type）和协议（Protocol）。该函数返回一个文件描述符，用于后续的套接字操作。
    
2. bind()：将一个套接字绑定到一个特定的地址和端口号。它接受一个套接字文件描述符和一个指向 sockaddr 结构体的指针，该结构体包含要绑定的地址信息。
    
3. listen()：将套接字设置为监听状态，等待连接请求。它接受一个套接字文件描述符和一个表示等待连接的队列大小。
    
4. accept()：接受客户端的连接请求，创建一个新的套接字用于与客户端进行通信。它接受一个套接字文件描述符和一个指向 sockaddr 结构体的指针，用于存储客户端的地址信息。
    
5. connect()：与远程服务器建立连接。它接受一个套接字文件描述符和一个指向 sockaddr 结构体的指针，包含要连接的服务器的地址信息。
    
6. send()：向已连接的套接字发送数据。它接受一个套接字文件描述符、一个指向要发送数据的缓冲区和数据的长度。
    
7. recv()：从已连接的套接字接收数据。它接受一个套接字文件描述符、一个指向接收数据的缓冲区和要接收的数据的最大长度。
    
8. close()：关闭套接字连接。它接受一个套接字文件描述符，释放相关的资源。
    

这些是常见的 Socket 编程的源语，用于创建、绑定、监听、连接、发送和接收数据以及关闭套接字连接。在实际的网络编程中，这些源语会根据具体的需求和协议进行灵活的使用

4.  文件系统 open 函数执行时，背后从上层到底层发生了什么？
当调用文件系统的 `open` 函数时，背后会从上层到底层执行以下步骤：

1. 应用程序调用 `open` 函数：应用程序通过系统调用调用 `open` 函数，并传递文件名和打开模式等参数。
    
2. 用户空间到内核空间切换：系统调用触发用户空间到内核空间的切换，将控制权交给操作系统内核。
    
3. 内核进行文件路径解析：内核根据文件名参数进行路径解析，查找文件在文件系统中的位置。这可能涉及到查找目录、权限验证和符号链接解析等操作。
    
4. 文件描述符分配：内核为打开的文件分配一个文件描述符（file descriptor），它是一个整数，用于标识文件在内核中的打开实例。文件描述符在应用程序中用于后续的文件操作。
    
5. 文件打开和权限检查：内核根据打开模式（如读、写、追加等）和文件权限检查，验证应用程序是否有足够的权限打开文件。
    
6. 文件对象创建：内核为文件创建一个文件对象，其中包含有关文件的元数据（如文件大小、访问权限、时间戳等）和文件操作相关的数据结构。
    
7. 文件描述符与文件对象关联：将文件描述符与文件对象关联起来，以便应用程序可以通过文件描述符访问文件对象。
    
8. 文件打开完成：内核将文件描述符返回给应用程序，表明文件打开操作已完成。
    

在文件打开之后，应用程序可以使用文件描述符进行读取、写入、定位和关闭等文件操作，这些操作通过系统调用和内核的支持来完成。具体的操作过程和涉及的内核功能会根据操作系统和文件系统的实现而有所不同。

1.  虚拟内存的设计有什么好处？
虚拟内存的设计带来了许多好处，包括：

1. 内存扩展：虚拟内存允许应用程序访问超出物理内存容量的地址空间。它将物理内存与辅助存储设备（如硬盘）结合使用，将不常用的数据存储在磁盘上，从而扩展了可用内存的大小。这使得应用程序可以处理比物理内存更大的数据集。
2. 内存隔离：虚拟内存为每个应用程序提供了独立的地址空间，使得不同应用程序之间的内存彼此隔离。这样，每个应用程序就可以在自己的地址空间中运行，而不会干扰其他应用程序的内存操作。这提高了系统的安全性和稳定性。
3. 内存共享：虚拟内存允许多个进程共享同一段内存区域。这对于需要在多个进程之间共享数据或共享代码的应用程序非常有用。通过内存共享，可以减少复制数据的开销，提高系统的性能和资源利用率。
4. 内存映射：虚拟内存通过内存映射技术，将文件映射到进程的地址空间中，使得文件可以像内存一样被访问。这样，应用程序可以通过简单的内存访问操作来读取和写入文件，而无需进行繁琐的文件操作。这简化了文件访问的编程方式。
5. 页面置换：虚拟内存通过页面置换算法，将内存中不常用的页面（或称为虚拟页）置换到磁盘上，从而释放内存空间给其他需要的页面使用。这使得系统可以在有限的物理内存下运行更多的应用程序，并根据应用程序的需求进行动态调整。
总体而言，虚拟内存的设计提供了更大的地址空间、内存隔离、内存共享、文件映射和页面置换等功能，使得系统可以更高效地管理和利用内存资源，提高系统的性能、安全性和可用性。

1.  mmap 共享内存是否破坏了进程间的隔离性？
在使用 `mmap` 进行共享内存时，确实会破坏进程间的隔离性。共享内存允许多个进程将同一块内存映射到它们各自的地址空间中，使得它们可以直接访问相同的物理内存区域。这意味着一个进程对共享内存的修改会立即反映到其他进程中，从而打破了进程间的隔离性。

由于共享内存是直接映射到进程的地址空间中，因此进程可以直接读写共享内存的数据，无需通过其他的进程间通信机制。这种直接的访问方式可能导致进程之间发生竞争条件和数据一致性问题，需要进行适当的同步和互斥控制来确保数据的一致性和正确性。

因此，当使用共享内存时，必须小心处理进程间的同步和互斥问题，以确保多个进程正确地访问和修改共享内存的数据。同时，对于共享内存的使用需要谨慎，确保只有需要访问和修改共享数据的进程才能够获得相应的权限，以保持进程间的隔离性和安全性。

# 给定 n 个不同元素的数组，设计算法等概率取 m 个不同的元素
```go

func selectRandomElements(arr []int, m int) []int {
	rand.Seed(time.Now().UnixNano())

	// 创建结果数组
	result := make([]int, m)

	// 将前m个元素直接放入结果数组中
	for i := 0; i < m; i++ {
		result[i] = arr[i]
	}

	// 使用Fisher-Yates算法从剩余的元素中随机选择m个元素
	for i := m; i < len(arr); i++ {
		j := rand.Intn(i + 1)
		if j < m {
			result[j] = arr[i]
		}
	}

	return result
}

```
整数数组的前m个直接存下来。
用一个计数器保存当前正在处理的请求是第几个，比如n
对于从m+1开始的新请求，以m/n的概率选择保存，并同从已保存的m个请求中随机选出的一个进行交换。
细说就是，

对于第m+1个请求，以m/(m+1)的概率选择留下，如果留下了则从已保存的m个请求中随机选出一个，同它交换;
对于第m+2个请求，以m/(m+2)的概率选择留下，如果留下了则从已保存的m个请求中随机选出一个，同它交换;
对于第m+3个请求，以m/(m+3)的概率选择留下，如果留下了则从已保存的m个请求中随机选出一个，同它交换;
…

对于第n个请求，以m/n的概率选择留下，如果留下了则从已保存的m个请求中随机选出一个，同它交换

# 如果做一个翻译服务，翻译能力来自于供应商，如何从技术上对几家（A、B、C）供应商作出评估？
如果几家都要接入，且各家之间的翻译能力都各有优劣，那应该如何去搭建这个服务的框架？

  
从技术角度对几家供应商进行评估时，可以考虑以下几个关键因素：

1. 接口和数据格式：评估供应商的翻译服务接口和数据格式是否符合你的需求。检查供应商是否提供标准化的API接口，并且与你的系统可以无缝集成。
    
2. 翻译质量：评估供应商的翻译质量如何。可以通过测试一些典型的翻译案例来评估翻译准确性、流畅性以及对特定领域的理解程度。
    
3. 支持的语言：评估供应商能够提供的语言覆盖范围是否满足你的需求。确保供应商能够支持你所需要的所有语言翻译。
    
4. 响应时间和性能：评估供应商的响应时间和性能表现。检查供应商是否能够在合理的时间范围内返回翻译结果，并且能够处理你的预期的并发请求量。
    
5. 可用性和稳定性：评估供应商的服务可用性和稳定性。检查供应商的系统是否具备高可用性，是否有相应的故障恢复机制，以及是否有监控和报警系统来及时发现和处理问题。
    
6. 安全性和隐私保护：评估供应商对数据的安全性和隐私保护措施。确保供应商能够提供安全的数据传输和存储，并且符合你所在地区的数据隐私法规要求。
    

在搭建翻译服务的框架时，可以考虑以下方案：

1. 多供应商接入：同时接入多家供应商，可以利用每个供应商的优势，提高翻译的覆盖范围和质量。可以通过配置文件或者动态路由的方式进行供应商选择。
    
2. 负载均衡和容错机制：使用负载均衡和容错机制来平衡请求的分发和处理。可以采用负载均衡算法，如轮询或随机选择供应商进行请求转发，以及引入故障转移和容错机制，确保服务的稳定性和可靠性。
    
3. 异步处理和并发控制：对于大量的翻译请求，可以采用异步处理方式，通过消息队列或任务队列来进行处理。同时，需要控制并发请求量，避免对供应商的过度请求造成性能问题或限制。
    
4. 缓存和结果缓存：针对相同的翻译请求，可以考虑引入缓存机制，将翻译结果缓存起来，避免重复的请求和减少对供应商的依赖。可以使用内存缓存或分布式缓存来提高响应速度和降低对供应商的请求量。
    
5. 异常处理和监控：对供应商的请求过程中出现的异常情况，需要进行适当的异常处理和错误恢复机制。同时，建立监控系统来实时监测供应商的性能指标和服务状态，及时发现和处理问题。
    

以上只是一些基本的框架设计考虑，具体的实现方式和架构会根据具体需求和情况而有所不同。

# # i++在两个线程分别执行100次，最大值和最小值分别多少
`线程A 拿了个``0``，放在手里，等线程B计算到最后一步，写入i，i变成了``1``。`

`此时线程B拿到这个``1``，一直等到线程A计算完，线程B再完成计算，i变成``2``。`

`为什么不能更小呢?比如i =` `1``.`

`因为必须要两次覆盖才能最小。线程A和线程B一直都在使i变大。i变小的唯一途径就是被另外一个线程覆盖。`

`所以要想线程A的值变小，线程B必须覆盖一次A，线程B的值要想变小就必须被线程A覆盖一次。`

`覆盖意味着什么？`

`覆盖意味着i++，拿到i，i加``1``，然后写回。`

`两次覆盖就加两次。所以i最小为``2``.`

最大值就是200

# 操作系统有任务管理器，管理任务的执行，任务之间存在依赖关系，写一个算法判断是否存在任务的循环依赖？
```go
package main

type Task struct {
	ID          int
	Dependencies []int
}

func isCircularDependency(tasks []*Task, taskID int, visited map[int]bool, stack map[int]bool) bool {
	visited[taskID] = true
	stack[taskID] = true

	for _, dependencyID := range tasks[taskID].Dependencies {
		if !visited[dependencyID] && isCircularDependency(tasks, dependencyID, visited, stack) {
			return true
		} else if stack[dependencyID] {
			return true
		}
	}

	stack[taskID] = false
	return false
}

func hasCircularDependency(tasks []*Task) bool {
	visited := make(map[int]bool)
	stack := make(map[int]bool)

	for _, task := range tasks {
		if !visited[task.ID] && isCircularDependency(tasks, task.ID, visited, stack) {
			return true
		}
	}

	return false
}

func main() {
	// 示例任务列表
	tasks := []*Task{
		{ID: 1, Dependencies: []int{2, 3}},
		{ID: 2, Dependencies: []int{3}},
		{ID: 3, Dependencies: []int{4}},
		{ID: 4, Dependencies: []int{1}},
	}

	if hasCircularDependency(tasks) {
		println("存在任务的循环依赖")
	} else {
		println("不存在任务的循环依赖")
	}
}

```
这个算法通过深度优先搜索（DFS）的方式遍历任务的依赖关系图。它使用两个辅助数据结构 `visited` 和 `stack`，其中 `visited` 用于跟踪已经访问过的任务，`stack` 用于检测当前路径上的循环依赖。

在 `isCircularDependency` 函数中，首先将当前任务标记为已访问并加入到 `stack` 中。然后对当前任务的所有依赖进行递归检查，如果依赖任务未被访问过且存在循环依赖，则返回 `true`。如果依赖任务在当前路径上已经存在于 `stack` 中，则说明存在循环依赖，也返回 `true`。最后，将当前任务从 `stack` 中移除，并返回 `false`。

在 `hasCircularDependency` 函数中，对每个任务进行检查，如果存在循环依赖则返回 `true`，否则返回 `false`。

根据示例任务列表的定义，存在任务的循环依赖，因此程序将输出 "存在任务的循环依赖"。你可以根据需要修改任务列表的定义，测试不同的依赖关系。

# 是否了解二叉排序树？左子树比根小，右子树比根大，如何移除一个二叉排序树的节点？
移除一个二叉排序树的节点需要考虑以下几种情况：

1. 要删除的节点没有子节点：这是最简单的情况，直接将父节点指向该节点的指针置为空即可。
    
2. 要删除的节点只有一个子节点：将父节点指向该节点的指针指向该节点的子节点即可。
    
3. 要删除的节点有两个子节点：这是最复杂的情况。我们需要找到该节点的中序遍历的后继节点或前驱节点来替代它。后继节点是比该节点大的最小节点，前驱节点是比该节点小的最大节点。可以选择使用后继节点或前驱节点替代被删除节点，这样仍然能够保持二叉排序树的性质。找到后继节点或前驱节点后，将其值复制到要删除的节点，然后递归删除后继节点或前驱节点。



# 一副扑克牌中随机取 5 张，取到顺子的概率是多少？
Hint 1：一种花色有多少种顺子？9 种
Hint 2：一个顺子有 5 张牌，有多少种组合可能？9 * 4 ^ 5 种(对于这个问题，我们可以先考虑在没有大小王的情况下，我们抽取的概率是多少。没有大小王即总共有52张牌，因此抽取5张牌的组合数有 (52,5). 既然要成为顺子，那么顺子必须为1-5，2-6，...，9-13等，故只有9种顺子，但是对于每张牌都有4个花色，故成为顺子的个数总共有 9 * 4^5种。)
Hint 3：分子已经知道了，分母怎么表示，n 张取 m 张怎么表示？(52,5)

```java
#### [122. 买卖股票的最佳时机 II](https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii/)

难度中等

2151

给你一个整数数组 `prices` ，其中 `prices[i]` 表示某支股票第 `i` 天的价格。

在每一天，你可以决定是否购买和/或出售股票。你在任何时候 **最多** 只能持有 **一股** 股票。你也可以先购买，然后在 **同一天** 出售。

返回 _你能获得的 **最大** 利润_ 。

**示例 1：**

**输入：**prices = [7,1,5,3,6,4]
**输出：**7
**解释：**在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。
     随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6 - 3 = 3 。
     总利润为 4 + 3 = 7 。

**示例 2：**

**输入：**prices = [1,2,3,4,5]
**输出：**4
**解释：**在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。
     总利润为 4 。

**示例 3：**

**输入：**prices = [7,6,4,3,1]
**输出：**0
**解释：**在这种情况下, 交易无法获得正利润，所以不参与交易可以获得最大利润，最大利润为 0 。
```
```go
func maxProfit(prices []int) int {
    n := len(prices)
    dp := make([][2]int, n)
    dp[0][1] = -prices[0]
    for i := 1; i < n; i++ {
        dp[i][0] = max(dp[i-1][0], dp[i-1][1]+prices[i])
        dp[i][1] = max(dp[i-1][1], dp[i-1][0]-prices[i])
    }
    return dp[n-1][0]
}

func max(a, b int) int {
    if a > b {
        return a
    }
    return b
}
func maxProfit(prices []int) (ans int) {
    for i := 1; i < len(prices); i++ {
        ans += max(0, prices[i]-prices[i-1])
    }
    return
}

```
# 归并排序
```go
func mergeSort(s []int) []int {  
	n := len(s)  
	if n == 1 {  
		return s  
	}  
	m := n / 2  
	lefts := mergeSort(s[:m])  
	rights := mergeSort(s[m:])  
	return merge(lefts, rights)  
}  
func merge(l []int, r []int) []int {  
	lLen := len(l)  
	rLen := len(r)  
	res := make([]int, 0)  
  
	lIndex, rIndex := 0, 0 //两个切片的下标，插入一个数据，下标加一  
	for lIndex < lLen && rIndex < rLen {  
		if l[lIndex] > r[rIndex] {  
			res = append(res, r[rIndex])  
			rIndex++  
		} else {  
			res = append(res, l[lIndex])  
			lIndex++  
		}  
	}  
	if lIndex < lLen {  
		res = append(res, l[lIndex:]...)  
	}  
	if rIndex < rLen {  
		res = append(res, r[rIndex:]...)  
	}  
return res  
}
```


# 服务端发送RST包的原因有哪些
1、连接重置：当服务端主动关闭连接的时候，它会发送rst
2、收到非法数据包，当服务器收到一个不符合协议规则的数据包的时候，会发送rst包
3、防火墙规则：服务器的防火墙规则可能会拦截特定的数据包，并发送rst
4、连接拒绝，当服务器拒绝客户端的连接请求的时候，可能会发送rst

# 浏览器获取服务器CA证书与认证流程-HTTPS
证书的签发过程
服务方 S 向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证；
CA 通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等；
如信息审核通过，CA 会向申请者签发认证文件-证书。
证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA 的信息、有效时间、证书序列号等信息的明文，同时包含一个签名（指纹）；
签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA 的私钥对信息摘要进行加密，密文即签名；

浏览器获取服务端CA证书与证书验证流程
客户端 C 向服务器 S 发出https请求时，S 返回证书文件到客户端；
客户端首先在本地电脑寻找是否有这个服务器证书上的ca机构的根证书。如果有继续下一步，如果没有弹出警告，认为证书是非法的。
客户端会内置信任CA的证书信息，包括CA的公钥。
客户端C使用CA机构根证书的公钥对服务器证书的签名和签名算法（散列函数）进行解密，得到摘要（签名解密后就是摘要）和散列函数。
客户端 C 读取证书中的相关的明文信息，采用得到的散列函数计算得到信息摘要，对比得到的摘要和自己计算出的摘要是否一致，如果一致，则可以确认证书的合法性，即服务器的公钥合法；
客户端然后验证证书相关的域名信息、有效时间等信息；
在这个过程注意几点：

申请证书不需要提供私钥，确保私钥永远只能服务器掌握；
证书的合法性仍然依赖于非对称加密算法，证书主要是增加了服务器信息以及签名；
3.客户端内置 CA 对应的证书称为根证书，颁发者和使用者相同，自己为自己签名，即自签名证书；
HTTPS的通信过程

客户端发送请求到服务器端；
服务器端返回证书和公开密钥，公开密钥作为证书的一部分而存在；
客户端验证证书和公开密钥的有效性，如果有效，则生成共享密钥并使用公开密钥加密发送到服务器端；
服务器端使用私有密钥解密数据，并使用收到的共享密钥加密数据，发送到客户端；
客户端使用共享密钥解密数据；
SSL加密建立………
特定
非对称加密相比对称加密更加安全；
非对称加密算法对加密内容的长度有限制；
CA数字证书作用之一是公钥分发；
数字签名的签发过程是私钥加密，公钥解密；

## 什么是线性结构和非线性结构
数据结构可以分为2大类：**线性结构与非线性结构**。
### 一、线性结构
线性结构是最常用的数据结构，而其常见的形式有：数组、队列、链表和栈。
线性结构的特点就是：数据元素之间存在着一对一的线性关系。比如说：
有一个数组`a = [1, 3, 2, 5, 6]`，于是`a[3] = 5`，当数组下标为3的时候，就有一个对应的值是5。
同理，`a[1] = 3`，也是这样`1对1`的关系。
而在线性结构中，又存在2种不同的存储结构：**顺序存储结构、链式存储结构**。
- 顺序存储结构：
- 顺序存储结构的线性表称为顺序表，它的存储元素是连续的(内存地址连续，比如数组)。  
    
- 链式存储结构：  
    链式存储结构的线性表称为链表，它的存储元素不一定是连续的，元素节点中存放数据元素以及相邻元素的地址信息，
比如，单链表、双向链表。因为地址不连续，所以可以利用碎片内存。
### 二、非线性结构
与线性结构相反，非线性结构就不是1对1的关系了。它包括：二维数组、多维数组、广义表、树结构、图结构。
数组相对来说还算比较简单，但是在应用中，**树结构跟图结构**算是用的最多的。
单从树结构与图结构，就可以延伸出很多算法。

## 1. Docker 容器停止过程

对于容器来说，`init` 系统不是必须的，当你通过命令 `docker stop mycontainer` 来停止容器时，docker CLI 会将 `TERM` 信号发送给 mycontainer 的 `PID` 为 1 的进程。

-   **如果 PID 1 是 init 进程** - 那么 PID 1 会将 TERM 信号转发给子进程，然后子进程开始关闭，最后容器终止。
-   **如果没有 init 进程** - 那么容器中的应用进程（Dockerfile 中的 `ENTRYPOINT` 或 `CMD` 指定的应用）就是 PID 1，应用进程直接负责响应 `TERM` 信号。这时又分为两种情况：
    -   **应用不处理 SIGTERM** - 如果应用没有监听 `SIGTERM` 信号，或者应用中没有实现处理 `SIGTERM` 信号的逻辑，应用就不会停止，容器也不会终止。
    -   **容器停止时间很长** - 运行命令 `docker stop mycontainer` 之后，Docker 会等待 `10s`，如果 `10s` 后容器还没有终止，Docker 就会绕过容器应用直接向内核发送 `SIGKILL`，内核会强行杀死应用，从而终止容器。

## 题目列表
背嵬:
1143

背嵬:
583

背嵬:
279
背嵬:
### 26、简述Kubernetes deployment升级过程

-   初始创建Deployment时，系统创建了一个ReplicaSet，并按用户的需求创建了对应数量的Pod副本。
-   当更新Deployment时，系统创建了一个新的ReplicaSet，并将其副本数量扩展到1，然后将旧ReplicaSet缩减为2。
-   之后，系统继续按照相同的更新策略对新旧两个ReplicaSet进行逐个调整。
-   最后，新的ReplicaSet运行了对应个新版本Pod副本，旧的ReplicaSet副本数量则缩减为0。

背嵬:
### 27、简述Kubernetes deployment升级策略

在Deployment的定义中，可以通过spec.strategy指定Pod更新的策略，目前支持两种策略：Recreate（重建）和RollingUpdate（滚动更新），默认值为RollingUpdate。

-   Recreate：设置spec.strategy.type=Recreate，表示Deployment在更新Pod时，会先杀掉所有正在运行的Pod，然后创建新的Pod。
-   RollingUpdate：设置spec.strategy.type=RollingUpdate，表示Deployment会以滚动更新的方式来逐个更新Pod。同时，可以通过设置spec.strategy.rollingUpdate下的两个参数（maxUnavailable和maxSurge）来控制滚动更新的过程。

背嵬:
31、简述Kubernetes Service分发后端的策略

Service负载分发的策略有：RoundRobin和SessionAffinity

-   RoundRobin：默认为轮询模式，即轮询将请求转发到后端的各个Pod上。
-   SessionAffinity：基于客户端IP地址进行会话保持的模式，即第1次将某个客户端发起的请求转发到后端的某个Pod上，之后从相同的客户端发起的请求都将被转发到后端相同的Pod上。

背嵬:
37、简述Kubernetes各模块如何与API Server通信

Kubernetes API Server作为集群的核心，负责集群各功能模块之间的通信。集群内的各个功能模块通过API Server将信息存入etcd，当需要获取和操作这些数据时，则通过API Server提供的REST接口（用GET、LIST或WATCH方法）来实现，从而实现各模块之间的信息交互。

如kubelet进程与API Server的交互：每个Node上的kubelet每隔一个时间周期，就会调用一次API Server的REST接口报告自身状态，API Server在接收到这些信息后，会将节点状态信息更新到etcd中。

如kube-controller-manager进程与API Server的交互：kube-controller-manager中的Node Controller模块通过API Server提供的Watch接口实时监控Node的信息，并做相应处理。

如kube-scheduler进程与API Server的交互：Scheduler通过API Server的Watch接口监听到新建Pod副本的信息后，会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑，在调度成功后将Pod绑定到目标节点上。

背嵬:
  39、简述Kubernetes Scheduler使用哪两种算法将Pod绑定到worker节点

Kubernetes Scheduler根据如下两种调度算法将 Pod 绑定到最合适的工作节点：

-   预选（Predicates）：输入是所有节点，输出是满足预选条件的节点。kube-scheduler根据预选策略过滤掉不满足策略的Nodes。如果某节点的资源不足或者不满足预选策略的条件则无法通过预选。如“Node的label必须与Pod的Selector一致”。
-   优选（Priorities）：输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的Nodes进行打分排名，选择得分最高的Node。例如，资源越富裕、负载越小的Node可能具有越高的排名。

背嵬:
 49、简述Kubernetes网络模型

Kubernetes网络模型中每个Pod都拥有一个独立的IP地址，并假定所有Pod都在一个可以直接连通的、扁平的网络空间中。所以不管它们是否运行在同一个Node（宿主机）中，都要求它们可以直接通过对方的IP进行访问。设计这个原则的原因是，用户不需要额外考虑如何建立Pod之间的连接，也不需要考虑如何将容器端口映射到主机端口等问题。

同时为每个Pod都设置一个IP地址的模型使得同一个Pod内的不同容器会共享同一个网络命名空间，也就是同一个Linux网络协议栈。这就意味着同一个Pod内的容器可以通过localhost来连接对方的端口。

在Kubernetes的集群里，IP是以Pod为单位进行分配的。一个Pod内部的所有容器共享一个网络堆栈（相当于一个网络命名空间，它们的IP地址、网络设备、配置等都是共享的）。

背嵬:
K8s 的核心是 API 而非容器：从理论到 CRD 实践
kubectl 创建 Pod 背后到底发生了什么

背嵬:
416，518，322
162,712,279，剑指 Offer 26. 树的子结构，！！！

# 1. 1.  设计一个线程安全的 LRU和LFU。


提供短链服务的时候是否有支持 HTTP 缓存呢？
缓存机制是什么样子的呢？
HTTP 缓存除了通过超时时间来做，还有其他的机制吗？
多线程编程中线程安全怎么来保证呢？
刚刚谈到加锁，加锁的话一般有哪些类型呢？
读写锁有什么优点呢？
CAS 是什么样的机制？
开发过程中怎么避免死锁呢？
内存泄露和内存溢出有什么区别呢？
熟悉的排序算法有哪些？归并排序和快速排序还记得原理吗？
归并排序时间复杂度是什么？有什么样的优缺点呢？

9.  如何定位系统延迟的瓶颈？
10.  如何降低 GC 对主干流量的影响？
11.  多副本如何选主？
12.  多个副本写入如何保证一致性和可靠性？
13. 1.  golang：defer 的开销，如何进行优化？
14.  golang：runtime 是以什么形式存在？库还是二进制？
是以库的形式存在。


16. ###二、 介绍负载均衡算法

17.  介绍平滑负载均衡算法，实现
18.  当出现下游出现不可用，负载均衡算法怎么处理 
//todo

3.  mysql超时是什么引起的
没用到索引（sql问题或者统计数据散列情况有误），刷脏页。


