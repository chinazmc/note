# 七猫统计埋点实践

[Keeping](https://tech.qimao.com/author/wang/) 发表于 2021/06/02

**一、**概述****

**1.1 **数据过程****

大数据应用像一条工业流水线，它一般会有数据采集、数据加工、数据存储、数据计算及可视化这几个环节。数据采集，顾名思义采集相应的数据，是整个数据流的起点，采集的全不全、对不对，直接决定数据广度和质量，影响后续所有的环节。而埋点作为一种重要的采集手段，可以将用户行为信息转化为数据资产，为产品分析、业务决策、数据推荐、商业化应用等提供可靠的数据支持。

**1.2 **事件模型定义****

事件模型：谁（WHO）在什么时间（WHEN）在什么地点（WHERE）做了什么事情（WHAT）。

其中各元素代表的意义：

|   |   |
|---|---|
|**元素**|**意义**|
|WHO|设备标识符集合|
|WHEN|事件触发时间、接收时间等|
|WHERE|设备环境、网络环境、业务环境等|
|WHAT|事件、事件属性等|

例如：韩梅梅在2021-05-28 09:10:15分在WI-FI环境下启动了七猫免费小说。

其余的WHO、WHEN、WHERE都是通过客户端SDK统一的方式来定义和获取的，一次实现之后，少量优化和维护。而WHAT代表事件及属性，是跟业务使用紧密结合的，其质量的好坏，直接决定了后续数据系统的质量。

**二、**事件的定义****

事件定义包含事件ID和事件属性两个部分。

2.1 事件ID

事件ID以“页面_组件_展位_事件类型”四段式位置追踪规范组成唯一事件ID。

其中各元素代表的意义：

|   |   |
|---|---|
|**元素**|**意义**|
|页面|APP中一个独立的功能页面|
|组件|APP中某个页面下的一个功能模块区域|
|展位|APP中某个页面某个组件下的具体的一个功能元素|
|事件类型|该次事件动作的类型，如展现、点击、阅读等|

如下图3-1所示，后台在埋点管理时，也按照对应页面、组件、展位、事件类型进行定义。

![](https://tech.qimao.com/content/images/2021/06/--1.png)

图3-1 管理后台

元素命名规范：

✔ ️“#”可以用作所有元素的通配符；

✔ ️不能出现汉字、拼音、拼音英文混用的情况；

✔ ️只有展位可以用数字命名，如果用数字要用纯数字，不要加入其他符号；

关于页面、组件、展位的定义，参照以下组图进行理解：

![](https://tech.qimao.com/content/images/2021/06/-----------.png)

图3-2 书城页面

![](https://tech.qimao.com/content/images/2021/06/--------------.jpg)

图3-3 七猫中文网

2.2 事件属性

事件属性指事件携带的可定义属性，如bookid（书籍ID）、chapterid（章节ID）、duration（看书时长）等，事件属性会提供一个固定列表，在使用中发现属性列表不能满足需要时，由大数据研发评估后增加属性。

**三、**配套系统****

3.1 客户端SDK

分别开发了Android端和iOS端客户端SDK来采集WHO、WHEN、WHERE等公用数据，SDK对WHAT事件做一定预聚合之后上报，这一块的细节比较多，在后端客户端关于SDK的部分会详解。

3.2 日志接收系统

基于Golang研发，部署于K8S，结合Filebeat工具，完成了从日志接收、数据补全、落盘、转发的轻量化处理流程，保障数据的处理效率和稳定性。系统细节较多，会在后续的文章中详解。

3.3 日志埋点管理系统

日志埋点管理系统主要用来管理事件组成要素，包括项目、页面、组件、展位、事件类型、属性。同时日志埋点管理系统里记录的数据会作为日志检测系统的元数据，来对埋点合规性进行管理。

3.4 埋点检测系统

该系统同时具备数据合规性检测和埋点质量检测功能，它周期性拉取日志埋点管理系统的元数据，把从日志接收系统传递过来的数据，与其逐条进行比对、校验后，保留合规的、剔除不合规的，并通过邮件提醒对应的负责人。

**四、**埋点需求开发流程****

![](https://tech.qimao.com/content/images/2021/06/---------.jpg)

图4-1 埋点需求流程

需求流程如上图4-1所示：

****Step1:一个埋点需求****

即想在APP的某个页面某个位置添加一个事件，统计某个功能的使用情况。

****Step2:日志埋点管理系统录入****

在日志埋点管理系统里，按照事件ID的定义方式创建页面->创建组件->创建展位->选择事件类型、选择事件属性，完成后提交在后台里。

注：如果你所需要的页面、组件、展位已经存在，则不需要再创建，直接下拉选择即可。

![](https://tech.qimao.com/content/images/2021/06/--2.png)

图4-2 在埋点系统录入事件

****Step3:埋点审核（目前是自动通过审核）****

目前都是自动通过审核的，后续会考虑增加人工（数据产品、大数据研发）审核环节，确保数据埋点的质量。

****Step4:研发执行埋点处理****

研发根据产品提交的埋点需求，将正确的事件埋在正确的位置。

****Step5:测试校验埋点准确性****

研发完成后，需要测试进行埋点准确性的校验，我们的标准是，一个字符也不能错，错了就会被埋点检测系统过滤掉。

****Step6:跟随版本发布上线****

我们采用的是代码埋点的方式，必须发版才能发布新的埋点方案。

****Step7:查看统计结果****

版本发布上线后可在七猫统计里查看所埋事件的PV和UV等计算结果。

![](https://tech.qimao.com/content/images/2021/06/--3.png)

图4-3 查看统计结果

**五、**埋点的思想****

**5.1 **多个点形成面****

让一个面上的事件能够完整的铺开，把需要的位置都能统计到，可以有效分析整个页面的使用情况。

**5.2 **多个点连成线****

让一个操作路径上的事件具有连贯性、逻辑性，形成一条紧密的线，便于使用情况追踪、转化漏斗计算。

例如：启动APP->选择性别、内容偏好->书城页打开->书籍展现->书籍点击->书籍详情页打开->阅读按钮点击->阅读器打开->翻章->翻章->......。

**5.3 **只埋小位置****

事件是由“页面_组件_展位_事件类型”组成的，只埋小位置也就是说，我们要在“展位”这个层面进行埋点，系统会自动对“页面”、“页面_组件”维度进行上卷计算。

如下图5-1所以，书城男生频道页中，组件C是主编推荐区域，我们在埋点的时候只需要给其中的3本书对应的展位分别进行埋点即可，系统会自动计算出组件C的点击量。

![](https://tech.qimao.com/content/images/2021/06/------------1.png)

图5-1 只埋小位置

**5.4 **埋点单一职责原则****

每个事件的作用是独立的，只代表一个意义和功能，不需要二次推导其作用。

如终章页里的“换一换”按钮，它代表的就是“换一换”功能的触发情况，而不是让它同时具备“换一换”和与之相关的书籍展现统计。

**5.5 **多功能操作要多个埋点****

同一个按钮，如果有多种功能，从维度拆分的角度来说，应该埋多个事件，细化粒度，提升数据利用效率。

如终章页有个“加入书架并继续阅读”按钮，那在这个按钮触发的时候，就应该埋下去“加入书架”和“阅读”两个事件。

**5.6 **埋点属性的添加要针对被操作的对象****

所有的埋点属性的应用，应该是基于被操作的那个对象是什么。

如终章页里由A书推出了B书，那点击加入书架按钮的时候，bookid的值应该为B书ID，因为被操作的对象是B。

**5.7 **合理利用事件类型****

尤其是对内容方面来说，不同事件类型（show、click、join、move、read等）代表了其对内容的不同喜好程度，是可以根据不同操作类型来给用户行为打分的。

注：慎重增加新的事件类型。

**5.8 **双端统一实现方式****

同样的功能，双端在实现时，要对埋点、技术实现方案进行统一。

# 七猫日志接收系统之架构设计（上）

[秦皓](https://tech.qimao.com/author/qinhao/) 发表于 2023/11/01

# 前言

七猫日志接收系统系列文章将会向大家介绍七猫日志接收系统及相关的埋点 SDK，总共分为四篇：

- **七猫日志接收系统之架构设计（上）（本篇）**
- 七猫日志接收系统之架构设计（下）
- 七猫日志接收系统之客户端埋点 SDK
- 七猫日志接收系统之服务端埋点 SDK

本文为系列的第一篇，将带大家一起回顾七猫 2020 年至今，七猫日志接收系统近四年来的演化历程。如果您之前未了解过统计埋点系统，强烈推荐您阅读本站发布的[七猫统计埋点实践](https://tech.qimao.com/qi-mao-mai-dian-shi-jian/)一文。

---

# 背景说明

自公司七猫免费小说立项以来，日志接收系统便一直存在，初始版本的日志接收系统使用 PHP 实现，随着客户端上报的日志量越来越多，整体处理上不够高效稳定，此后我们使用 Go 对其进行重新实现并运行了一段时间。

自 2019 年以来，七猫免费小说业务迎来了爆发式增长，日活突破 2000w 大关，旧架构下的日志接收系统无法承载如此大规模的流量，2020 年年初，研发中心的客户端、基础平台和大数据等团队一起重新梳理、规划并设计了新的客户端埋点日志上报流程，并对日志接收系统进行了重构，下文将基于此次重构的新系统进行说明。

当前的七猫日志接收系统基于 Go 语言开发，使用 k8s 进行云上部署，结合 Filebeat、Kafka 等组件的使用，完成了从日志接收、格式校验、日志补全、数据落盘到分流转发等一系列数据处理逻辑。日志接收系统作为基础服务，既需要保障日志的处理效率，又需要有极高的稳定性，接下来，我们来一起回顾这四年来它的演化历程，看它是如何演化成长的。

_注：为使整体架构清晰明了、便于理解，本文中我们对系统架构做了一定程度的简化，更加完整的系统架构将在后续发布的_[_七猫日志接收系统之架构设计（下）_](httpshttps://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-xia)_中进行分析。_

---

# 时间线

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-12.png)

# v1 版本

v1 版本只实现了接收客户端聚合日志逻辑（客户端埋点日志并非在事件触发时进行实时上报，客户端埋点 SDK 会收集、存储埋点事件，并在满足一定条件下进行批量上报，从而实现聚合日志上报，其具体的实现逻辑将在后续文章中进行分析，敬请期待），整体功能和部署都比较简单。

## 架构图示

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-13-1.png)

v1 版本

_图注：v1 版本实际为云上双可用区部署，图示中只画了单个区的部署架构。_

## 数据流程

1. 客户端埋点 SDK 收集、存储并通过请求 HTTP 接口上报聚合日志，请求通过 k8s 中的 Ingress 网关转发到主机上的日志处理服务实例；
2. 日志处理服务（Service）经过认证、解密等处理后，将日志写入到主机磁盘的指定目录下的文件中；
3. 主机中 Filebeat 实例读取磁盘中的日志文件数据并写入 Kafka 集群中；
4. 下游归因系统等业务服务消费处理 Kafka 数据，后经一系列处理后，数据最终会写入到大数据系统中。

## 技术要点

1. 如前文所述，因为历史原因，我们需要对历史老版本接口进行兼容，以及对老版本日志进行格式转换和清洗；
2. 为了防止日志数据丢失，经过日志处理服务的数据会写入文件，从而实现持久化存储（存储周期为三天）；日志数据未成功落盘时，会让客户端进行重试上报；
3. 为了避免 Filebeat 更新、重启时重复读取日志文件，Filebeat 的读取记录也存在运行主机的磁盘上（图示中未体现）；
4. 通过创建本地持久化存储卷时配置 nodeAffinity 指定 2-3 个存储主机，确保使用该存储卷的 Pod 全部分布在指定主机上；
5. 日志处理服务使用 Deployment 方式部署，默认滚动更新 RollingUpdate 策略，保证高可用，可弹性伸缩；
6. Filebeat 使用 DaemonSet 方式部署，来确保每个节点上只运行一个 Filebeat Pod 的实例；
7. 为了进一步保证日志系统的稳定性，我们在部署时使用了多分区方式部署，即在阿里云北京部署 G 区集群，在阿里云北京部署 H 区集群，平时流量基本持平，当有一个区不可用时，对另一个区集群进行扩容即可保障业务的快速恢复。

综上所述，整个 v1 架构通过容器化服务、k8s 集群部署和数据本地磁盘持久化等方式，在保证数据完整性的同时，通过解耦使整个系统中的各环节可以弹性扩展，提供了很高的可用性，基本满足了流式计算系统稳定、实时、高可用、易扩展的需求。

---

# v2 版本

v1 版本持续运行了一段时间，随着业务进一步发展，七猫开始自建 AB 测试、推荐引擎等基础平台，需要对服务端埋点日志也进行收集处理，于是我们基于 v1 迁出了 v2 版本代码（使用 Go Mod 多版本方式），在 v2 版本的代码里面实现服务端日志接收逻辑。此时 v1 和 v2 两个版本共存，主要从职责上来划分版本：

- v1 服务接收并处理客户端埋点日志（v1 Serivce）
- v2 服务接收并处理服务端埋点日志（v2 Service）

## 架构图示

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-14.png)

v2 版本

_图注：图示中只画了一个主机（Node A）细节，实际为多主机实例部署，下文同，不再单独说明。_

## 数据流程

v2 版本整体数据流程与 v1 版本基本一致，主要是引入了 v2 Service 独立处理服务端埋点日志：

1. v2 版本引入 v2 Service，用于承接服务端埋点日志（由 AB 测试等系统产生）；
2. 客户端日志和服务端日志经过对应的 Service 处理落盘进入不同的文件目录，对应的 Filebeat 实例读取指定的日志文件内容，并通过不同 Topic 写入到 Kafka 中；
3. 下游对应的业务系统消费日志数据进行处理并最终落到大数据系统。

## 技术要点

1. 将客户端日志（v1 Service）和服务端日志（v2 Service）分开处理，双端日志进行业务隔离；
2. 使用独立的 Ingress 来分别承接客户端和服务端日志数据，隔离网络相互间的影响；
3. 基于维护成本和效率上考量，我们将之前的双分区（G 区和 H 区）部署方式改为单分区单集群部署方式（降低了一定可用性，但总体收益为正）。

因为在同一代码仓库维护两个分支的方式存在很大的不便利性，且随着算法业务的发展，我们需要接收客户端实时埋点日志，期间我们尝试将代码拆分到多个不同仓库中进行独立维护，但总体上各类埋点日志处理的业务逻辑基本一致，所以最终我们又将代码进行了梳理和整合，重新划分了服务职责，并以此为契机，日志接收系统进入到了 v3 版本时代。

---

# v3 版本

随着七猫的业务发展，日志接收系统需要接收客户端（聚合和实时）埋点、服务端埋点、服务端通用、前端埋点（Web 和 H5）等各种类型的日志，我们着重对代码进行整合，重新划分了各个服务的职责。

## 架构图示

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-15.png)

v3 版本

从图中我们可以看到，我们根据数据来源，将日志接收系统服务划分出了以下服务：

- aggregate-client 接收客户端聚合埋点日志
- realtime-client 接收客户端实时埋点日志
- frontend 接收前端（Web、H5 等）埋点日志
- server 接收服务端埋点日志（AB 测试等）
- backend 接收服务端通用日志（其他业务需要上报和收集的日志）

## 数据流程

1. 从 v3 版本开始，我们引进了 Envoy 替换 Ingress 作为网关来承接所有流量，Envoy 接收到流量后，根据请求 Path 将其转发到不同服务；
2. 不同的服务独立处理不同类型的日志数据，并写入到对应的文件目录中；
3. 不同的 Filebeat 实例读取日志文件并将数据写入 Kafka（不同实例或不同 Topic）；
4. 下游归因等业务系统读取并处理 Kafka 数据，数据最终落到大数据系统；
5. 其中客户端实时埋点日志主要是算法相关业务使用，我们将这部分日志直接写入独立 Kafka，下游服务直接消费 Kafka。

## 技术要点

1. 因为随着业务发展，客户端埋点日志上报越来越多，Ingress 在流量高峰时 RT(P99) 比较高，请求成功率在高峰时段跌落到 98% 左右，通过调研，我们引入了 Envoy 网关，并将 k8s 的网络插件从 Flannel 换成了 Terway，成功地解决了这个问题；
2. 因为算法对某些客户端埋点事件的实时性要求更高，我们通过独立的客户端实时埋点服务（realtime-client）将日志直接写入 Kafka 供下游消费，这部分的数据链路相对独立；
3. 这些服务除了请求参数、路由不同，其他如加解密、写文件等后续逻辑基本一致，所以我们将其整合在一个代码仓库中，并且将公用部分抽象成公用包。

然而随着时间的推移，处理数据、存储数据等成本越来越高，旧的数据链路也无法满足业务的快速发展，为了解决这些问题，响应公司降本提效的政策，由大数据团队牵头，我们对整个大数据链路进行了升级改造（主要针对客户端聚合日志），日志接收系统也需要进行同步升级，由此我们来到了 v4 版本。

---

# v4 版本

## 架构图示

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-16.png)

v4 版本

## 数据流程

v4 版本的数据流程基本与之前版本相同，主要针对客户端聚合埋点日志进行了以下优化：

1. 根据公司大数据区分的业务线，将下游 Kafka Topic 以业务线聚合；服务将接收到的日志根据项目标识字段，将日志归属到不同的业务线，Filebeat 在消费文件时，根据业务线将日志写入下游 Kafka 不同的 Topic 之中；
2. 为了减轻下游任务依赖以及耦合度，将通用的逻辑从下游的归因系统中抽离，前置到了日志接收系统中，由日志接收系统完成下文 3~6 的逻辑；
3. 日志格式校验：实现日志通用字段约束等校验逻辑，并将校验不通过的日志写入特殊的 Topic 中，以供后续日志分析使用；
4. 埋点事件合法性校验：日志接收系统定时同步埋点后台中注册的事件，对日志中未进行埋点或已下线的事件进行剔除，并将剔除掉的事件写入下游特殊 Topic，以供后续对埋点事件分析使用；
5. 新老用户判断：根据日志中的设备标识相关字段，判断设备为活跃还是新增，生成该条日志对应设备的唯一标识信息，并写入日志，传入下游；
6. 日志信息补全：如 IP 信息等，通过解析请求来源 IP，生成 IP 地址相关的地区信息，写入日志，传入下游；
7. 为了进一步提高下游数据处理效率，在日志接收系统针对不同的埋点事件类别进行甄别，将广告相关的埋点事件日志写入独立目录，由一组独立的 Filebeat 消费，并直接传递至大数据广告系统中。

## 技术要点

1. 由于不同的业务需要的校验和解析功能（比如一些内部项目不需要关心归因逻辑中推广渠道等信息，也不需要校验埋点事件），我们将日志中不同类别字段的校验和解析抽象成了校验器和解析器，通过配置化的形式，可以做到动态控制业务项目使用不同解析或校验功能；
2. 对于校验器和解析器，他们各自处理的是不同的字段，为了提升性能，我们对日志字段的各部分校验进行并发处理，对各部分的解析也进行并发处理，进一步提升了响应速度，整体 RT(P99) 可以控制在 10ms 以下；
3. IP 解析服务我们集成了内部自研的 IP 解析功能，参看本站之前发布的文章：[IP 库 - IP 段生成 Trie 树过程的剪枝实现](https://tech.qimao.com/ip/)，可以做到对 IPv4 和 IPv6 两种 IP 的高效解析；
4. 简化下游归因系统逻辑，归因系统属于业务系统，不应该处理如日志预处理、IP 解析、非法日志过滤、新老设备判断等通用基础逻辑；
5. 将广告相关的埋点事件进行分流处理，下游归因系统不需要关心的事件不会再流入到该系统中，分流处理大大降低了归因系统及后续服务器服务器负载，降本效果明显。

---

# 总结

回顾七猫日志接收系统近四年的发展，它的成长似乎也从侧面见证了我们七猫的茁壮成长。从最开始的纯 HTTP 接口请求处理，到使用 Filebeat + Kafka 的模式兼顾效率和持久化，到不同类型埋点日志的日益丰富，再到升级 Envoy 网关以保证请求成功率，最后到 v4 的前置通用逻辑和按业务线分流。这也正是我们七猫业务的发展轨迹，从极速成长到逐步成熟稳定，从单一业务到业务多元的发展轨迹。

关于七猫日志接收系统的更多细节，我们将基于当前的 v4 版本，在[下篇](httpshttps://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-xia)中围绕**日志处理效率**、**成本控制**以及**系统的高可用**等方面进行分析和讨论。随着七猫的继续壮大，日志接收系统必将迎来越来越多的挑战，届时我们也会对后续的 v5 迭代版本进行规划与展望。

# 七猫日志接收系统之架构设计（下）

[秦皓](https://tech.qimao.com/author/qinhao/) 发表于 2023/11/16

# 前言

七猫日志接收系统系列文章将会向大家介绍七猫日志接收系统及相关的埋点 SDK，总共分为四篇：

- [七猫日志接收系统之架构设计（上）](https://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-shang/)
- **七猫日志接收系统之架构设计（下）（本篇）**
- 七猫日志接收系统之客户端埋点 SDK
- 七猫日志接收系统之服务端埋点 SDK

本文为系列的第二篇，我们将基于当前的 v4 版本详细介绍七猫日志接收系统架构，并从**日志处理效率**、**系统的高可用以及成本控制**等方面进行架构设计分析。同时随着七猫的继续壮大，日志接收系统必将迎来越来越多的挑战，我们也会对后续的迭代版本进行规划与展望。

---

# 架构总览说明

[上篇](https://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-shang/)中，我们为了让架构清晰明了，在对历史各版本的架构图示进行说明时，做了一定程度的简化，下面我们给出七猫日志接收系统 v4 架构更完整的图示：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-16-1.png)

1 - 架构总览

**注：淡红色部分为系统所依赖的相关辅助系统。**

## 辅助系统

在图上方淡红色部分，我们看到日志接收系统依赖了诸如埋点系统、Nacos、Redis 集群和其它三方服务，这些系统对于日志接收服务功能的完整性是不可或缺的。

**_埋点系统：_**七猫埋点系统是产品和运营人员完成创建、注销埋点事件，设置埋点事件属性等操作的后台系统。日志处理服务会定期从埋点系统同步埋点事件的配置信息，并将配置缓存在内存中，在处理日志数据（日志补全、日志校验、事件校验等）时，可以快速获取这些埋点配置信息。

**_Nacos：_**[Nacos](https://nacos.io/) 是阿里云开源的一个用于构建云原生应用的动态服务发现、动态配置管理和服务管理平台，其动态配置管理功能，消除了配置变更时重新部署应用和服务的需要。目前七猫各业务线都有使用它来进行服务配置管理，在日志接收系统中，不同项目的日志使用的校验器和解析器（见下文），就是通过 Nacos 的配置管理功能实现动态开启和关闭。

**_Redis：_**我们使用 Redis 集群储存了七猫所有不同设备标识的映射关系，日志处理服务在进行设备归因等逻辑时，通过实时读写 Redis，可以高效的对设备进行归因，完成新老设备判断、设备映射关系更新等操作。

**_三方服务：_**日志接收系统中集成了七猫自己开发的 IP 解析服务，它可以做到对 IPv4 和 IPv6 两种 IP 的高效解析，给下游的 IP 归因等功能提供了基础。对 IP 解析实现感兴趣推荐参看本站之前发布的文章：[IP 库 - IP 段生成 Trie 树过程的剪枝实现](https://tech.qimao.com/ip/)。

## 核心数据流

架构图示中间部分是日志处理的核心数据流程，可以细化如下图所示：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-3.png)

2 - 核心数据流

流程主要包括：

1. 客户端和服务端等各端的埋点 SDK 收集、存储并通过 HTTP API 上报日志数据；
2. SLB 将请求均衡到 Envoy 网关集群的不同 Pod 上；
3. Envoy 网关 Pod 接收请求，并根据路由将日志转发到具体的日志处理服务；
4. 日志处理服务首先对请求权限进行认证，随后对日志进行数据解密、基本信息补全、日志过滤、IP 解析、埋点事件解析校验、设备归因等一系列处理，然后将其写入不同目录下的磁盘文件；
5. Filebeat 实例读取指定的文件目录下的文件，并将日志数据写入下游 Kafka 集群；
6. 下游业务系统从 Kafka 消费日志，进行具体的业务处理。

---

# 架构设计分析

日志接收系统作为基础服务，承载了埋点日志的所有流量，是下游市场媒体归因（可参看本站文章：[媒体推广业务架构演进](https://tech.qimao.com/mei-ti-tui-yan-ye-wu-jia-gou-yan-jin/)）、广告分析、用户数据分析、大数据系统及数据报表等核心业务的入口，我们需要在保证日志处理服务的效率和系统高可用的同时，尽可能的降低成本，下面我们从这三个方面来看整体架构设计上我们是如何考虑的。

## 日志处理效率

### 使用 Go 语言开发

在[上篇](https://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-shang/)文章提到，我们最原始的日志接收系统使用 PHP 开发的，后来随着上报请求的增多，日志体量的增长，PHP 在并发能力上处理也逐渐接近瓶颈，在进行重构时我们选择了用 Go 语言实现。选择 Go 的原因很简单，它有着：

- 简单易学，社区活跃
- 代码风格统一易读
- 原生和轻量级的 goroutine
- 基于 channel 并发处理机制
- 标准库和三方库丰富
- 以及**优越的性能**表现
- 开发效率高

等特性，是编写云原生大流量服务的不二之选。目前 Go 也是我们七猫后端服务的主要开发语言，经过这几年来的使用摸索，我们后端团队已经积累了非常丰富的经验。

### 使用缓存进行加速

众所周知，增加缓存是提升处理效率的最快方式，所以我们在日志接收系统中大量使用缓存，包括 Redis 缓存和内存缓存。

- 对于设备信息映射关系和设备基本的活跃信息等数据，我们使用 Redis 作为缓存；
- 对于从埋点后台同步过来的埋点配置信息，我们以内存缓存的方式存储，并通过协程来定时更新。

我们在对日志进行处理时，直接使用缓存来提高处理效率，使用图示如下：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-20.png)

3 - Redis 缓存与内存缓存

### 通过并发提高效率

日志接收系统接收来自不同端的各类日志，而我们“永远不要相信客户端的传值”，对于上报的日志，我们需要对日志字段做解析、校验和过滤，以防止客户端无限制的上报事件，而不同的项目对日志校验和过滤规则不尽相同。

因此我们根据这些规则抽象出了不同的解析器和校验器，并通过配置为不同的项目指定需要的校验器与解析器。我们抽象出的解析器和校验器针对日志的不同字段处理，为了提高处理速度，在日志进行解析和校验的时候开启 goroutine 并发操作，在所有协程完成处理后，才进行下一步的操作，示意图如下：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-5.png)

4 - 并发处理日志

## **系统高可用**

### 网关优化升级

[上篇](https://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-shang/)中提到，因为随着业务发展，日志上报越来越多，一段时间后 Ingress（Nginx）在大流量的冲击下，RT(P99) 较高，请求成功率在高峰时段达跌落到 98% 左右。通过运维同事的调研，我们引入了 Envoy（MSE 云原生网关：是基于 Envoy，做了深度优化的云上服务）网关，并将 k8s 的网络插件从 Flannel 换成了 Terway，成功地解决了这个问题，扛住了大流量的冲击。

我们优化前的网关架构如下（Nigix 和 Flannel 网络插件）：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-6.png)

5 - 优化前的网关架构

优化后网关架构的如下（使用 Envoy 和 Terway 网络插件）：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-7.png)

6 - 优化后的网关架构

**Terway 与 Flannel 对比：**

|   |   |   |
|---|---|---|
|**对比项**|**Terway**|**Flannel**|
|性能|Pod 地址即为 VPC 中地址，无 NAT 损耗支持独占 ENI 模式，几乎无损。|配合阿里云 VPC 路由，Pod 地址为虚拟地址，存在 NAT 转换损耗。|
|安全|支持使用网络策略 Network Policy。|不支持使用网络策略 Network Policy。|
|地址管理|无需按节点分配地址段，随用随分配，地址无浪费。支持为 Pod 配置固定 IP 及独立虚拟交换机、安全组。|节点维度划分地址段，大规模集群下地址浪费多。|
|SLB|SLB 后端直接对接 Pod，支持业务无中断升级。|SLB 后端不能直接对接 Pod，需要通过 NodePort 转发。|

来源：**[使用 Terway 网络插件](https://help.aliyun.com/zh/ack/ack-managed-and-ack-dedicated/user-guide/work-with-terway)** 。

### 日志落盘及异步解耦

日志接收系统接收并处理日志之后，如何将数据传递给下游呢？如果我们直接调用下游提供的 RPC 接口，势必会影响日志处理效率，在高峰时给下游服务过大的压力，同时当下游服务出现故障时，导致日志数据丢失。所以我们使用日志落盘 + Filebeat + Kafka 等组件实现了日志持久化和异步解耦。

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-8.png)

7 - 日志落盘及异步解耦

1. 首先在处理完日志之后，会将日志写入磁盘文件，保证接收到的日志持久化，在出现问题时能够回放日志；
2. 然后在每台主机上都部署 Filebeat 实例，由它实现对日志文件的监听并转发写入 Kafka；
3. 最后下游服务通过订阅消费 Kafka Topic 的方式，进行业务处理。

这样处理虽然链路会变长，但能够保证日志的完整性，降低日志丢失的风险，从而提升了系统整体的高可用性。

## **成本控制**

### 日志分流

在[上篇](https://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-shang/)中可以看到，旧版本架构下的的日志并没有进行任何分离处理，所有的客户端埋点聚合日志都经过下游归因系统、回传系统等处理后，写入新的 Kafka 再由大数据系统消费，最终生成实时报表以及写入数仓。分流前数据图示：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-14-1.png)

8 - 日志分流前数据流

然而在归因等系统中实际业务需要的日志仅占很小一部分（大约 10%），大部分的日志（如阅读行为、广告等）都不会进行业务处理，而是直接透传，造成资源浪费。为了减少成本，我们在日志接收系统中根据事件对日志进行了分流处理。分流后数据图示：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-18.png)

9 - 日志分流后数据流

进行日志分流后，日志接收系统将归因系统，回传系统等不需要的其他事件日志（约 90%）写入另外的 Kafka Topic 直接供大数据系统消费，而剩下的 10% 日志由归因、回传等业务系统与大数据一起直接消费。整体链路得到的有效缩短，运维效率得到了提升，同时也节约了资源。资源节约比例：

|   |   |
|---|---|
|**资源列表**|**节省比例**|
|归因等相关服务器资源|50%~60%|
|大数据相关 Kafka 资源|20%~30%|
|大数据相关计算资源|10%~20%|

### 滚动删除

架构图中 Cronjob 用于对日志文件进行定期清除，最开始我们定时的清除日志（日志存储周期为三天，每日凌晨三点低峰时段进行清除操作），经过这几年的运行下来，我们发现整个日志系统是很稳定的，即使遇到问题，一般也能较快的进行解决修复，日志储存三天磁盘占用过高，我们通过计算和评估，决定将存储周期改为 48 小时，后续会进一步缩减到 36 小时，而且由一天清理一次，并改为滚动删除的方式。下图为保留三天定时删除和保留 48 小时滚动删除的硬盘使用情况对比：

![](https://tech.qimao.com/content/images/2023/11/img_v3_0251_b9bb4389-25c7-48c9-baa6-fb15860877fg.jpg)

10 - 日志清楚优化前后地比

其中蓝线为保留 3 天的定时删除方式，橙线为滚动删除保留 48 小时的方式。可以看出，将删除方式改为删除 48 小时且滚动删除时：

- 可以明显减少硬盘的存储压力，硬盘的存储水位一直保持相对稳定;
- 可以明显瞬时硬盘的 IO 压力，不会在某一时刻删除大量文件。

经过计算，使用滚动删除保留 48 小时的删除方式时，预计**节约 25%左右的资源成本。**

---

# 展望与规划

## 高可用性提升

为了进一步提升系统高可用，我们考虑未来可以引入应用多活的架构，如下：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-11.png)

11 - 应用多活架构

多可用区部署，1 个可用区 1 个网关，1 个 K8s，整体由 ACK ONE 统一管理。在某一分区出现问题时，可将流量全部转移至另一个分区。

## 埋点事件分级

由于有些埋点事件对于我们整个系统上下游中非常重要，我们考虑对埋点事件重要程度进行分级。对于这些高优先级事件的日志，各端增加一些特殊处理，以保证高优先级事件一定能被日志系统接收，比如：

- 客户端对于高优先级事件可以选择分开上报，在网络环境不佳时，本地优先缓存高优先级事件日志存储，同时增加此类事件上报失败的重试次数等；
- 日志接收系统可以针对高优先级事件做更强的一致性保证（比如单独发送 Kafka 后再落盘，增加重试等）。

## 部署方式优化

当前 Filebeat 的部署方式如下：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-12-1.png)

12 - Filebeat 部署在主机中（独立 Pod）

每个 Filebeat 以守护进程的形式部署在每台机器上，它需要监听当前机器上所有 Pod 产生的日志文件，文件数较多。若想要修改 Filebeat 配置，或者升级，重启 Filebeat 时，按照当前的文件数，Filebeat 会有大量时间消耗在扫描元数据上，使得该机器上的日志暂时积压，影响系统内的日志时效性。

所以可以考虑将 Filebeat 的部署 Pod 化，如下图所示：

![](https://tech.qimao.com/content/images/2023/11/whiteboard_exported_image-13-2.png)

13 - Filebeat 部署在 Pod 中

将 Filebeat 与业务服务部署在同一个 Pod 内，Filebeat 直接监听 Pod 产出的日志文件（监听 Pod 内目录，底层日志文件实际上还是会落在硬盘）

**这样部署主要有以下两个好处：**

1. Filebeat 监听文件数显著减少，减少每个 Filebeat 的 metadata 大小，大大提升 Filebeat 启动速度；
2. 部署粒度更细，更加方便灰度操作，比如升级 Filebeat 版本，修改 Filebeat 配置等。出现问题，影响范围也仅仅是单 Pod 级别，而不是整台机器。

---

# 总结

我们向大家详尽的介绍了七猫日志接收系统整体的架构设计，并从日志处理效率、系统的高可用以及成本控制等方面进行了设计上的分析，同时提出了一下优化方向。在后续文章中，我们还会给大家带来关于客户端埋点设计的分析，敬请期待。


# Reference
https://tech.qimao.com/qi-mao-mai-dian-shi-jian/
https://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-shang/
https://tech.qimao.com/qi-mao-ri-zhi-jie-shou-xi-tong-zhi-jia-gou-she-ji-xia/

