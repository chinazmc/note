
## 背景介绍

伴随物流行业的迅猛发展，一体化供应链模式的落地，对系统吞吐、系统稳定发出巨大挑战，库存作为供应链的重中之重表现更为明显。近三年数据可以看出：

![](https://segmentfault.com/img/remote/1460000044141472)

接入商家同比增长37.64%、货品种类同比增长53.66%

货品数量同比增长46.43%、仓库数量同比增长18.87%

通过分析过往大促流量，分钟级流量增长率为75%，大促仓内反馈三方订单下传不及时，库存预占吞吐量和性能是导致订单积压因素之一。目前库存使用mysql数据库作为接单预占的扛量手段，随着一体化供应链建设以及重点KA商家不断接入，现有库存架构在业务支撑上存在风险和缺陷。

此外未来3到5年业务增长、流量增长预计增长5-10倍。为避免系统性能和技术架构缺陷导致业务损失，轻量级库存架构势在必行。

// 名词解释：

库存预占：是指消费者拍下商品订单后，库存先为该订单短暂预留，预留的库存即为预占库存。

## 架构原则

> **架构**：是⾯向问题，解决问题的手段。 库存系统的问题: 非功能性：1.高并发 2.系统稳定性(容灾) 3.数据一致性 功能性: 1.业务复杂 2.数据一致性

## 系统设计

### 设计思路

1. 当前库存系统瓶颈在哪里？：抗写流量，数据库成为瓶颈点。
2. 如何解决系统瓶颈？：由高并发组件Redis替代数据库。
3. 利用Redis需要解决哪些问题？：防超卖，异步写数据库保证最终一致性。

![](https://segmentfault.com/img/remote/1460000044141473)

### 总体设计

- **扛量部分**：库存性能瓶颈在预占，传统架构主要依靠数据库事务保持数据一致以及数据读写；新版架构设计将数据扛量部分移植到Redis，利用Redis高性能吞吐解决高并发场景下数据读写。
- **数据回写**：Redis进行扛量削峰，后续数据仅用于记账，最终牺牲数据的短暂一致性达到削峰的目的。
- **差异部分**：老版本库存预占设计仅依靠数据进行数据处理，新版设计依靠切量配置建数据切换到Redis，利用Redis高读写进行削峰操作。

![](https://segmentfault.com/img/remote/1460000044141474)

### 详细设计

- 主流程：

![](https://segmentfault.com/img/remote/1460000044141475)

- **库存初始化**：竞态条件利用Redis watch命令来实现锁等待，解决并发场景数据不一致问题。
- **LUA执行器**：将原子操作指令/复用指令封装到LUA脚本中以减少网络开销。
- **补偿机制：i>** 执行流程中所有业务异常发生时会同步发起反向操作请求；**ii>** 反向操作执行异常后会提交异步反向操作任务；**iii>**异步任务执行异常后，依赖监q控系统扫描异常单据或异常库存并修改异常库存量

![](https://segmentfault.com/img/remote/1460000044141476)

- **回溯回写**：任务落库后发出mq组装参数调用数据回写服务，数据回写服务操作库存数量；同时回写redis数据，释放预占量库存数据；更新任务库数据状态

![](https://segmentfault.com/img/remote/1460000044141477)

### 数据结构

- **库存记录索引**：{deptNo|goodsNo|warehouseNo}|stockStatus|stockType|goodsLevel
- **hashTag**：{deptNo|goodsNo|warehouseNo}|stockStatus|stockType|goodsLevel
- **可售库存数量**：usableKey：{库存记录索引}
- **扣减库存量**：usableSubtractKey：{库存记录索引} ，记录Redis到DB执行期间减库存量
- **预占防重key**：operateKey：{库存记录索引：单号} 防重key防并发重复请求
- **回滚防重**：rollbackOperateKey：{库存记录索引}
- **缺量预占库存量**：ullageOperateKey：{库存记录索引}
- **扣减库存单据记录**：hSetrecord: {库存记录索引}

|key|预占|缺量预占|回滚|回写|
|---|---|---|---|---|
|**可售库存数量**|-|-|+|不变|
|**扣减库存量**|+|+|-|-|
|**预占防重key**|+|+|-|不变|
|**回滚防重**|不变|不变|+|不变|
|**缺量预占库存量**|不变|+|反向|不变|
|**扣减库存单据记录**|+|+|-|-|

### Redis&DB

- 首先进行redis&从库数据比对，若存在差异则对主库进行校验
- 比对过程中，DB中sku明细行进行锁定(for update)，比对逻辑为DB可用库存量==(Redis可用库存量+Redis预占量)
- 有差异，报警且触发SDK可用量过期，同时矫正预占量

![](https://segmentfault.com/img/remote/1460000044141478)

### 容灾方案

---

![](https://segmentfault.com/img/remote/1460000044141479)

// 对系统容错/降级、监控机制(空间换稳定性，两份redis，故障3次丢数)，流量分布材料，618流量大、峰值数据切量。数据不一致，多个商家，不能超过5分。

预占任务持久化：mysql需要将核心属性字段数据持久化：事业部，商品编码，仓编码，等级，库存类型，库存状态，预占库存量，任务状态;调度执行完成后需要更新stockTask状态为完成

初始化：

(1) lock db

(2) sum stockTask

(3)使用DB可用库存初始化Redis可用库存，stockTask预占量初始化Redis预占量

(4)Redis库存回滚，如果预占量key不存在，该key不需要回滚

## 性能结果

---

![](https://segmentfault.com/img/remote/1460000044141480)

23年618大促

![](https://segmentfault.com/img/remote/1460000044141481)

![](https://segmentfault.com/img/remote/1460000044141482)

## 切量细则

切量细则

## 冷热数据

OMS库存冷热装置

预占架构升级切量重点key监控

库存预占架构升级切量商家

架构升级切量商家明细2

已切量商家

## 反向切量

> 原有设计中存在以下名单
> 
> 禁止切量商家：优先级较高，一旦在名单中，禁止切量
> 
> 批次库存商家：批次库存管理商家，目前该部分能力尚未建设
> 
> 动态质押商家：物流金融业务，目前该部分能力尚未建设 切量名单商家：该部分为切量商家
> 
> 原有切量流程：！禁止切量->！批次库存->！动态质押->切量名单中，通过以上校验为切量商家。
> 
> 原有流程在增量商家中需要手动将商家配置到切量名单中才可进行切量操作，对于新增商家场景操作不变，且原有流程中逻辑库存名单为痛点：逻辑库存的启用配置在事业部主数据中，不在库存侧。
> 
> 新版切量流程中对切量名单进行优化，将原来切量名单商家拆分成非逻辑库存名单、逻辑库存两个名单，其中：
> 
> 非逻辑库存名单：包含可切量商家
> 
> 逻辑库存名单：逻辑库存商家，该部分不可切量

原流程新流程对切量商家名单进行优化，拆分成非逻辑库存名单、逻辑库存两个名单

## 构建模型(批次库存&内存模型待续)

![](https://segmentfault.com/img/remote/1460000044141483)

### Redis存储数据结构

- MD生成规则工具集

◦逻辑库存MD5工具

```
     StringBuffer md5Key = new StringBuffer();
     md5Key.append(logicWarehouseStock.getGoodsNo()+"_"+logicWarehouseStock.getWarehouseNo()+"_"+logicWarehouseStock.getOwnerNo()+
             "_"+logicWarehouseStock.getDeptNo()+"_"+logicWarehouseStock.getStockType()+"_"+logicWarehouseStock.getGoodsLevel());
     if(StringUtils.isBlank(logicWarehouseStock.getFactor1())){
         md5Key.append("_0");
     }else {
         md5Key.append("_"+logicWarehouseStock.getFactor1());
     }
     if(StringUtils.isBlank(logicWarehouseStock.getFactor2())){
         md5Key.append("_0");
     }else {
         md5Key.append("_"+logicWarehouseStock.getFactor2());
     }
     if(StringUtils.isBlank(logicWarehouseStock.getFactor3())){
         md5Key.append("_0");
     }else {
         md5Key.append("_"+logicWarehouseStock.getFactor3());
     }
     if(StringUtils.isBlank(logicWarehouseStock.getFactor4())){
         md5Key.append("_0");
     }else {
         md5Key.append("_"+logicWarehouseStock.getFactor4());
     }
     if(logicWarehouseStock.getYn()== null){
      md5Key.append("_1");
     }else {
         md5Key.append("_"+logicWarehouseStock.getYn());
     }
     md5Key.toString().hashCode()
```

- 批次库存MD5工具

```java
public void fillMd5Value(){
        StringBuffer md5Key = new StringBuffer();
        md5Key.append(warehouseNo);
        md5Key.append("_");
        md5Key.append(goodsNo);
        md5Key.append("_");
        md5Key.append(goodsLevel);
        md5Key.append("_");
        md5Key.append(stockType);
        //遍历类字段不遍历map是为了控制MD5的组成顺序
        Class clazz = BatchAttrStock.class;
        Field[] fields = clazz.getDeclaredFields();
        try {
            int batchFieldCount = 0 ;
            for (Field field : fields){
                BatchAttrEnum attrEnum = BatchAttrEnum.batchFieldEnumMap.get(field.getName());
                //不是批属性的字段不进入MD5的组成
                if (attrEnum == null){
                    continue;
                }
                batchFieldCount ++;
                field.setAccessible(true);
                Object value = field.get(this);
                if (value == null ){
                    md5Key.append("0");
                    continue;
                }
                if(field.getType().toString().contains("String")){
                    md5Key.append(value);
                    continue;
                }
                if(field.getType().toString().contains("Date")){
                    Date timeField = (Date) value;
                    md5Key.append(timeField.getTime());
                    continue;
                }
                throw new RuntimeException(attrEnum.getField()+"填充MD5异常");
            }
            //默认50个批属性长度,长度不够0补齐
            int remainLength = 50 - batchFieldCount;
            String str = String.format("%0"+remainLength+"d", 0);
            md5Key.append(str);

        }catch (Exception e){
            throw new RuntimeException("填充MD5异常.");
        }

        md5Key.append(yn);
        String md5Value =  MD5Util.md5(md5Key.toString());
        setMd5Value(md5Value);
    }
```

- MD&ID&属性保存工具
 

# 电商库存系统的防超卖和高并发扣减方案

作者：京东云官方账号2022-09-19 09:49:17

[安全](https://www.51cto.com/netsecurity)[应用安全](https://www.51cto.com/application)

首先 MCube 会依据模板缓存状态判断是否需要网络获取最新模板，当获取到模板后进行模板加载，加载阶段会将产物转换为视图树的结构，转换完成后将通过表达式引擎解析表达式并取得正确的值，通过事件解析引擎解析用户自定义事件并完成事件的绑定，完成解析赋值以及事件绑定后进行视图的渲染，最终将目标页面展示到屏幕。

如果你要开发一个电商库存系统，最担心的是什么？闭上眼睛想下，当然是高并发和防超卖了！本文给出一个统筹考虑如何高并发和防超卖数据准确性的方案。读者可以直接借鉴本设计，或在此基础上做出更切合使用场景的设计。

### 背景

在今年的敏捷团队建设中，我通过Suite执行器实现了一键自动化单元测试。Juint除了Suite执行器还有哪些执行器呢？由此我的Runner探索之旅开始了！

下面用电商库存为示例，来说明如何高并发扣减库存，原理同样适用于其他需要并发写和数据一致性的场景。

#### 1.1 库存数量模型示例

为了描述方便，下面使用简化的库存数量模型，真实场景中库存数据项会比以下示例多很多，但已经够说明原理。如下表，库存数量表(stockNum)包含商品标识和库存数量两个字段，库存数量代表有多少货可以卖。

![7a3b7364562f43959581fc5148915cc7.png](https://s9.51cto.com/oss/202209/19/696902d0751c3d99ba21899f28257563a1c9bd.jpg "7a3b7364562f43959581fc5148915cc7.png")

**传统通过数据库保证不超卖**

库存管理的传统方案为了保证不超卖，都是使用数据库的事务来保证的：通过Sql判断剩余的库存数够用，多个并发执行update语句只有一个能执行成功；为了保证扣减不重复，会配合一个防重表来防止重复的提交，做到幂等性，防重表示例（antiRe）设计如下：

![95da90e550b94fa4b36733384a33e834.png](https://s6.51cto.com/oss/202209/19/883c15760c66c6ca420563e52e0a642d9b3cff.jpg "95da90e550b94fa4b36733384a33e834.png")

比如一个下单过程的扣减过程示例如下：

复制

```
事务开始
Insert into antiRe(code) value (‘订单号+Sku’)
Update stockNum set num=num-下单数量 where skuId=商品ID and num-下单数量>0
事务结束
```

面临系统流量越来越大，数据库的性能瓶颈就会暴露出来：就算分库分表也是没用的，促销的时候高并发都是针对少量商品的，最终并发流量会打向少数表，只能去提升单分片的抗量能力，所以接下来设计一种使用Redis缓存做库存扣减的方案。

### Redis缓存做库存扣减的方案

理解，首先 MCube 会依据模板缓存状态判断是否需要网络获取最新模板，当获取到模板后进行模板加载，加载阶段会将产物转换为视图树的结构，转换完成后将通过表达式引擎解析表达式并取得正确的值，通过事件解析引擎解析用户自定义事件并完成事件的绑定，完成解析赋值以及事件绑定后进行视图的渲染，最终将目标页面展示到屏幕。

2.1 综合使用数据库和Redis满足高并发扣减的原理

扣减库存其实包含两个过程：第一步是超卖校验，第二步是扣减数据的持久化；在传统数据库扣减中，两步是一起完成的。抗写的实现原理其实是巧妙的利用了分离的思想，分离开防超卖和数据持久化；首先防超卖是由Redis来完成的；通过Redis防超卖后，只要落库就可以；落库通过任务引擎，业务数据库使用商品分库分表，任务引擎任务通过单据号分库分表，热点商品的落库会被状态机分散开，消除热点。

整体架构如下：

![c2badfdee15c42729328fa4f49b60de5.png](https://s7.51cto.com/oss/202209/19/f8a33341731bb0b4d707154035c80c3c291d6c.jpg "c2badfdee15c42729328fa4f49b60de5.png")

第一关解决超卖检验：可以把数据放入Redis中，每次扣减库存，都对Redis中的数据进行incryby 扣减，如果返回的数量大于0，说明库存够，因为Redis是单线程，可以信任返回结果。第一关是Redis，可以抗高并发，性能Ok。超卖校验通过后，进入第二关。

第二关解决库存扣减：经过第一关后，第二关不需要再判断数量是否足够，只需要傻瓜扣减库存就行，对数据库执行如下语句,当然还是需要处理防重幂等的，不需要判断数量是否大于0了，扣减SQL只要如下写就可以。

复制

```
事务开始
Insert into antiRe(code) value (‘订单号+Sku’)
Update stockNum set num=num-下单数量 where skuId=商品ID
事务结束
```

要点：最终还是要使用数据库，热点怎么解决的呢？任务库使用订单号进行分库分表，这样针对同一个商品的不同订单会散列在任务库的不同库存，虽然还是数据库抗量，但已经消除了数据库热点。

整体交互序列图如下：

![520ad6910a8e49078016bf3de3b6c92e.png](https://s6.51cto.com/oss/202209/19/d7fd7dd989335494e617254538c2465b61b8a2.jpg "520ad6910a8e49078016bf3de3b6c92e.png")

#### 2.2 热点防刷

但Redis也是有瓶颈的，如果出现过热SKU就会打向Redis单片，会造成单片性能抖动。库存防刷有个前提是不能卡单的。可以定制设计JVM内毫秒级时间窗的限流，限流的目的是保护Redis,尽可能的不限流。限流的极端情况就是商品本来应该在一秒内卖完，但实际花了两秒，正常并不会发生延迟销售，之所以选择JVM是因为如果采用远端集中缓存限流，还未来得及收集数据就已经把Redis打死。

实现方案可以通过guava之类的框架，每10ms一个时间窗，每个时间窗进行计数，单台服务器超过计数进行限流。比如10ms超过2个就限流，那么一秒一台服务器就是200个，50台服务器一秒就可以卖出1万个货，自己根据实际情况调整阈值就可以。

![34ed1c84ea36442ba93388fa2bd51ecd.png](https://s9.51cto.com/oss/202209/19/33e1729065d5dac54ca6035b54cbaf0f006cfc.jpg "34ed1c84ea36442ba93388fa2bd51ecd.png")

#### 2.3 Redis扣减原理

Redis的incrby 命令可以用做库存扣减，扣减项可能多个，使用Hash结构的hincrby命令，先用Reids原生命令模拟整个过程，为了简化模型下面将演示一个数据项的操作，多个数据项原理完全等同。

复制

```
127.0.0.1:6379> hset iphone inStock 1 #设置苹果手机有一个可售库存
(integer) 1
127.0.0.1:6379> hget iphone inStock   #查看苹果手机可售库存为1
"1"
127.0.0.1:6379> hincrby iphone inStock -1 #卖出扣减一个，返回剩余0，下单成功
(integer) 0
127.0.0.1:6379> hget iphone inStock #验证剩余0
"0"
127.0.0.1:6379> hincrby iphone inStock -1 #应用并发超卖但Redis单线程返回剩余-1，下单失败
(integer) -1
127.0.0.1:6379> hincrby iphone inStock 1 #识别-1，回滚库存加一，剩余0
(integer) 0
127.0.0.1:6379> hget iphone inStock #库存恢复正常
"0"
```

**2.3.1 扣减的幂等性保证**

如果应用调用Redis扣减后，不知道是否成功，可以针对批量扣减命令增加一个防重码，对防重码执行setnx命令，当发生异常的时候，可以根据防重码是否存在来决定是否扣减成功，针对批量命名可以使用pipeline提高成功率。

复制

```
// 初始化库存
127.0.0.1:6379> hset iphone inStock 1 #设置苹果手机有一个可售库存
(integer) 1
127.0.0.1:6379> hget iphone inStock   #查看苹果手机可售库存为1
"1"
// 应用线程一扣减库存，订单号a100，jedis开启pipeline
127.0.0.1:6379> set a100_iphone 
"1"
NX EX 10 #通过订单号和商品防重码
OK
127.0.0.1:6379> hincrby iphone inStock -1 #卖出扣减一个，返回剩余0，下单成功
(integer) 0
//结束pipeline，执行结果OK和0会一起返回
```

防止并发扣减后校验：为了防止并发扣减，需要对Redis的hincrby命令返回值是否为负数，来判断是否发生高并发超卖，如果扣减后的结果为负数，需要反向执行hincrby，把数据进行加回。

如果调用中发生网络抖动，调用Redis超时，应用不知道操作结果，可以通过get命令来查看防重码是否存在来判断是否扣减成功。

复制

```
127.0.0.1:6379> get a100_iphone   #扣减成功
"1"
127.0.0.1:6379> get a100_iphone   #扣减失败
(nil)
```

**2.3.2 单向保证**

在很多场景中，因为没有使用事务，你很难做到不超卖，并且不少卖，所以在极端情况下，可以选择不超卖，但有可能少卖。当然还是应该尽量保证数据准确，不超卖，也不少卖；不能完全保证的前提下，选择不超卖单向保证，也要通过手段来尽可能减少少卖的概率。

比如如果扣减Redis过程中，命令编排是先设置防重码，再执行扣减命令失败；如果执行过程网络抖动可能放重码成功，而扣减失败，重试的时候就会认为已经成功，造成超卖，所以上面的命令顺序是错误的，正确写法应该是：

如果是扣减库存，顺序为：1.扣减库存 2.写入放重码。

如果是回滚库存，顺序为：1.写入放重码 2.扣减库存。

#### 2.4 为什么使用Pipeline

在上面命令中，使用了Redis的Pipeline，来看下Pipeline的原理。

非pipeline模式

复制

```
request-->执行-->responserequest-->执行-->response
```

pipeline模式

复制

```
request-->执行 server将响应结果队列化request-->执行 server将响应结果队列化-->response-->response
```

使用Pipeline,能尽量保证多条命令返回结果的完整性，读者可以考虑使用Redis事务来代替Pipeline，实际项目中，个人有过Pipeline的成功抗量经验，并没有使用Redis事务，正常情况下事务比pipeline慢一些，所以没有采用。

Redis事务

1）mutil:开启事务，此后的所有操作将被添加到当前链接事务的“操作队列”中

2）exec:提交事务

3）discard:取消队列执行

4）watch:如果watch的key被修改，触发dicard。

#### 2.5 通过任务引擎实现数据库的最终一致性

前面通过任务引擎来保证数据一定持久化数据库，「任务引擎」的设计如下，把任务调度抽象为业务无关的框架。「任务引擎」可以支持简单的流程编排，并保证至少成功一次。「任务引擎」也可以作为状态机的引擎出现，支持状态机的调度，所以「任务引擎」也可以称为「状态机引擎」，在此文是同一个概念。

任务引擎设计核心原理：先把任务落库，通过数据库事务保证子任务拆分和父任务完成的事务一致性。

任务库分库分表：任务库使用分库分表，可以支撑水平扩展，通过设计分库字段和业务库字段不同，无数据热点。

**2.5.1 任务引擎的核心处理流程**

![c6b6f0a9606c421e9a38954a3046f979.png](https://s3.51cto.com/oss/202209/19/d26205d661c99174460542b310a8b4b806126d.jpg "c6b6f0a9606c421e9a38954a3046f979.png")

第一步：同步调用提交任务，先把任务持久化到数据库，状态为「锁定处理」，保证这件事一定得到处理。

注：原来的最初版本，任务落库是待处理，然后由扫描Worker进行扫描，为了防止并发重复处理，扫描后进行单个任务锁定，锁定成功再进行处理。后来优化为落库任务直接标识状态为「锁定处理」，是为了性能考虑，省去重新扫描再抢占任务，在进程内直接通过线程异步处理。

锁定Sql参考：

复制

```
UPDATE 任务表_分表号 SET 状态 = 100,modifyTime = now() WHERE id = #{id} AND 状态 = 0
```

第二步：异步线程调用外部处理过程，调用外部处理完成后，接收返回子任务列表。通过数据库事务把父任务状态设置为已经完成，子任务落库。并把子任务加入线程池。

要点：保证子任务生成和父任务完成的事务性

第三步：子任务调度执行，并重新把新子任务落库，如果没有子任务返回，则整个流程结束。

**异常处理Worker**

异常解锁Worker来把长时间未处理完成的任务解锁，防止因为服务器重启，或线程池满造成的任务一直锁定无服务器执行。

补漏Worker防止服务器重启造成的线程池任务未执行完成，补漏程序重新锁定，触发执行。

**任务状态转换过程**

![8fe29b6356b54237ae9c6334e15b1327.png](https://s3.51cto.com/oss/202209/19/49aea0957d3df54b34e634b9cc282f4abf3d71.jpg "8fe29b6356b54237ae9c6334e15b1327.png")

#### 2.5.2 任务引擎数据库设计

任务表数据库结构设计示例（仅做示例使用，真实使用需要完善）

![6bd8c5ab7a0d40f780b76b8045a6ac70.png](https://s4.51cto.com/oss/202209/19/034efee64001768ec036563827a4dce062c345.jpg "6bd8c5ab7a0d40f780b76b8045a6ac70.png")

### 任务引擎数据库容灾

任务库使用分库分表，当一个库宕机，可以把路由到宕机库的流量重新散列到其他存活库中，可以手工配置，或通过系统监控来自动化容灾。如下图，当任务库2宕机后，可以通过修改配置，把任务库2流量路由到任务库1和3。补漏引擎继续扫描任务库2是因为当任务库2通过主从容灾恢复后，任务库2宕机时未来的及处理的任务可以得到补充处理。

![1d011519a7f64db494206a470c917c3c.jpeg](https://s2.51cto.com/oss/202209/19/48b107a8018e3488d1a71816b7bb3b927293f0.jpg "1d011519a7f64db494206a470c917c3c.jpeg")

### 任务引擎调度举例

比如用户购买了两个手机和一个电脑，手机和电脑分散在两个数据库，通过任务引擎先持久化任务，然后驱动拆分为两个子任务，并最终保证两个子任务一定成功，实现数据的最终一致性。整个执行过程的任务编排如下：

![47a4827efa46423fac2cf60db56e3675.jpeg](https://s3.51cto.com/oss/202209/19/549cc5d32ce41a9b4d8151dbeb95a91ac0075b.jpg "47a4827efa46423fac2cf60db56e3675.jpeg")

图7 任务引擎调度举例

### 任务引擎交互流程

![4bf94db94b5f4be6a09c6399a35e8ab0.png](https://s4.51cto.com/oss/202209/19/293c7225146e90b9f4a940a3db53a15d0b45ea.jpg "4bf94db94b5f4be6a09c6399a35e8ab0.png")

图8 任务引擎交互流程

### 总结

理解，首先 MCube 会依据模板缓存状态判断是否需要网络获取最新模板，当获取到模板后进行模板加载，加载阶段会将产物转换为视图树的结构，转换完成后将通过表达式引擎解析表达式并取得正确的值，通过事件解析引擎解析用户自定义事件并完成事件的绑定，完成解析赋值以及事件绑定后进行视图的渲染，最终将目标页面展示到屏幕。

#### 差异对比-异构数据的终极解决方案

只要有异构，一定会有差异的，为了保证差异的影响可控，终极方案还是要靠差异对比来解决。本文篇幅所限，不再展开，后续再单独成文。DB和Redis差异对比的大概过程为：接收库存变化消息，不断跟进对比Redis和DB的数据是否一致，如果连续稳定不一致，则进行数据修复，用DB数据来修改Redis的数据。

#### 常见问题答疑

问：第一步超卖校验Redis内存扣减，第二步扣减数据的持久化，中间断了怎么办？(例：服务重启)

答：如果是服务重启，会在服务器重启之前停止这台服务器的服务；但此方案并不能保证数据的绝对一致，比如扣减redis后，应用服务器故障直接死机，这种情况下的处理就需要更复杂的方案才能保证实时一致（目前没有采取更复杂方案），可以通过另一个方案使用库存数据和用户的订单数据进行数据比对修复，达到最终一致性。

# Reference
https://www.51cto.com/article/719033.html
https://segmentfault.com/a/1190000044141470#item-3-1