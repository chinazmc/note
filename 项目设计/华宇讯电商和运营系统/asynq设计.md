# 0x00 å‰è¨€ 

[asynq](https://github.com/hibiken/asynq)ï¼šGolang distributed task queue libraryï¼Œè®¸å¤šè®¾è®¡æ€æƒ³éƒ½æ¥è‡ª[sidekiq](https://github.com/mperham/sidekiq)ã€‚[å®˜æ–¹æ–‡æ¡£](https://github.com/hibiken/asynq/wiki)ç»™å‡ºçš„ç‰¹ç‚¹å¦‚ä¸‹ï¼ˆçœç•¥äº†è‹¥å¹²ï¼‰ï¼š

- ä»»åŠ¡å·²å†™å…¥Redisåä¼šæŒä¹…åŒ–ï¼ˆæ”¯æŒRedis Cluster/Sentinelsï¼‰
- ä»»åŠ¡æ‰§è¡Œå¤±è´¥è‡ªåŠ¨ retry
- æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§æƒé‡ï¼ˆåŠ æƒä¼˜å…ˆçº§é˜Ÿåˆ—ï¼‰
- æ”¯æŒå®šæ—¶å‘é€ä»»åŠ¡
- å¯ä½¿ç”¨ unique-option ä¾†é¿å…ä»»åŠ¡é‡å¤æ‰§è¡Œ
- UIåŠå®¢æˆ·ç«¯ã€metricsæ”¯æŒï¼ˆCLIæ£€æŸ¥å’Œè¿œç¨‹æ§åˆ¶é˜Ÿåˆ—å’Œä»»åŠ¡ï¼‰
- æ”¯æŒä»»åŠ¡è®¾ç½®æ‰§è¡Œæ—¶é—´oræœ€é•¿å¯è¿è¡Œçš„æ—¶é—´

åº“çš„ä½¿ç”¨ç¤ºä¾‹[åœ¨æ­¤](https://github.com/hibiken/asynq/wiki/Getting-Started)ï¼Œæœ¬æ–‡åŸºäº`v0.23.0`[ç‰ˆæœ¬](https://github.com/hibiken/asynq/releases/tag/v0.23.0)

#### asynqæ¶æ„ 

![arch](https://raw.githubusercontent.com/pandaychen/pandaychen.github.io/master/blog_img/asyncq/asyncq-arch.jpg)

## 0x01 ä»£ç åˆ†æ 

asynqæ•´ä½“æµç¨‹ä¸Šå’Œå…ˆå‰åˆ†æçš„ä¸­é—´ä»¶å¤§åŒå°å¼‚ï¼Œå¹¶ä¸”è¯¥ä¸­é—´ä»¶ä¸¥é‡ä¾èµ–Redisï¼Œæ‰€æœ‰çš„åŸå­åŒ–é€»è¾‘éƒ½æ˜¯é€šè¿‡luaè„šæœ¬å®ç°çš„ï¼ˆå¦‚ä»»åŠ¡çš„å‡ºå…¥é˜Ÿåˆ—ç­‰ç­‰ï¼‰ï¼ŒæŒ‰ç…§ä»»åŠ¡çš„çŠ¶æ€åˆ’åˆ†äº†ä¸åŒçš„redisæ•°æ®ç»“æ„åŠ[é€»è¾‘](https://github.com/hibiken/asynq/blob/master/internal/rdb/rdb.go)ï¼š

- activeï¼šasynq:{}:active LISTç±»å‹
- pendingï¼šasynq:{}:pending LISTç±»å‹
- leaseï¼šasynq:{}:lease SortedSetç±»å‹
- completedï¼šasynq:{}: SortedSetç±»å‹
- pausedï¼šasynq:{}:pausedï¼šHASHTABLEç±»å‹

æ­¤å¤–ï¼Œè¿˜æœ‰å„ç§ä¸åŒç±»å‹çš„ç»“æ„ï¼Œç”¨æ¥è®°å½•ä»»åŠ¡æ‰§è¡Œçš„çŠ¶æ€ã€è®¡æ•°å™¨ç­‰ç­‰
![[Pasted image 20240220144753.png]]

#### ä»»åŠ¡æµ

![flow](https://raw.githubusercontent.com/pandaychen/pandaychen.github.io/master/blog_img/asyncq/asyncq-flow.png)

#### ä»»åŠ¡æ“ä½œçš„Rediså°è£… 

1ã€[`dequeueCmd`](https://github.com/hibiken/asynq/blob/master/internal/rdb/rdb.go#L204)ï¼šç”¨äºæŠŠä»»åŠ¡ä»`pending`Listå–å‡ºï¼Œæ”¾åˆ°`active`Listä¸­

```go
// Input:
// KEYS[1] -> asynq:{<qname>}:pending
// KEYS[2] -> asynq:{<qname>}:paused
// KEYS[3] -> asynq:{<qname>}:active
// KEYS[4] -> asynq:{<qname>}:lease
// --
// ARGV[1] -> initial lease expiration Unix time
// ARGV[2] -> task key prefix
//
// Output:
// Returns nil if no processable task is found in the given queue.
// Returns an encoded TaskMessage.
//
// Note: dequeueCmd checks whether a queue is paused first, before
// calling RPOPLPUSH to pop a task from the queue.
var dequeueCmd = redis.NewScript(`
if redis.call("EXISTS", KEYS[2]) == 0 then
	local id = redis.call("RPOPLPUSH", KEYS[1], KEYS[3])
	if id then
		local key = ARGV[2] .. id
		redis.call("HSET", key, "state", "active")
		redis.call("HDEL", key, "pending_since")
		redis.call("ZADD", KEYS[4], ARGV[1], id)
		return redis.call("HGET", key, "msg")
	end
end
return nil`)
```

2ã€`markAsCompleteCmd`æ–¹æ³•ï¼šä»»åŠ¡æˆåŠŸå¤„ç†å®Œæˆï¼Œé€šè¿‡`HSET`æ›´æ–°çŠ¶æ€ï¼ŒåŒæ—¶åˆ é™¤`active`LISTçš„æ•°æ®

```Go
// KEYS[1] -> asynq:{<qname>}:active
// KEYS[2] -> asynq:{<qname>}:lease
// KEYS[3] -> asynq:{<qname>}:completed
// KEYS[4] -> asynq:{<qname>}:t:<task_id>
// KEYS[5] -> asynq:{<qname>}:processed:<yyyy-mm-dd>
// KEYS[6] -> asynq:{<qname>}:processed
//
// ARGV[1] -> task ID
// ARGV[2] -> stats expiration timestamp
// ARGV[3] -> task exipration time in unix time
// ARGV[4] -> task message data
// ARGV[5] -> max int64 value
var markAsCompleteCmd = redis.NewScript(`
if redis.call("LREM", KEYS[1], 0, ARGV[1]) == 0 then
  return redis.error_reply("NOT FOUND")
end
if redis.call("ZREM", KEYS[2], ARGV[1]) == 0 then
  return redis.error_reply("NOT FOUND")
end
if redis.call("ZADD", KEYS[3], ARGV[3], ARGV[1]) ~= 1 then
  redis.redis.error_reply("INTERNAL")
end
redis.call("HSET", KEYS[4], "msg", ARGV[4], "state", "completed")
local n = redis.call("INCR", KEYS[5])
if tonumber(n) == 1 then
	redis.call("EXPIREAT", KEYS[5], ARGV[2])
end
local total = redis.call("GET", KEYS[6])
if tonumber(total) == tonumber(ARGV[5]) then
	redis.call("SET", KEYS[6], 1)
else
	redis.call("INCR", KEYS[6])
end
return redis.status_reply("OK")
`)
```

#### æ ¸å¿ƒç»“æ„ 

1ã€`processor`ç»“æ„  

```Go
type processor struct {
	logger *log.Logger
	broker base.Broker
	clock  timeutil.Clock

	handler   Handler
	baseCtxFn func() context.Context

	queueConfig map[string]int

	// orderedQueues is set only in strict-priority mode.
	orderedQueues []string

	retryDelayFunc RetryDelayFunc
	isFailureFunc  func(error) bool

	errHandler ErrorHandler

	shutdownTimeout time.Duration

	// channel via which to send sync requests to syncer.
	syncRequestCh chan<- *syncRequest

	// rate limiter to prevent spamming logs with a bunch of errors.
	errLogLimiter *rate.Limiter

	// sema is a counting semaphore to ensure the number of active workers
	// does not exceed the limit.
	sema chan struct{}

	// channel to communicate back to the long running "processor" goroutine.
	// once is used to send value to the channel only once.
	done chan struct{}
	once sync.Once

	// quit channel is closed when the shutdown of the "processor" goroutine starts.
	quit chan struct{}

	// abort channel communicates to the in-flight worker goroutines to stop.
	abort chan struct{}

	// cancelations is a set of cancel functions for all active tasks.
	cancelations *base.Cancelations

	starting chan<- *workerInfo
	finished chan<- *base.TaskMessage
}

```

#### ä»»åŠ¡çš„çŠ¶æ€ 

æ¯ä¸ªä»»åŠ¡çš„å”¯ä¸€key`asynq:{<qname>}:t:<task_id>`ï¼Œåœ¨Redisæ•°æ®ç»“æ„ä¸ºHashTableï¼Œæœ‰å¦‚ä¸‹å­—æ®µï¼š

- `msg`ï¼šä»»åŠ¡å…³è”æ•°æ®
- `state`ï¼šä»»åŠ¡çŠ¶æ€ï¼ˆ`pending`ã€`active`ã€`completed`ã€`aggregating`ã€`scheduled`ã€`retry`ã€`archived`ï¼‰
- `pending_since`ï¼š
- `unique_key`ï¼š
- `group`ï¼š
- `result`ï¼š

1ã€[`Enqueue`](https://github.com/hibiken/asynq/blob/master/internal/rdb/rdb.go#L96)æ–¹æ³•ï¼Œå…³è”`enqueueCmd`  

```Go
// enqueueCmd enqueues a given task message.
//
// Input:
// KEYS[1] -> asynq:{<qname>}:t:<task_id>
// KEYS[2] -> asynq:{<qname>}:pending
// --
// ARGV[1] -> task message data
// ARGV[2] -> task ID
// ARGV[3] -> current unix time in nsec
//
// Output:
// Returns 1 if successfully enqueued
// Returns 0 if task ID already exists
var enqueueCmd = redis.NewScript(`
if redis.call("EXISTS", KEYS[1]) == 1 then
	return 0
end
redis.call("HSET", KEYS[1],
           "msg", ARGV[1],
           "state", "pending",
           "pending_since", ARGV[3])
redis.call("LPUSH", KEYS[2], ARGV[2])
return 1
`)
```

2ã€`enqueueUniqueCmd`  

```Go
// enqueueUniqueCmd enqueues the task message if the task is unique.
//
// KEYS[1] -> unique key
// KEYS[2] -> asynq:{<qname>}:t:<taskid>
// KEYS[3] -> asynq:{<qname>}:pending
// --
// ARGV[1] -> task ID
// ARGV[2] -> uniqueness lock TTL
// ARGV[3] -> task message data
// ARGV[4] -> current unix time in nsec
//
// Output:
// Returns 1 if successfully enqueued
// Returns 0 if task ID conflicts with another task
// Returns -1 if task unique key already exists
var enqueueUniqueCmd = redis.NewScript(`
local ok = redis.call("SET", KEYS[1], ARGV[1], "NX", "EX", ARGV[2])
if not ok then
  return -1 
end
if redis.call("EXISTS", KEYS[2]) == 1 then
  return 0
end
redis.call("HSET", KEYS[2],
           "msg", ARGV[3],
           "state", "pending",
           "pending_since", ARGV[4],
           "unique_key", KEYS[1])
redis.call("LPUSH", KEYS[3], ARGV[1])
return 1
`)
```

3ã€`dequeueCmd`  

```Go

// Input:
// KEYS[1] -> asynq:{<qname>}:pending
// KEYS[2] -> asynq:{<qname>}:paused
// KEYS[3] -> asynq:{<qname>}:active
// KEYS[4] -> asynq:{<qname>}:lease
// --
// ARGV[1] -> initial lease expiration Unix time
// ARGV[2] -> task key prefix
//
// Output:
// Returns nil if no processable task is found in the given queue.
// Returns an encoded TaskMessage.
//
// Note: dequeueCmd checks whether a queue is paused first, before
// calling RPOPLPUSH to pop a task from the queue.
var dequeueCmd = redis.NewScript(`
if redis.call("EXISTS", KEYS[2]) == 0 then
	local id = redis.call("RPOPLPUSH", KEYS[1], KEYS[3])
	if id then
		local key = ARGV[2] .. id
		redis.call("HSET", key, "state", "active")
		redis.call("HDEL", key, "pending_since")
		redis.call("ZADD", KEYS[4], ARGV[1], id)
		return redis.call("HGET", key, "msg")
	end
end
return nil`)
```

ä¸¾ä¾‹æ¥è¯´ï¼Œredisæ•°æ®å¦‚ä¸‹ï¼š

```bash
127.0.0.1:6379[1]> keys *
 1) "asynq:servers:{VM_120_245_centos:20022:69678348-e2e8-4a40-a729-6f50b8180194}"
 2) "asynq:{critical}:processed:2022-10-17"
 3) "asynq:servers"
 4) "asynq:{low}:scheduled"
 5) "asynq:{low}:processed:2022-10-17"
 6) "asynq:workers"
 7) "asynq:{critical}:processed:2022-10-08"
 8) "dq_queue_order"
 9) "asynq:{low}:processed:2022-10-08"
10) "1570239831121"
11) "15702398321"
12) "asynq:queues"
13) "asynq:{default}:processed:2022-10-08"
```

#### æ ¸å¿ƒæµç¨‹ 

1ã€`processor.exec`  
asynqæ²¡æœ‰ä½¿ç”¨Â `brpop/rpop`Â æŒ‡ä»¤ï¼ˆå‰è€…é˜»å¡ï¼Œåè€…è½®è¯¢ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡ channel å®ç°ä¿¡å·é‡å»æ§åˆ¶å¯¹ Redis çš„è½®è¯¢ã€‚å‚è§ä¸‹é¢çš„`processor.exec`æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç‹¬ç«‹è¿è¡Œï¼Œä¼šå…ˆå°è¯•è·å–ä¸€ä¸ªå…è®¸ç»§ç»­æ‰§è¡Œçš„ä¿¡å·ï¼Œå¦‚æœæœ‰åˆ™è°ƒç”¨ brokerçš„`Dequeue`Â æ–¹æ³•æŸ¥è¯¢å¾…æ‰§è¡Œçš„ä»»åŠ¡ä¿¡æ¯ï¼Œå¦åˆ™å°±åœä¸‹æ¥ç­‰å¾…ä¿¡å·ã€‚å¦‚æœé˜Ÿåˆ—æ˜¯ç©ºçš„ï¼Œé‚£ä¹ˆä¼š`time.Sleep(time.Second)`ï¼Œä»¥å…ä¸æ–­çš„æŸ¥è¯¢ Redis ã€‚æ­¤å¤–ï¼Œæ‰§è¡Œä¿¡å·çš„ä¸ªæ•°ä¹Ÿæ˜¯å¯é…ç½®ï¼ˆé»˜è®¤æœºå™¨æ ¸æ•°ï¼‰ï¼Œè¿™é‡Œå°±æ˜¯æ™®é€šçš„é™åˆ¶å–ä»»åŠ¡å¹¶å‘

```Go
// exec pulls a task out of the queue and starts a worker goroutine to
// process the task.
func (p *processor) exec() {
	select {
	case <-p.quit:
		return
	case p.sema <- struct{}{}: // acquire token
		qnames := p.queues()

        //ä»brokerä¸­å–ä»»åŠ¡æ•°æ®
		msg, leaseExpirationTime, err := p.broker.Dequeue(qnames...)
		switch {
		case errors.Is(err, errors.ErrNoProcessableTask):
			p.logger.Debug("All queues are empty")
			// Queues are empty, this is a normal behavior.
			// Sleep to avoid slamming redis and let scheduler move tasks into queues.
			// Note: We are not using blocking pop operation and polling queues instead.
			// This adds significant load to redis.
			time.Sleep(time.Second)
			<-p.sema // release token
			return
		case err != nil:
			if p.errLogLimiter.Allow() {
				p.logger.Errorf("Dequeue error: %v", err)
			}
			<-p.sema // release token
			return
		}

		lease := base.NewLease(leaseExpirationTime)
		deadline := p.computeDeadline(msg)
		p.starting <- &workerInfo{msg, time.Now(), deadline, lease}
		go func() {
			defer func() {
				p.finished <- msg
				<-p.sema // release token
			}()

			ctx, cancel := asynqcontext.New(p.baseCtxFn(), msg, deadline)
			p.cancelations.Add(msg.ID, cancel)
			defer func() {
				cancel()
				p.cancelations.Delete(msg.ID)
			}()

			// check context before starting a worker goroutine.
			select {
			case <-ctx.Done():
				// already canceled (e.g. deadline exceeded).
				p.handleFailedMessage(ctx, lease, msg, ctx.Err())
				return
			default:
			}

			resCh := make(chan error, 1)
			go func() {
				task := newTask(
					msg.Type,
					msg.Payload,
					&ResultWriter{
						id:     msg.ID,
						qname:  msg.Queue,
						broker: p.broker,
						ctx:    ctx,
					},
				)
				resCh <- p.perform(ctx, task)
			}()

			select {
			case <-p.abort:
				// time is up, push the message back to queue and quit this worker goroutine.
				p.logger.Warnf("Quitting worker. task id=%s", msg.ID)
				p.requeue(lease, msg)
				return
			case <-lease.Done():
				cancel()
				p.handleFailedMessage(ctx, lease, msg, ErrLeaseExpired)
				return
			case <-ctx.Done():
				p.handleFailedMessage(ctx, lease, msg, ctx.Err())
				return
			case resErr := <-resCh:
				if resErr != nil {
					p.handleFailedMessage(ctx, lease, msg, resErr)
					return
				}
				p.handleSucceededMessage(lease, msg)
			}
		}()
	}
}
```

2ã€ä»»åŠ¡æ‰§è¡Œ  
ä»»åŠ¡çš„æ‰§è¡Œä¹Ÿæ˜¯å¼‚æ­¥çš„

```Go
func (p *processor) exec() {
    //...
    go func() {
                    task := newTask(
                        msg.Type,
                        msg.Payload,
                        &ResultWriter{
                            id:     msg.ID,
                            qname:  msg.Queue,
                            broker: p.broker,
                            ctx:    ctx,
                        },
                    )
                    resCh <- p.perform(ctx, task)
                }()

    //...
}
// perform calls the handler with the given task.
// If the call returns without panic, it simply returns the value,
// otherwise, it recovers from panic and returns an error.
func (p *processor) perform(ctx context.Context, task *Task) (err error) {
	defer func() {
		if x := recover(); x != nil {
			p.logger.Errorf("recovering from panic. See the stack trace below for details:\n%s", string(debug.Stack()))
			_, file, line, ok := runtime.Caller(1) // skip the first frame (panic itself)
			if ok && strings.Contains(file, "runtime/") {
				// The panic came from the runtime, most likely due to incorrect
				// map/slice usage. The parent frame should have the real trigger.
				_, file, line, ok = runtime.Caller(2)
			}

			// Include the file and line number info in the error, if runtime.Caller returned ok.
			if ok {
				err = fmt.Errorf("panic [%s:%d]: %v", file, line, x)
			} else {
				err = fmt.Errorf("panic: %v", x)
			}
		}
	}()
	return p.handler.ProcessTask(ctx, task)
}

func (fn HandlerFunc) ProcessTask(ctx context.Context, task *Task) error {
	return fn(ctx, task)
}
```

3ã€ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æœ  
å¼€å¤´åˆ—ä¸¾çš„ï¼Œasynqæ”¯æŒä»»åŠ¡çš„æ§åˆ¶æ ¸å¿ƒå°±åœ¨æ­¤å®ç°ï¼Œå¦‚ï¼›

- `p.abort`ï¼š
- `lease.Done()`ï¼šä»»åŠ¡æ‰§è¡Œè¿‡æœŸï¼ˆè¶…æ—¶ï¼‰äº†
- `ctx.Done()`ï¼š
- `<-resCh`ï¼šä»»åŠ¡æ­£å¸¸ç»“æŸï¼Œè·å–ç»“æœæˆåŠŸ/å¤±è´¥

```GOLANG
func (p *processor) exec() {
    //...
    select {
			case <-p.abort:
				// time is up, push the message back to queue and quit this worker goroutine.
				p.logger.Warnf("Quitting worker. task id=%s", msg.ID)
				p.requeue(lease, msg)
				return
			case <-lease.Done():
				cancel()
				p.handleFailedMessage(ctx, lease, msg, ErrLeaseExpired)
				return
			case <-ctx.Done():
				p.handleFailedMessage(ctx, lease, msg, ctx.Err())
				return
			case resErr := <-resCh:
				if resErr != nil {
					p.handleFailedMessage(ctx, lease, msg, resErr)
					return
				}
				p.handleSucceededMessage(lease, msg)
			}
    //...
}

//å¤„ç†ç»“æœ
func (p *processor) handleSucceededMessage(l *base.Lease, msg *base.TaskMessage) {
	if msg.Retention > 0 {
		//
		p.markAsComplete(l, msg)
	} else {
		p.markAsDone(l, msg)
	}
}
```

æ³¨æ„ï¼š`markAsComplete`æ˜¯

4ã€å¤„ç†ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼š`handleFailedMessage`  
æœ€ç»ˆï¼Œéœ€è¦retryé‡è¯•çš„ä»»åŠ¡åœ¨`p.retry`æ–¹æ³•ä¸­è¢«æ‰“ä¸Šä¸‹ä¸€æ¬¡é‡è¯•çš„æ—¶é—´ï¼Œç„¶ååœ¨`retryCmd`ä¸­é€šè¿‡`ZADD`æ·»åŠ åˆ°`asynq:{<qname>}:retry`å¯¹åº”çš„SortedSetä¸­

```Go
func (p *processor) handleFailedMessage(ctx context.Context, l *base.Lease, msg *base.TaskMessage, err error) {
	if p.errHandler != nil {
		p.errHandler.HandleError(ctx, NewTask(msg.Type, msg.Payload), err)
	}
	if !p.isFailureFunc(err) {
		// retry the task without marking it as failed
		p.retry(l, msg, err, false /*isFailure*/)
		return
	}
	if msg.Retried >= msg.Retry || errors.Is(err, SkipRetry) {
		p.logger.Warnf("Retry exhausted for task id=%s", msg.ID)
		p.archive(l, msg, err)
	} else {
		//è°ƒç”¨p.retryé‡è¯•
		p.retry(l, msg, err, true /*isFailure*/)
	}
}

func (p *processor) retry(l *base.Lease, msg *base.TaskMessage, e error, isFailure bool) {
	if !l.IsValid() {
		// If lease is not valid, do not write to redis; Let recoverer take care of it.
		return
	}
	ctx, _ := context.WithDeadline(context.Background(), l.Deadline())

	//è®¡ç®—ä¸‹ä¸€æ¬¡é‡è¯•è§¦å‘çš„æ—¶é—´
	d := p.retryDelayFunc(msg.Retried, e, NewTask(msg.Type, msg.Payload))
	retryAt := time.Now().Add(d)

	//è°ƒç”¨brokerçš„retryçš„æ–¹æ³•
	err := p.broker.Retry(ctx, msg, retryAt, e.Error(), isFailure)
	if err != nil {
		errMsg := fmt.Sprintf("Could not move task id=%s from %q to %q", msg.ID, base.ActiveKey(msg.Queue), base.RetryKey(msg.Queue))
		p.logger.Warnf("%s; Will retry syncing", errMsg)
		p.syncRequestCh <- &syncRequest{
			fn: func() error {
				return p.broker.Retry(ctx, msg, retryAt, e.Error(), isFailure)
			},
			errMsg:   errMsg,
			deadline: l.Deadline(),
		}
	}
}

// Retry moves the task from active to retry queue.
// It also annotates the message with the given error message and
// if isFailure is true increments the retried counter.
func (r *RDB) Retry(ctx context.Context, msg *base.TaskMessage, processAt time.Time, errMsg string, isFailure bool) error {
	var op errors.Op = "rdb.Retry"
	now := r.clock.Now()
	modified := *msg
	if isFailure {
		modified.Retried++
	}
	modified.ErrorMsg = errMsg
	modified.LastFailedAt = now.Unix()		//ä¸‹ä¸€æ¬¡è§¦å‘çš„æ—¶é—´ï¼Œå±æ€§å…³è”äºRedisçš„SortSet
	encoded, err := base.EncodeMessage(&modified)
	if err != nil {
		return errors.E(op, errors.Internal, fmt.Sprintf("cannot encode message: %v", err))
	}
	expireAt := now.Add(statsTTL)
	keys := []string{
		base.TaskKey(msg.Queue, msg.ID),
		base.ActiveKey(msg.Queue),
		base.LeaseKey(msg.Queue),
		base.RetryKey(msg.Queue),
		base.ProcessedKey(msg.Queue, now),
		base.FailedKey(msg.Queue, now),
		base.ProcessedTotalKey(msg.Queue),
		base.FailedTotalKey(msg.Queue),
	}
	argv := []interface{}{
		msg.ID,
		encoded,
		processAt.Unix(),
		expireAt.Unix(),
		isFailure,
		int64(math.MaxInt64),
	}
	return r.runScript(ctx, op, retryCmd, keys, argv...)
}

// KEYS[1] -> asynq:{<qname>}:t:<task_id>
// KEYS[2] -> asynq:{<qname>}:active
// KEYS[3] -> asynq:{<qname>}:lease
// KEYS[4] -> asynq:{<qname>}:retry
// KEYS[5] -> asynq:{<qname>}:processed:<yyyy-mm-dd>
// KEYS[6] -> asynq:{<qname>}:failed:<yyyy-mm-dd>
// KEYS[7] -> asynq:{<qname>}:processed
// KEYS[8] -> asynq:{<qname>}:failed
// -------
// ARGV[1] -> task ID
// ARGV[2] -> updated base.TaskMessage value
// ARGV[3] -> retry_at UNIX timestamp
// ARGV[4] -> stats expiration timestamp
// ARGV[5] -> is_failure (bool)
// ARGV[6] -> max int64 value
var retryCmd = redis.NewScript(`
if redis.call("LREM", KEYS[2], 0, ARGV[1]) == 0 then  
  return redis.error_reply("NOT FOUND")
end
if redis.call("ZREM", KEYS[3], ARGV[1]) == 0 then
  return redis.error_reply("NOT FOUND")
end
redis.call("ZADD", KEYS[4], ARGV[3], ARGV[1])
redis.call("HSET", KEYS[1], "msg", ARGV[2], "state", "retry")
if tonumber(ARGV[5]) == 1 then
	local n = redis.call("INCR", KEYS[5])
	if tonumber(n) == 1 then
		redis.call("EXPIREAT", KEYS[5], ARGV[4])
	end
	local m = redis.call("INCR", KEYS[6])
	if tonumber(m) == 1 then
		redis.call("EXPIREAT", KEYS[6], ARGV[4])
	end
    local total = redis.call("GET", KEYS[7])
    if tonumber(total) == tonumber(ARGV[6]) then
    	redis.call("SET", KEYS[7], 1)
    	redis.call("SET", KEYS[8], 1)
    else
    	redis.call("INCR", KEYS[7])
    	redis.call("INCR", KEYS[8])
    end
end
return redis.status_reply("OK")`)
```

## 0x02 metricsæŒ‡æ ‡ 

æœ¬å°èŠ‚ä¸»è¦çœ‹ä¸‹asynqå®šä¹‰çš„[metrics](https://github.com/hibiken/asynq/tree/master/x/metrics)ï¼Œä¸€æ¬¾å¼‚æ­¥é˜Ÿåˆ—ä¸­é—´ä»¶éœ€è¦è€ƒè™‘å“ªäº›æŒ‡æ ‡

#### æŒ‡æ ‡å®šä¹‰ä¸è¯´æ˜ 

```Go
// Descriptors used by QueueMetricsCollector
var (
	tasksQueuedDesc = prometheus.NewDesc(
		prometheus.BuildFQName(namespace, "", "tasks_enqueued_total"),
		"Number of tasks enqueued; broken down by queue and state.",
		[]string{"queue", "state"}, nil,
	)

	queueSizeDesc = prometheus.NewDesc(
		prometheus.BuildFQName(namespace, "", "queue_size"),
		"Number of tasks in a queue",
		[]string{"queue"}, nil,
	)

	queueLatencyDesc = prometheus.NewDesc(
		prometheus.BuildFQName(namespace, "", "queue_latency_seconds"),
		"Number of seconds the oldest pending task is waiting in pending state to be processed.",
		[]string{"queue"}, nil,
	)

	queueMemUsgDesc = prometheus.NewDesc(
		prometheus.BuildFQName(namespace, "", "queue_memory_usage_approx_bytes"),
		"Number of memory used by a given queue (approximated number by sampling).",
		[]string{"queue"}, nil,
	)

	tasksProcessedTotalDesc = prometheus.NewDesc(
		prometheus.BuildFQName(namespace, "", "tasks_processed_total"),
		"Number of tasks processed (both succeeded and failed); broken down by queue",
		[]string{"queue"}, nil,
	)

	tasksFailedTotalDesc = prometheus.NewDesc(
		prometheus.BuildFQName(namespace, "", "tasks_failed_total"),
		"Number of tasks failed; broken down by queue",
		[]string{"queue"}, nil,
	)

	pausedQueues = prometheus.NewDesc(
		prometheus.BuildFQName(namespace, "", "queue_paused_total"),
		"Number of queues paused",
		[]string{"queue"}, nil,
	)
)
```

## 0x03 æ€»ç»“ 

æœ¬æ–‡ä»‹ç»äº†asynqçš„å®ç°ï¼Œasynqçš„ä»£ç éå¸¸å€¼å¾—ä¸€è¯»ï¼Œå®ç°æ€è·¯éå¸¸æ¸…æ™°


# çˆ†ç ´ ğŸ’¥ Asynq


æˆ‘åœ¨ Golang çš„ç”Ÿæ€é‡Œä¸€ç›´æ²¡æ‰¾åˆ°å¥½ç”¨çš„å»¶æ—¶ä»»åŠ¡æ–¹æ¡ˆï¼Œåœ¨ä¹‹å‰çš„å·¥ä½œä¸­éœ€è¦çš„æ—¶å€™ä¹Ÿæ˜¯è‡ªå·±[å®ç°äº†ä¸€ä¸ªç®€æ˜“æ–¹æ¡ˆ](https://www.jianshu.com/p/83f37db7b078)ï¼Œå®ƒæœ‰è¯¸å¤šé—®é¢˜ï¼Œæ¯”å¦‚éƒ¨ç½²å¤æ‚ï¼Œç¨³å®šæ€§ä¸å¤Ÿã€‚

ç›´åˆ° 2022 å¹´æˆ‘çŸ¥æ™“äº†Â [Asynq](https://github.com/hibiken/asynq)ã€‚

Asynq è¿™æ ·ä»‹ç»è‡ªå·±ï¼š

> Simple, reliable & efficient distributed task queue in Go
> 
> Go ä¸­ç®€å•ã€å¯é ã€é«˜æ•ˆçš„åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—
> 
> Asynq is a Go library for queueing tasks and processing them asynchronously with workers. It's backed by Redis and is designed to be scalable yet easy to get started.
> 
> Asynq æ˜¯ä¸€ä¸ª Go åº“ï¼Œç”¨äºæ’é˜Ÿä»»åŠ¡å¹¶é€šè¿‡å·¥ä½œè€…å¼‚æ­¥å¤„ç†è¿™äº›ä»»åŠ¡ã€‚å®ƒç”± Redis æ”¯æŒï¼Œè¢«è®¾è®¡æˆå¯æ‰©å±•ä¸”å®¹æ˜“ä¸Šæ‰‹ã€‚

Asynq è¿‡å»ä¸€å¹´åœ¨å…¬å¸ä¸šåŠ¡ä¸­è°ƒåº¦äº†è¶…è¿‡ 5000w ä¸ªä»»åŠ¡ï¼Œç¡®å®é«˜æ•ˆä¸”ç¨³å®šï¼Œå¹¶ä¸”ä½¿ç”¨çš„ Redis äººæ‰‹éƒ½æœ‰ï¼Œéƒ¨ç½²éš¾åº¦å¾ˆä½ã€‚

ç°åœ¨ç©ºä¸‹æ¥ç ”ç©¶ä¸‹å®ƒçš„å®ç°åŸç†ï¼Œå‘ç°æ¯”æƒ³è±¡ä¸­æ›´å¤æ‚ä¹Ÿæœ‰è¶£ã€‚

## åœ¨æ­¤ä¹‹å‰çš„æ€è€ƒ

åœ¨ç ”ç©¶ Asynq ä¹‹å‰ï¼Œæˆ‘ä¹Ÿå°è¯•è‡ªå·±æ€è€ƒäº†ä¸‹åº”è¯¥å¦‚ä½•å®ç°ï¼Œè¿™æ ·æ‰çŸ¥é“æœ‰å“ªäº›éš¾ç‚¹ï¼Œä»¥åŠ Asyncq å¦‚æ­¤è®¾è®¡æ˜¯ä¸ºäº†è§£å†³ä»€ä¹ˆé—®é¢˜ã€‚

å®ç°æ–¹æ¡ˆï¼šä½¿ç”¨æœ‰åºé›†åˆå­˜å‚¨å°†è¦åˆ°æœŸçš„ä»»åŠ¡ï¼Œå®šæ—¶ä»é›†åˆä¸­æ‹¿å–ä»»åŠ¡ï¼Œçœ‹èµ·æ¥æˆ‘ä»¬åªéœ€è¦ç”¨åˆ°ä¸€ä¸ªæ•°æ®ç»“æ„ï¼Œä¸€ä¸ª key å°±å¯ä»¥äº†ã€‚

é—®é¢˜ï¼š

1. å¦‚æœæœ‰å¤šä¸ªèŠ‚ç‚¹åŒæ—¶æ‰§è¡Œï¼Œé‚£ä¹ˆè¿™äº›èŠ‚ç‚¹å¯èƒ½ä¼šæ‹¿åˆ°åŒä¸€ä¸ªè¿‡æœŸçš„ä»»åŠ¡ï¼Œå¯¼è‡´é‡å¤æ‰§è¡Œã€‚
2. å¦‚æœä»»åŠ¡æ‰§è¡Œå¤±è´¥æˆ–è€…æ— å“åº”ï¼Œå¦‚ä½•é‡è¯•ï¼Ÿ

è§£å†³é—®é¢˜ 1 å¯ä»¥å…ˆæ‹¿å‡ºå†åˆ é™¤ï¼Œå¦‚æœæ²¡åˆ é™¤æˆåŠŸï¼Œè¯´æ˜å·²ç»æœ‰å…¶ä»–èŠ‚ç‚¹æ‹¿åˆ°äº†è¿™ä¸ªä»»åŠ¡ï¼Œåªæœ‰åˆ é™¤æˆåŠŸæ‰èƒ½æ‰§è¡Œã€‚

é—®é¢˜ 2 æ›´å¤æ‚ï¼Œç¨‹åºé€»è¾‘æ— æ³•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸ºç¨‹åºæœ¬èº«å°±ä¸ç¨³å®šï¼Œ æ‰€ä»¥ä»…ä»…ä½¿ç”¨é—®é¢˜ 1 çš„è§£å†³æ–¹æ¡ˆæ˜¯å®ç°ä¸äº†çš„ï¼Œå› ä¸ºåˆ é™¤åæ•°æ®å°±ä» Redis ä¸¢å¤±äº†ï¼Œè€Œç¨‹åºåˆæ— æ³•å¯é çš„è¿›è¡Œé‡è¯•ã€‚

æˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªæ–°çš„ key å­˜å‚¨ç­‰å¾…å“åº”çš„ä»»åŠ¡ï¼Œåœ¨ä»»åŠ¡è¶…æ—¶åé‡è¯•ã€‚ç°åœ¨é—®é¢˜å˜å¾—å¤æ‚èµ·æ¥äº†ï¼Œæ”¾å¼ƒæ€è€ƒï¼ŒæŠ„ç­”æ¡ˆå§ã€‚

å¸¦ç€è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹ Asyncq å®ƒæ˜¯å¦‚ä½•å®ç°çš„ã€‚

## Asynq æ€»ä½“æµç¨‹

### å…¥é˜Ÿ

- ä½¿ç”¨ æœ‰åºé›†åˆÂ `scheduled`Â è®°å½•å¼‚æ­¥ä»»åŠ¡ã€‚
- å¦‚æœä¸æ˜¯å»¶æ—¶ä»»åŠ¡ï¼ˆç«‹å³æ‰§è¡Œï¼‰ï¼Œåˆ™ç›´æ¥åŠ å…¥åˆ°Â `pending`Â é˜Ÿåˆ—ã€‚

### å‰è¿›

- ä½¿ç”¨Â `ZRANGEBYSCORE`Â å®šæ—¶ä»Â `scheduled`Â å’ŒÂ `retry`Â é˜Ÿåˆ—æŸ¥è¯¢åˆ°æœŸçš„ä»»åŠ¡ï¼Œå¹¶ä½¿ç”¨Â `ZREM`Â åˆ é™¤ ä»»åŠ¡ï¼Œå¹¶æ’å…¥åˆ°Â `pending`Â é˜Ÿåˆ—ã€‚ ï¼ˆï¼å¿…é¡»ä½¿ç”¨ script æ‰èƒ½æ»¡è¶³åŸå­æ€§ï¼‰

### å‡ºé˜Ÿ

- ä½¿ç”¨Â `RPOPLPUSH`Â å°†`pending`Â çš„ä»»åŠ¡æ”¾å…¥`active`Â é˜Ÿåˆ—ï¼Œå¹¶å°†ä»»åŠ¡æ”¾åœ¨æœ‰åºé›†åˆÂ `lease`ï¼ˆå»¶æ—¶ 30 sï¼‰

### æ‰§è¡Œä»»åŠ¡

- æˆåŠŸæ‰§è¡Œäº†ä¹‹å å°†ä»»åŠ¡ä»Â `active`Â å’ŒÂ `lease`Â ç§»é™¤ï¼Œç„¶åå­˜å…¥å½’æ¡£ã€‚
- æ‰§è¡Œå¤±è´¥ï¼Œæ‰§è¡Œ retryï¼šå°†ä»»åŠ¡ä»Â `active`Â å’ŒÂ `lease`Â ç§»é™¤ï¼Œï¼ˆå¦‚æœæ²¡æœ‰ç§»é™¤æˆåŠŸï¼Œåˆ™ä¸åšä»»ä½•å¤„ç†ï¼‰ï¼Œæ”¾å…¥æœ‰åºé›†åˆÂ `retry`Â ï¼ˆå»¶æ—¶ N sï¼‰
- å¦‚æœæœåŠ¡æ­£åœ¨é€€å‡ºåˆ™é‡å…¥é˜Ÿåˆ—ï¼šå°†ä»»åŠ¡ä»Â `active`Â ç§»é™¤ï¼Œä»`lease`Â ç§»é™¤ï¼Œæ·»åŠ åˆ°Â `pending`Â é˜Ÿåˆ—ã€‚
- è¶…æ—¶æ²¡æœ‰ ACKï¼šå®šæ—¶ä»Â `lease`Â å–å‡ºä»»åŠ¡ï¼Œæ£€æŸ¥æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œå¦‚æœæ²¡æœ‰è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°å°±æ‰§è¡Œ retryã€‚å¦åˆ™å°±å­˜æ¡£æ ‡è®°ä¸ºå¤±è´¥ã€‚ï¼ˆæ³¨æ„è¿™é‡Œå¯ä»¥ä¸ä½¿ç”¨ script å®ç°åŸå­æ“ä½œï¼Œå› ä¸º retry å‘½ä»¤æ˜¯å¹‚ç­‰çš„ã€‚ï¼‰

> æµç¨‹å›¾å¯èƒ½ç”»å¾—ä¸å¤Ÿå¥½ï¼Œå°†å°±çœ‹çœ‹è¾…åŠ©ç†è§£ã€‚

## è¦ç‚¹

### ä¿è¯åŸå­æ€§

> åŸå­æ€§æ˜¯æŒ‡æ“ä½œåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ä¸å¯è¢«ä¸­æ–­æˆ–åˆ†å‰²ï¼Œè¦ä¹ˆå…¨éƒ¨æ‰§è¡ŒæˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥å›æ»šï¼Œä¿è¯æ“ä½œçš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§ã€‚ åœ¨å¹¶å‘ç¯å¢ƒä¸‹ï¼ŒåŸå­æ€§æ˜¯ç¡®ä¿å¤šä¸ªçº¿ç¨‹åœ¨åŒæ—¶è®¿é—®å…±äº«èµ„æºæ—¶ï¼Œå¯¹å…±äº«èµ„æºçš„æ“ä½œä¸ä¼šç›¸äº’å¹²æ‰°ä»è€Œå¯¼è‡´æ•°æ®ä¸ä¸€è‡´ã€‚

ç”±äºåœ¨æŸä¸ªåŠ¨ä½œä¸­éœ€è¦æ“ä½œå¤šä¸ªé˜Ÿåˆ—ï¼Œä¸ºäº†å®ç°åŸå­æ€§ï¼Œåˆ™éœ€è¦ä½¿ç”¨ script å‘½ä»¤æ¥æ‰§è¡Œæ“ä½œï¼Œæ¯”å¦‚ä¸€æ¬¡å‡ºé˜Ÿåˆ—æ“ä½œå¦‚ä¸‹ï¼š

```go
var dequeueCmd = redis.NewScript(`
if redis.call("EXISTS", KEYS[2]) == 0 then
	local id = redis.call("RPOPLPUSH", KEYS[1], KEYS[3])
	if id then
		local key = ARGV[2] .. id
		redis.call("HSET", key, "state", "active")
		redis.call("HDEL", key, "pending_since")
		redis.call("ZADD", KEYS[4], ARGV[1], id)
		return redis.call("HGET", key, "msg")
	end
end
return nil`)


```

### ä¿è¯è‡³å°‘æ‰§è¡Œä¸€æ¬¡

ç”±äºç¨‹åºçš„å´©æºƒå¯èƒ½å‘ç”Ÿåœ¨ä»»ä½•åœ°æ–¹ï¼Œä¸ºäº†ä¿è¯ä¸ä¸¢æ•°æ®ï¼Œå’Œ MQ ä¸€æ ·ï¼Œæˆ‘ä»¬å¿…é¡»è®¾è®¡ä¸€ä¸ª ACKï¼ˆç¡®è®¤ Acknowledgementï¼‰æœºåˆ¶ï¼Œå¦‚æœè¶…è¿‡ä¸€æ®µæ—¶é—´ç¨‹åºæ²¡æœ‰åº”ç­”ï¼ˆæ— è®ºæˆåŠŸå’Œå¤±è´¥éƒ½ç®—åº”ç­”ï¼‰åˆ™éœ€è¦é‡è¯•ã€‚è¿™ä¹Ÿæ˜¯æ•´ä¸ªç³»ç»Ÿæœ€å¤æ‚çš„åœ°æ–¹ï¼Œå¯ä»¥è¯´å°†å¤æ‚åº¦æ‰©å¤§äº†å‡ å€ã€‚

åœ¨ asyncq ä¸­å‡ºé˜Ÿåˆ—æ—¶ï¼Œä¸å…‰ä½¿ç”¨Â `RPOPLPUSH`Â å°†Â `pending`Â çš„ä»»åŠ¡æ”¾å…¥Â `active`Â é˜Ÿåˆ—ï¼ŒåŒæ—¶ä¹Ÿä¼šå°†ä»»åŠ¡æ”¾åœ¨æœ‰åºé›†åˆÂ `lease`ï¼ˆé»˜è®¤å»¶æ—¶ 30 sï¼‰ï¼Œç„¶åå®šæ—¶ä»Â `lease`Â æŸ¥è¯¢å‡ºè¿‡æœŸçš„ä»»åŠ¡å¹¶é‡è¯•ã€‚

### é¿å…é‡å¤æ‰§è¡Œ

å¹¶å‘å¯èƒ½å¯¼è‡´åˆ¤æ–­å¤±æ•ˆè€Œé‡å¤æ‰§è¡Œï¼Œasynq åœ¨ä¸åŒåœºæ™¯ä½¿ç”¨ä¸åŒæœºåˆ¶æ¥é¿å…é‡å¤æ‰§è¡Œï¼š

- å‡ºé˜Ÿåˆ—ï¼šasyncq ä¸­ä½¿ç”¨äº† redis script å®ç°å¹¶å‘æ§åˆ¶ï¼ˆå…ˆæŸ¥è¯¢ååˆ é™¤ä¸¤æ­¥æ“ä½œï¼‰æ¥é¿å…ä¸€ä¸ªä»»åŠ¡è¢«å¤šæ¬¡æŸ¥è¯¢å‡ºæ¥å¹¶æ‰§è¡Œã€‚
- è¶…æ—¶é‡è¯•ï¼š1. å®šæ—¶ä»Â `lease`Â æŸ¥è¯¢å‡ºè¿‡æœŸçš„ä»»åŠ¡ï¼Œ2. å†æ£€æŸ¥é‡è¯•æ¬¡æ•°ä¹‹åé‡æ–°æ”¾å…¥Â `retry`Â é›†åˆï¼Œå¹¶ä»Â `active`Â å’ŒÂ `lease`Â ç§»é™¤ä»»åŠ¡ï¼Œ ç”±äºæ­¥éª¤ 1 å’Œ 2 æ— æ³•åƒå‡ºé˜Ÿåˆ—æ—¶åšåœ¨ä¸€ä¸ª script ä¸­ï¼Œæ‰€ä»¥å½“å¤šä¸ª pod å¹¶å‘æŸ¥è¯¢æ—¶ä¼šæŸ¥è¯¢åˆ°åŒä¸€ä¸ªä»»åŠ¡ï¼Œå¦‚æœéƒ½å¾€Â `retry`Â é›†åˆæ”¾å…¥çš„è¯å°±ä¼šå¯¼è‡´é‡å¤æ‰§è¡Œ ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥å…ˆä»Â `active`Â å’ŒÂ `lease`Â ç§»é™¤ä»»åŠ¡ï¼Œåªæœ‰å½“ç§»é™¤æˆåŠŸä¹‹åæ‰ä¼šæ”¾å…¥Â `retry`Â é›†åˆã€‚

# Reference
https://pandaychen.github.io/2021/08/18/A-GOLANG-ASYNQ-ANALYSIS/
https://blog.bysir.top/blogs/boom_asynq/

