# 背景
刚才说了限流是我们保证服务稳定性的手段之一，但是他并不是所有场景的稳定性都能保证，和他名字一样他只能在大流量或者突发流量的场景下才能发挥出自己的作用。比如我们的系统最高支持100QPS，但是突然有1000QPS请求打了进来，可能这个时候系统就会直接挂掉，导致后面一个请求都处理不了，但是如果我们有限流的手段，无论他有多大的QPS，我们都只处理100QPS的请求，其他请求都直接拒绝掉，虽然有900的QPS的请求我们拒绝掉了，但是我们的系统没有挂掉，我们系统仍然可以不断的处理后续的请求，这个是我们所期望的。有同学可能会说，现在都上的云了，服务的动态伸缩应该是特别简单的吧，如果我们发现流量特别大的时候，自动扩容机器到可以支撑目标QPS那不就不需要限流了吗？其实有这个想法的同学应该还挺多的，有些同学可能被一些吹牛的文章给唬到了，所以才会这么想，这个想法在特别理想化的时候是可以实现的，但是在现实中其实有下面几个问题：

-   扩容是需要时间。扩容简单来说就是搞一个新的机器，然后重新发布代码，做java的同学应该是知道发布成功一个代码的时间一般不是以秒级计算，而是以分钟级别计算，有时候你扩容完成，说不定流量尖峰都过去了。
-   扩容到多少是个特别复杂的问题。扩容几台机器这个是比较复杂的，需要大量的压测计算，以及整条链路上的一个扩容，如果扩容了你这边的机器之后，其他团队的机器没有扩容可能最后还是有瓶颈这个也是一个问题。

所以单纯的扩容是解决不了这个问题的，限流仍然是我们必须掌握的技能！

# 基本算法
想要掌握好限流，就需要先掌握他的一些基本算法，限流的算法基本上分为三种，计数器，漏斗，令牌桶，其他的一些都是在这些基础上进行演变而来。

## 计数器算法

首先我们来说一下计数器算法，这个算法比较简单粗暴，我们只需要一个累加变量，然后每隔一秒钟去刷新这个累加变量，然后再判断这个累加变量是否大于我们的最大QPS。

```text
    int curQps = 0;
    long lastTime = System.currentTimeMillis();
    int maxQps = 100;
    Object lock = new Object();
    boolean check(){
        synchronized (lock){
            long now = System.currentTimeMillis();
            if (now - lastTime > 1000){
                lastTime = now;
                curQps = 0;
            }
            curQps++;
            if (curQps > maxQps){
                return false;
            }
        }
        return true;
    }
```

这个代码比较简单，我们定义了当前的qps,以及上一次刷新累加变量的时间，还有我们的最大qps和我们的lock锁，我们每次检查的时候，都需要判断是否需要刷新，如果需要刷新那么需要把时间和qps都进行重置，然后再进行qps的累加判断。

这个算法因为太简单了所以带来的问题也是特别明显，如果我们最大的qps是100，在0.99秒的时候来了100个请求，然后在1.01秒的时候又来了100个请求，这个是可以通过我们的程序的，但是我们其实在0.03秒之内通过了200个请求，这个肯定不符合我们的预期，因为很有可能这200个请求直接就会将我们机器给打挂。

## 滑动窗口计数器

为了解决上面的临界的问题，我们这里可以使用滑动窗口来解决这个问题：

![](https://pic4.zhimg.com/80/v2-cbfa361180188ce9fbd427efe44c6e87_720w.webp)

  
如上图所示，我们将1s的普通计数器，分成了5个200ms，我们统计的当前qps都需要统计最近的5个窗口的所有qps，再回到刚才的问题，0.99秒和1.01秒其实都在我们的最近5个窗口之内，所以这里不会出现刚才的临界的突刺问题。

其实换个角度想，我们普通的计数器其实就是窗口数量为1的滑动窗口计数器，只要我们分的窗口越多，我们使用计数器方案的时候统计就会越精确，但是相对来说维护的窗口的成本就会增加，等会我们介绍sentinel的时候会详细介绍他是怎么实现滑动窗口计数的。

## 漏斗算法

解决计数器中临界的突刺问题也可以通过漏斗算法来实现，如下图所示：

  

![](https://pic4.zhimg.com/80/v2-734c62e60831c28b1fad26899f941307_720w.webp)

  

在漏斗算法中我们需要关注漏桶和匀速流出，不论流量有多大都会先到漏桶中，然后以均匀的速度流出。如何在代码中实现这个匀速呢？比如我们想让匀速为100q/s，那么我们可以得到每流出一个流量需要消耗10ms，类似一个队列，每隔10ms从队列头部取出流量进行放行，而我们的队列也就是漏桶，当流量大于队列的长度的时候，我们就可以拒绝超出的部分。

漏斗算法同样的也有一定的缺点：无法应对突发流量(和上面的临界突刺不一样，不要混淆)。比如一瞬间来了100个请求，在漏桶算法中只能一个一个的过去，当最后一个请求流出的时候时间已经过了一秒了，所以漏斗算法比较适合请求到达比较均匀，需要严格控制请求速率的场景。

## 令牌桶算法

为了解决突发流量情况，我们可以使用令牌桶算法，如下图所示：

  

![](https://pic1.zhimg.com/80/v2-ade7d95abfc9290a30848f7167090758_720w.webp)

  
这个图上需要关注三个阶段：

-   生产令牌：我们在这里同样的还是假设最大qps是100，那么我们从漏斗的每10ms过一个流量转化成每10ms生产一个令牌，直到达到最大令牌。
-   消耗令牌：我们每一个流量都会消耗令牌桶，这里的消耗的规则可以多变，既可以是简单的每个流量消耗一个令牌，又可以是根据不同的流量数据包大小或者流量类型来进行不同的消耗规则，比如查询的流量消耗1个令牌，写入的流量消耗2个令牌。
-   判断是否通过：如果令牌桶足够那么我们就允许流量通过，如果不足够可以等待或者直接拒绝，这个就可以采用漏斗那种用队列来控制。

## 算法结论
1.  固定窗口算法实现简单，性能高，但是会有临界突发流量问题，瞬时流量最大可以达到阈值的2倍。
    
2.  为了解决临界突发流量，可以将窗口划分为多个更细粒度的单元，每次窗口向右移动一个单元，于是便有了滑动窗口算法。
    
    滑动窗口当流量到达阈值时会瞬间掐断流量，所以导致流量不够平滑。
    
3.  想要达到限流的目的，又不会掐断流量，使得流量更加平滑？可以考虑漏桶算法！需要注意的是，漏桶算法通常配置一个FIFO的队列使用以达到允许限流的作用。
    
    由于速率固定，即使在某个时刻下游处理能力过剩，也不能得到很好的利用，这是漏桶算法的一个短板。
    
4.  限流和瞬时流量其实并不矛盾，在大多数场景中，短时间突发流量系统是完全可以接受的。令牌桶算法就是不二之选了，令牌桶以固定的速率v产生令牌放入一个固定容量为n的桶中，当请求到达时尝试从桶中获取令牌。
    
    当桶满时，允许最大瞬时流量为n；当桶中没有剩余流量时则限流速率最低，为令牌生成的速率v。
    
5.  如何实现更加灵活的多级限流呢？滑动日志限流算法了解一下！这里的日志则是请求的时间戳，通过计算指定时间段内请求总数来实现灵活的限流。
    
    当然，由于需要存储时间戳信息，其占用的存储空间要比其他限流算法要大得多。
    

从上面看来好像漏桶和令牌桶比时间窗口算法好多了，那时间窗口算法有啥子用，扔了扔了？

并不是的，虽然漏桶和令牌桶对比时间窗口对流量的**整形效果更佳**，流量更加得平滑，但是也有各自的缺点（上面已经提到了一部分）。

**拿令牌桶来说**，假设你没预热，那是不是上线时候桶里没令牌？没令牌请求过来不就直接拒了么？这就误杀了，明明系统没啥负载现在。

再比如说请求的访问其实是随机的，假设令牌桶每 20ms 放入一个令牌，桶内初始没令牌，这请求就刚好在第一个 20ms 内有两个请求，再过 20ms 里面没请求，其实从 40ms 来看只有 2 个请求，应该都放行的，而有一个请求就直接被拒了。这就有可能造成很多请求的误杀，但是如果看监控曲线的话，好像流量很平滑，峰值也控制的很好。

**再拿漏桶来说**，漏桶中请求是暂时存在桶内的。这其实不符合互联网业务低延迟的要求。

所以漏桶和令牌桶其实比较适合**阻塞式限流**场景，即没令牌我就等着，这就不会误杀了，而漏桶本就是等着。比较适合后台任务类的限流。而基于时间窗口的限流比较适合**对时间敏感**的场景，请求过不了您就快点儿告诉我，等的花儿都谢了

不管黑猫白猫，能抓到老鼠的就是好猫。限流算法并没有绝对的好劣之分，如何选择合适的限流算法呢？不妨从性能，**是否允许超出阈值**，**落地成本**，**流量平滑度**，**是否允许突发流量**以及**系统资源**大小限制多方面考虑。

# 单机限流和分布式限流
## 单机流控

单机流控就是流控的效果只针对服务的一个实例，比如你的服务部署了三个实例分别在三台机器上。请求访问到了A实例的时候，如果触发了流控，那么只会限制A实例后面的请求，不会影响其他实例上的请求。

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bbc02a1c9bb44f4a83033fd479b66f84~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?)

比如你单身的时候，每月的工资都花个精光。影响的只是你自己，跟别人没关系，因为你本来就是一个人生活，单身跟单机就强行关联在一起了。

单机流控相对来说比较简单，不依赖中心化的存储。每个服务内部只需要记录自身的一些访问信息即可判断出是否需要流控操作。

像Guava的RateLimiter就是典型的单机流控模式，将令牌数据全部存储在本地内存中，不需要有集中式的存储，不需要跟其他服务交互，自身就能完成流控功能。

## 集群流控

集群流控就是流控的效果针对整个集群，也就是服务的所有的实例，比如你的服务部署了三个实例分别在三台机器上。总体限流QPS为100，请求访问到了A实例的时候，如果触发了流控，那么此时其他的请求到B实例的时候，也会触发流控。

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8cccc378f3894de780e87ca8622c7912~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp?)

比如你结婚后，你和你老婆的工资是你们整个家庭的总收入。你每天出去玩，到处乱花钱，把钱花完了，你老婆想买衣服的时候，就被流控了，因为没钱了，这就是集群流控的含义。

## 单机限流和分布式限流的取舍

本质上单机限流和分布式限流的区别其实就在于 “阈值” 存放的位置。

单机限流就上面所说的算法直接在单台服务器上实现就好了，而往往我们的服务是集群部署的。因此需要多台机器协同提供限流功能。

像上述的计数器或者时间窗口的算法，可以将计数器存放至 Tair 或 Redis 等分布式 K-V 存储中。

例如滑动窗口的每个请求的时间记录可以利用 Redis 的 `zset` 存储，利用`ZREMRANGEBYSCORE` 删除时间窗口之外的数据，再用 `ZCARD`计数。

像令牌桶也可以将令牌数量放到 Redis 中。

不过这样的方式等于每一个请求我们都需要去`Redis`判断一下能不能通过，在性能上有一定的损耗，所以有个优化点就是 「批量」。例如每次取令牌不是一个一取，而是取一批，不够了再去取一批。这样可以减少对  Redis 的请求。

不过要注意一点，**批量获取会导致一定范围内的限流误差**。比如你取了 10 个此时不用，等下一秒再用，那同一时刻集群机器总处理量可能会超过阈值。

其实「批量」这个优化点太常见了，不论是 MySQL 的批量刷盘，还是 Kafka 消息的批量发送还是分布式 ID 的高性能发号，都包含了「批量」的思想。

当然分布式限流还有一种思想是平分，假设之前单机限流 500，现在集群部署了 5 台，那就让每台继续限流 500 呗，即在总的入口做总的限流限制，然后每台机子再自己实现限流。


# 使用场景对比

## 保护层面对比

单机流控更适合作为兜底保护的一种方式，比如我们单机限流总的请求量为2000，如果超过2000开始限流，这样就能保证当前服务在可承受的范围内进行处理。

如果我们用的是集群限流，假设当前集群内有10个节点，如果每个节点能承受2000的请求，那么加起来就是2万的请求。也就是说只要不超过2万个请求都不会触发限流。如果我们的负载均衡策略是轮询的话没什么问题，请求分布到各个节点上都比较均匀。但是如果负载均衡策略不是轮询，如果是随机的话，那么请求很有可能在某个节点上超过2000，这个时候其实这个节点是处理不了那么多请求的，最终会被拖垮，造成连锁反应。

## 准确度对比

比如我们的需求是限制总的请求次数为2000，如果是单机流控，那么也就是每个节点超过200就开始限流。还是前面的问题，如果请求分配不均匀的话，其实整体总量还没达到2000，但是某一个节点超过了200，就开始限流了，对用户体验不是很好。

所以集群限流适合用在有整体总量限制的场景，比如开放平台的API调用。

# 实战中的宏观控制
我们上面已经介绍了很多限流的工具，但是很多同学对怎么去限流仍然比较迷惑。我们如果对一个场景或者一个资源做限流的话有下面几个点需要确认一下：

-   什么地方去做限流
-   限多少流
-   怎么去选择工具

## 什么地方去做限流

这个问题比较复杂，很多公司以及很多团队的做法都不相同，在美团的时候搞了一波SOA,那个时候我记得所有的服务所有的接口都需要做限流，叫每个团队去给接口评估一个合理的QPS上限，这样做理论上来说是对的，我们每个接口都应该给与一个上限，防止把整体系统拖垮，但是这样做的成本是非常之高的，所以大部分公司还是选择性的去做限流。

首先我们需要确定一些核心的接口，比如电商系统中的下单，支付，如果流量过大那么电商系统中的路径就有问题，比如像对账这种边缘的接口(不影响核心路径)，我们可以不设置限流。

其次我们不一定只在接口层才做限流，很多时候我们直接在网关层把限流做了，防止流量进一步渗透到核心系统中。当然前端也能做限流，当前端捕获到限流的错误码之后，前端可以提示等待信息，这个其实也算是限流的一部分。其实当限流越在下游触发我们的资源的浪费就越大，因为在下游限流之前上游已经做了很多工作了，如果这时候触发限流那么之前的工作就会白费，如果涉及到一些回滚的工作还会加大我们的负担，所以对于限流来说应该是越上层触发越好。

## 限多少流

限多少流这个问题大部分的时候可能就是一个历史经验值，我们可以通过日常的qps监控图，然后再在这个接触上加一点冗余的QPS可能这个就是我们的限流了。但是有一个场景需要注意，那就是大促(这里指的是电商系统里面的场景，其他系统类比流量较高的场景)的时候，我们系统的流量就会突增，再也不是我们日常的QPS了，这种情况下，往往需要我们在大促之前给我们系统进行全链路压测，压测出一个合理的上限，然后限流就基于这个上限去设置。

## 怎么去选择工具

一般来说大一点的互联网公司都有自己的统一限流的工具这里直接采用就好。对于其他情况的话，如果没有集群限流或者熔断这些需求，我个人觉得选择RateLimter是一个比较不错的选择，应该其使用比较简单，基本没有学习成本，如果有其他的一些需求我个人觉得选择sentinel，至于hytrix的话我个人不推荐使用，因为这个已经不再维护了。

## 限流的难点

可以看到每个限流都有个阈值，这个阈值如何定是个难点。

定大了服务器可能顶不住，定小了就“误杀”了，没有资源利用最大化，对用户体验不好。

我能想到的就是限流上线之后先预估个大概的阈值，然后不执行真正的限流操作，而是采取日志记录方式，对日志进行分析查看限流的效果，然后调整阈值，推算出集群总的处理能力，和每台机子的处理能力(方便扩缩容)。

然后将线上的流量进行重放，测试真正的限流效果，最终阈值确定，然后上线。

我之前还看过一篇耗子叔的文章，讲述了在自动化伸缩的情况下，我们要动态地调整限流的阈值很难，于是基于TCP拥塞控制的思想，根据请求响应在一个时间段的响应时间P90或者P99值来确定此时服务器的健康状况，来进行动态限流。在他的 Ease Gateway 产品中实现了这套算法，有兴趣的同学可以自行搜索。

其实真实的业务场景很复杂，**需要限流的条件和资源很多**，每个资源限流要求还不一样。


# 具体做法
## redis做计数器算法

这个方案不依赖限流的框架，我们整个集群使用同一个redis即可，需要自己封装一下限流的逻辑，这里我们使用最简单的计数器去设计，我们将我们的系统时间以秒为单位作为key，设置到redis里面（可以设置一定的过期时间用于空间清理），利用redis的int原子加法，每来一个请求都进行+1，然后再判断当前值是否超过我们限流的最大值。

redis的方案实现起来整体来说比较简单，但是强依赖我们的系统时间，如果不同机器之间的系统时间有偏差限流就有可能不准确。

# redis做滑动窗口
```go
var LuaScript = `  
local key         = KEYS[1];-- 键 keylocal now_time    = ARGV[1];-- 值 valuelocal before_time = ARGV[2];-- 间隔时间之前，纳秒  
local period      = ARGV[3];-- 时间间隔，多少秒内，设置过期时间  
local requests    = ARGV[4];-- 时间间隔内的请求次数  
  
  
redis.pcall("zremrangebyscore", key, 0, before_time); -- 移除scores范围在0到bofore_time之间的值，即移除时间窗口之前的行为记录，剩下的都是时间窗口内的  
local count = redis.pcall("zcard", key); -- 获取窗口内的请求数量  
redis.pcall("expire", key, period); -- 设置 zset 过期时间，避免不活跃用户持续占用内存  
  
if tonumber(count) >= tonumber(requests) then  
   return 2;end  
   redis.pcall("zadd", key, now_time, now_time);-- zset结构设置一个key，zadd(key,value,scores)  
return 1;`  
  
func IsPermited(uid string, action string, period, maxCount int) bool {  
   key := fmt.Sprintf("%s:%v_%v", common.Cfg.GetString("name"), uid, action)  
   now := time.Now().UnixNano() //纳秒  
   beforeTime := now - int64(period*1000000000)  
   sha, _ := common.Redis.Get(common.Cfg.GetString("limit.script.evalSha")).Result()  
   if sha == "" {  
      LoadScript()  
   }  
   res, err := common.Redis.EvalSha(sha, []string{key}, now, beforeTime, period, maxCount).Result()  
   if err != nil {  
      panic(err)  
   }  
   if res.(int64) == int64(2) {  
      return false  
   }  
   return true  
}  
func LoadScript() {  
   evalSha, err := common.Redis.ScriptLoad(LuaScript).Result()  
   if err != nil {  
      panic(err)  
   }  
   err = common.Redis.Set(common.Cfg.GetString("limit.script.evalSha"), evalSha, -1).Err()  
   if err != nil {  
      panic(err)  
   }  
}
```
这里的问题就是 now_time是在一个高并发或者手工的一个for循环下，会连续几个都是同一个时间戳，就算是纳秒也是一样的，而且各个pod的时钟也是有可能不一样的


# redis做令牌桶
我们采用 Redis + Lua 脚本的方式来实现令牌桶算法，在 Redis 中使用 Lua 脚本有诸多好处，例如：

-   减少网络开销：本来多次网络请求的操作，可以用一个请求完成，原先多次请求的逻辑放在 Redis 服务器上完成。使用脚本，减少了网络往返时延。
    
-   原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他进程或者进程的命令插入。
    
-   复用：客户端发送的脚本会永久存储在Redis中，意味着其他客户端可以复用这一脚本而不需要使用代码完成同样的逻辑。
    
-   复用：客户端发送的脚本会永久存储在Redis中，意味着其他客户端可以复用这一脚本而不需要使用代码完成同样的逻辑。
    

这其中最重要的方法就是原子操作。将 Redis 的多条命令写成一个 Lua 脚本，然后调用脚本执行操作，相当于只有一条执行脚本的命令，所以整个 Lua 脚本中的操作都是原子性的。

在 Redis 中使用 Lua 脚本主要涉及 `Script Load`、`Eval`、`Evalsha` 三个命令：

`Eval ${lua_script}` 可以直接执行 Lua 脚本。

`Script Load ${lua_script}` 命令是将脚本载入 Redis，载入成功后会返回一个脚本的sha1值，一旦载入则永久存储在 Redis 中，后续可以通过 `Evalsha ${sha1}` 来直接调用此脚本。我们采用先 Load 脚本得到 Sha1 值，再调用这个 sha1 值来执行脚本的方式可以减少像`eval ${lua_script}` 命令这样每次都向 Redis 中发送一长串 Lua 脚本带来的网络开销。

使用 Redis 中的 Hash 数据结构来存储限流配置，每个 Hash 表的 Key 为限流的粒度，可以是接口Uri、客户端 IP、应用uuid或者他们的组合形式。每个 Hash 表为一个令牌桶，Hash 表中包含如下字段：

-   `last_time` 最近一次请求的时间戳，毫秒级别。
    
-   `curr_permits` 当前桶内剩余令牌数量，单位为：个。
    
-   `bucket_cap` 桶的容量，即桶内可容纳最大令牌数量，代表限流时间周期内允许通过的最大请求数。
    
-   `period` 限流的时间周期，单位为：秒。
    
-   `rate` 令牌产生的速率，单位：个/秒，`rate = bucket_cap / period`
    

在上面的令牌桶算法描述中生产令牌的方式是按照一定的速率生产令牌并放入令牌桶中，这种方式需要一个线程不停地按照一定的速率生产令牌并更新相应的桶，如果被限流的接口(每个桶)令牌生产的速率都不一样，那么就需要开多个线程，很浪费资源。

为了提高系统的性能，减少限流层的资源消耗，我们将令牌的生产方式改为：**每次请求进来时一次性生产上一次请求到本次请求这一段时间内的令牌**。随意每次请求生成的令牌数就是 `(curr_time -last_time) / 1000 * rate`，注意：这里两次时间戳的差值单位是毫秒，而令牌产生速率的单位是 个/秒，所以要除以 1000，把时间戳的差值的单位也换算成秒。

令牌桶算法的实现逻辑为：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/6MZqUI3KNloibYjKKA3QxzqnEQVwNvzcRibohu5wEgr5kQPOt2WEibuAHciaTtiaU5P8VVibE8L0MsRZEMibMVxl10Ttw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

假如我们的限流策略是一分钟内最多能通过600个请求，那么相应的令牌产生速率为 600 / 60 = 10 (个/秒) 。那么当限流策略刚刚配置好这一时刻就有突发的10个请求进来，此时令牌桶内还没来的及生产令牌，所以请求拿不到令牌就会被拒绝，这显然不符合我们要求。

为了解决这一问题，我们在限流策略刚刚配置好后的第一个请求来临时将当前可用令牌的值设置为桶的最大容量 600，将最近一次请求时间设置为本次请求来临时一分钟后的时间戳，减去出本次请求需要的令牌后更新桶。这样，在这一分钟以内，有下一次请求进来时，从 Hash 表内取出配置计算当前时间就会小于最近一次请求的时间，随后计算生成的令牌就会是一个小于0的负数。所以在更新桶这一步，要根据生成的令牌是否为负数来决定是否更新最后一次请求时间的值。

用 Lua 脚本实现上述逻辑：

```lua
local key = KEYS[1] -- 要进行限流的Key，可以是 uri
local consume_permits = tonumber(ARGV[1]) -- 请求消耗的令牌数，每个请求消耗一个
local curr_time = tonumber(ARGV[2]) -- 当前时间

local limiter_info = redis.pcall("HMGET", key, "last_time", "curr_permits", "bucket_cap", "rate", "period")
if not limiter_info[3] then
    return -1
end
local last_time = tonumber(limiter_info[1]) or 0
local curr_permits = tonumber(limiter_info[2]) or 0
local bucket_cap = tonumber(limiter_info[3]) or 0
local rate = tonumber(limiter_info[4]) or 0
local period = tonumber(limiter_info[5]) or 0

local total_permits = bucket_cap
local is_update_time = true
if last_time > 0 then
    local new_permits = math.floor((curr_time-last_time)/1000 * rate)
    if new_permits <= 0 then
        new_permits = 0
        is_update_time = false
    end

    total_permits = new_permits + curr_permits
    if total_permits > bucket_cap then
        total_permits = bucket_cap
    end
else
    last_time = curr_time + period * 1000
end

local res = 1
if total_permits >= consume_permits then
    total_permits = total_permits - consume_permits
else
    res = 0
end

if is_update_time then
    redis.pcall("HMSET", key, "curr_permits", total_permits, "last_time", curr_time)
else
    redis.pcall("HSET", key, "curr_permits", total_permits)
end
return res
```

上述脚本在调用时接收三个参数，分别为：限流的key、请求消耗的令牌数、 当前时间戳(毫秒级别)。

在我们的业务代码中，先调用 Redis 的 `SCRIPT LOAD` 命令将上述脚本 Load 到 Redis 中并将该命令返回的脚本 sha1 值保存。

在后续的请求进来时，调用 Redis 的 `EVALSHA` 命令执行限流逻辑，根据返回值判断是否对本次请求触发限流行为。假如限流的 key 为每次请求的 uri，每次请求消耗 1 个令牌，那么执行 Evalsha 命令进行限流判断的具体操作为：`EVALSHA ${sha1} 1 ${uri} 1 ${当前时间戳}` （第一个数字 1 代表脚本可接收的参数中有 1 个Key，第二个数字 1 代表本次请求消耗一个令牌）；执行完这条命令后如果返回值是 1 代表桶中令牌够用，请求通过；如果返回值为 0 代表桶中令牌不够，触发限流；如果返回值为 -1 代表本次请求的 uri 未配置限流策略，可根据自己的实际业务场景判断是通过还是拒绝。

# 使用time/rate
作为单机限流

# 最终落地方案
先通过konga去根据ip限流
再设置k8s hpa来根据cpu的70%来扩容
最后再通过svc的轮询策略以及单机限流来做。不需要集群限流。

问题是面对数据库等临界资源要怎么做?
目前我的想法是先通过压测确定操作数据库的那些服务的负载，再去对数据库进行限制。上层不需要考虑数据层的压力

# Reference
https://juejin.cn/post/7020057486656798757  
https://zhuanlan.zhihu.com/p/448124932
https://mp.weixin.qq.com/s/MmqMeMKZbLO_u73OW1e47A