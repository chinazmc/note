 # 摘要
异构数据同步系统
项目描述：
通过订阅数据库binlog，获取数据变动信息，进行业务处理后，将处理后的数据进行消息通知，数据填充等等操作。
技术架构：
Golang,ElasticSearch,Redis,Gin,HBase,Nsq,Kubernetes,Kafka
技术描述：
- 负责系统方案设计：系统初期多表同步业务处理速度慢，消费速度差，导致线上经常出现数据错误，消息堆积等情况，所以我们需要解决的问题的核心是保证数据一致性的前提下提高多个业务线的同步速度，通过过往经验我们定下初步是40万数据五分钟写入所有业务线，最终我们通过调整kafka分区策略以及引入hbase和redis任务队列达到所有业务线同步50万最晚1分钟的结果，初步满足了我们的日常需求。
- 合理使用消息队列进行系统解耦：通过合理使用kafka分片策略来进行并发消费，通过nsq的延时队列来定时通过校验修复系统对数据进行增量修复，通过redis任务队列来通知各个业务线，并对任务进行去重。
- 对中间件进行版本写入：版本写入可以保证系统一致性，我通过HBase创建一个业务大宽表来汇总多表数据，并采用kafka offset作为版本来实现列级别的版本控制，并且通过HBase的自增数据实现对Redis和ElasticSearch的版本写入。


异构数据同步平台数据一致性差，消费速度慢  ----S
导致了线上容易堆积，数据错误 ----C
问题的核心是要保证数据一致性的前提下尽可能提高多个业务线的数据同步速度 ----Q
我通过合理的kafka分片策略保证同一行数据变更一致性，然后消费msg输入到hbase做一个大宽表来支撑多个业务，然后通过任务去重的方式降低写入量。 --A

目前 每秒每秒写入基本上都是3333，一万数据三秒就能写完。
我们当初定的目标是 40万的数据五分钟内要消费完成。为什么是40万呢？主要是我们通过多次的堆积后的取得一个平均数。为什么是五分钟？这个是业务方面的一个宽松的时间定义。

所有我们看到40万的数据能够在三分钟内消费完成我们就没有再测试了。
当然这个速度是写入hbase的速度，其中写入es基本上最高也就8000每秒，所以我们需要去重后发现写入es也能够五分钟内完成，主要是 hbase写入一个版本后就不会有其他版本能够写入，而且任务会去重。

一开始是每秒写入180条数据，现在每秒3333.提高了18.51倍。这还不是压测的极限。

一分钟内写入五十万的数据，es是六个node，使用cpu还不能超50%，六主二从的配置
# 项目背景
## 痛点

第一个，通过binlog导数据，绝对不能受到表结构的限制，所以直接结果就是有很多回查的操作
第二个，大量写操作必定是要乱序写才会快的，不然就受限于 kafka 分区数了
第三个，多个中间件的写入，不要大家都在消费原始kafka数据。
第四个，有些业务线是需要明确这个是什么类型的变动，所有需要有类型信息
第五个，需要优先级队列。

### 顺序一致性
落地到es和redis中，有很多数据，不是简单的单表同步。单表通过是不需要通过kafka来消费了，我们直接通过阿里云的dts直接通过原始binlog来同步了，简单明了。
我们很多数据都是在多表同步的基础上结合业务规则对数据进行抽取或者转换来落地的，所以需要注意同步过程中的顺序和一致性。
### 最终数据实时性
我们都是希望xxxx的数据量能够在xxx 秒内结束
### 数据准确性

### 数据量大
为什么数据量大，因为数据库数据多，批量修改，反复修改。
为什么操作次数多就堆积？ 因为下游处理速度慢
为什么慢？因为要进行业务处理，以及写入中间件
为什么业务处理慢？没有宽表
为什么写入中间件慢? 因为中间件不是mysql的从库，不能设计成完全重放请求。

# 目标和评估

# 技术方案

## 方案零（最开始的方案）
事情处理前：使用了pprof以及gctrace来观察程序，通过gcTrace的话会发现每十秒就gc一次。通过火焰图的话就会发现json花的时间太多了，但是通过去掉json后发现并没有什么用！！！  
使用了sync.pool以及多协程消费，将处理速度从每秒46个binlog优化到每秒73个binlog  
使用setMemoryLimit=100m以及gcoff之后，每秒处理82个binlog  
使用setMemoryLimit=256m以及gcoff之后，每秒处理180个binlog，但使用这个方案后内存一直无法降下来，一直维持在limit水平  
  

总结以下几点给打算用go开发项目或已经在用go开发项目的朋友：  
1、尽早的用memprof、cpuprof、GCTRACE来观察程序。  
2、关注请求处理时间，特别是开发新功能的时候，有助于发现设计上的问题。  
3、尽量避免频繁创建对象(&abc{}、new(abc{})、make())，在频繁调用的地方可以做对象重用。  
4、尽量不要用go管理大量对象，内存数据库可以完全用c实现好通过cgo来调用。

使用单分片的kafka+增量修复和全量修复，平稳运行一段时候后开始时不时就消息堆积

## 方案一
通过一个新的服务来批量获取binlog数据，然后分为多种消息类型，比如商品基础信息，商品价格，库存变动等等之类的类型，然后按照以商品id为消息键的方式来进行推送到一个新的topic。这种方式就是通过内部维护一个商品id数组，数组中是多个binlog对于一个商品的binlog数据聚合，后续再根据业务逻辑对这个数组进行补充数据来完善。

批量获取数据批量处理，增大吞吐量
缺点是对外输出固定的格式和内容，势必要大量回库补充完整数据。而且对外输出的大宽数据太大。

重新再完整描述下第二个版本的问题：我觉得这个版本的算是大多数人会想到会去做的版本。  
第一个：将消息按照消息键发到对应的分片中，以商品id或者订单id为维度去分发，保证了局部有序。

第二个：批量拉取消息，批量处理提高消息吞吐量，批量提交。

第三个：pod内部使用多协程的方式，以商品id或者订单id为维度去发到到每个协程，提高消费能力。

  

这个三个措施会导致以下几个问题：

1、批量拉取消息，批量提交会导致实时性低，因为必然要停顿一段时间达到要求后才批量处理

2、批量提交会导致在项目重启的时候丢失消息，因为分片只会维护最大的位置，重启前如果把大的提交了，小的没有提交而且没有处理就不会再发过来了。

3、批量拉取消息来聚合的时候，我们作为一个底层服务，势必要对外提供一致的结果，所以我们必然需要对消息进行补全，补全的过程还需要查询数据库，也就带来了读扩散，增大了数据库压力  
4、补全的过程中要是有表在进行大批量的修改，对这种热点数据进行补全是非常大的压力，因为如果是多个表聚合的话需要查询的数据就少，当时表非常单一的话就非常难补全。

  

所以我们当时的措施是，第一个问题不管，第二个问题就是维护一个链表，每个消息通过链表组织起来，处理完一个消息就把对应node标为已解决，只有连续的node都解决才提交最大的那个，定时提交。 第四个问题的话通过热点topic也解决不了的。

## 方案二
通过flink cdc
为什么不用flink cdc，因为除非是非业务场景下，只是单纯做数据同步，可以用。但是就要承担flink cdc链接db出现问题的情况，因为要自建。

而且每多一个业务线就要写一次flink sql。

我有n个表，要写入n个业务，每个业务有n个终端，那么我是否要负责全公司的所有 n\*n\*n的业务?这样是不行的。
## 方案三
既然方案二需要一个大宽数据支撑所有业务，那就找个地方存放大宽数据，并且每次都可以按照版本来更新部分字段。那么这个地方就是hbase了。
有个服务获取binlog数据，binlog通过主键来进行分片，然后利用offset作为后面hbase的version,因为同一个表的同步是顺序的，或者在高版本mysql中同一个行的更新是同步的。
然后自增这一行的version。然后带着这个version建立一个任务去各个业务线上执行，从hbase获取数据。
1、在hbase中建立htable，将带version的消息写入hbase中的时候，version大就可以写进去。

2、对于es的更新而言，更新完hbase后通过rowkey来获取数据进行index操作覆盖回去，（因为是完整数据，所以直接覆盖更方便，还可以省去update的取／合并操作，index 可以采用 exteneral 版本也称作外部版本号来进行控制，同样适用上述的 SeqNo 来做乐观锁去解决该问题。）

3、全量初始化的时候，只需要通过遍历htable就行。  
  
过程中还体现我ownership的一个方面是我通过火焰图定义json序列化严重，还有我使用sync.pool来优化。

维护一个链表，每个消息通过链表组织起来，处理完一个消息就把对应node标为已解决，只有连续的node都解决才提交最大的那个，定时提交。 第四个问题的话通过热点topic也解决不了的。
## 方案三 架构设计
![[Pasted image 20240217105946.png]]
#### 为什么要还要引入nsq消息队列
对比修复程序不与消费程序放到一起，防止互相影响，毕竟对比修复程序占用内存和大量使用数据库，速度比较慢。不用asynq也只是不想增加负载而已。而且两边代码不互相复用，互相backup来对比。
#### 如何使用hbase
为什么不是binlog直接通过asynq并且通过版本号直接写入redis和es？

因为写入hbase是不需要考虑太多业务的聚合的，而写入redis和es是需要业务逻辑的，有时候甚至要回表，而且hbase一个大宽表是可以支撑绝大部分的数据落地，不要每个数据落地的项目都来消费binlog，不要都来理解消息队列的处理。


订单查询流程和同步流程

根据订单状态去冷库或者热库去查。

  

通过借助 HBase 字段级别版本号帮助每个表保证表内部字段有序，同时 put 写入完数据之后，通过额外字段 version 做 increment 操作，当这两个写入动作完成之后立马 get 操作拿到 HBase 的数据写入到 ES 中，无论并发程度如何，最终至少有一次的 get 请求拿到的版本 version 字段是最大的，用该 version 作为 ES 的外部版本号解决 ES 版本号问题。  
用此方案会有好处：  
  
HBase 协助管理内部字段版本，同时根据内部操作，协助 ES 拿到对应的版本，且数据能拿到最新数据；  
  
去掉了顺序队列，HBase 具有良好的吞吐，相对于顺序队列拥有更大的吞吐量；  
  
横向拓展增大消费速率；  
  
ES 可以采用 index 操作，性能更好。


为什么要使用habse，每个中间件查表不就行？

事实上，如果没有hbase，消息处理和增量修补，和最终修补以及中间件数量都是一个非常大的数字，我们不希望这里有一个读扩散。而且一个大宽表是比较容易支撑后续的所有中间件的。没必要每个中间件的数据落地都要理解一次领域逻辑。
总结痛点是：业务多变，需要快速支撑，一致性，去重和优先级
##### rowkey设置规则
hbase的订单rowkey可以设定为1234:2308221547134561234789456  
前四位为业务id，需要用后面的订单id末尾取四位，没有：号

这一个rowkey的定义不止考虑到顺序，还得考虑region和压缩。

hbase的商品rowkey可以设定为前四位为后面的商品id的md5摘要，然后后面的就补前置0+商品id。  
前四位的目的只是为了打散这个顺序而已，不然就是按照时间分布了。

#### 异步系统中，每个环节都体现了什么呢？

首先，kakfa->hbase中，体现了对多表异步同步的乱序消息下一致性的控制。（如果要讲明白这个问题，首先就要将讲一下es的版本，redis我们怎么做版本）

为什么是一定要弄到hbase中呢，第一个方面是因为我们需要版本控制，第二个方面是，我们落到中间件以及发布出去的数据，都是hbase中的一个子集，那么我们会容易就知道我们需要维护一个大的快照来应对所有的场景。

最后，这个环节体现的是版本控制丢弃以及批量的概念！！！

hbase->asynq 体现的是一整个异步任务处理系统中，我们是如何解决业务长耗时高并发难题？

除了可靠性之外，我们需要关注任务去重，背压，任务优先级队列，超时处理过期处理且预警，最后就是平滑扩容,还有就是任务聚合

最后，这个环节同样体现的是版本控制丢弃以及批量的概念！！！  

如果应用的流量持续保持高位，导致队列积压，系统将为他们自动创建单独的队列，并将流量分流到新的队列上。  
将一些延时敏感，或者优先级高的应用流量迁移到其他队列上，避免被高流量应用产生的队列积压影响。  
允许用户设置任务的过期时间，对于有实时性要求的任务，在发生积压时快速丢弃过期任务，确保新任务能更快的处理。(这一步主要通过在任务数据中加入binlog时间，处理时间，加入hbase时间等等，然后让一个程序来判断)  

  

为什么异步任务处理系统要注意超时和过期？

因为之前有个场景是这样的，我们有个特定条件下的binlog会在系统中死循环，导致消息堆积。我们通过pprof来解决了。但是呢，不排除以后也可能有这种情况，那么这个时候超时和过期就非常重要了。

#### 为什么要使用asynq
使用asynq前的实际感受是
第一，业务线绝对不能作为mysql的备库，每个业务线的速度或多或慢，资源有多有少，业务有复杂和简单，处理目标不同，按照从库的标准来执行太过死板了，不能作为从库来写入每一条数据。
第二，对于相同的内容，比如同一个商品的变更，其实不需要完整去执行这些所有的变更，只需要最后一个就行
第三，有些binlog就是最容易被发现有问题，就是优先级比较高。比如商品名称，比如是否开放，比如库存之类的。需要有优先级队列。

Asynq 这个库 可以作为异构数据同步平台的补充，因为他有优先级队列，而且可以进行数据的重复性检测。

而且还可以进行任务的超时和截止时间。

某些binlog就是比别的binlog要重要，比如库存变动之类的。
某些binlog只需要最新一条就行，而且对于中间件的写入也不要对数据一直进行回放。
针对消息堆积的情况，binlog处理时间大于20分钟，就全部丢弃了，然后报警手动处理。

取舍方面：Kafka、RocketMQ、Pulsar、NSQ不支持优先级队列，可以通过不同的队列来实现消息优先级。  
kafka的消息压缩是有的，但是这个不是绝对意义上的压缩，是要按照脏数据比例以及时间来进行压缩的，而我要的是短时间内数据的压缩。

而且我需要每个任务都有一个截止时间，太过超时的任务就算执行了，就是堆积了，不要执行而是选择直接暴露问题是最好的。  

kafka的优先级队列如何做？

//queues返回要查询的队列列表。  
//队列名称的顺序基于每个队列的优先级。  
//如果严格优先级为true，队列名称将按优先级排序。  
//如果严格优先级为false，那么队列名称的顺序大致基于  
//优先级但是随机化以避免饥饿的低优先级队列。

  

asynq的严格模式是一个数组中按照优先级排序，每次都去第一个队列查询，只要第一个队列永远有数据，永远轮不到后一个队列。

非严格模式是：按照优先级创建多个副本放到数组中，那么数组中每个元素的数量就是优先级，然后对这个数组进行洗牌，然后再随机取一个元素出来就是要进行拉取的队列了。

### binlog处理的一致性与批量处理

### 多业务线公共逻辑抽取与复用

### 通过与数据库解耦的角度来进行任务复用

### 版本号写入达到一致性要求

### 方案过程中的优化
#### hbase优化
异构数据同步平台是不需要hbase wal的。

数据一致性校验中，如果某个值变动非常大，导致每次校验都出现问题，那么应该怎么办。（是否可以这样回答，校验是在数据变更后的五分钟内，某一个数据频繁变更不大可能维持五分钟？）
目前如何scan hbase来重构缓存和es，是否有空，因为hbase中有order和product，所有是否scan出来有问题。
### 一致性
**任何基于消息的同步都需要进行数据对比**
我们应该怎么做？
增量同步：
我们会在获取到dts服务的binlog消息之后，在发给新topic之前，通过nsq发送延时消息，一般延时十分钟，给下一个服务通过这个延时消息中的商品id来从db，es，hbase三方获取数据来进行对比，有差错的话通过db的数据来覆盖。(其他类型的服务也差不多，记住最近更新的数据，然后对这些数据进行重load)

全量同步：
每天晚上全量处理。  

**数据异构的实践在问题监控、报警、及时降级方面是非常重要的。它的链路上所有环节，基本上都是有高可用的要求的。**  

如果dts这边的高可用由阿里云负责，我们自己的新topic过程是可能出现问题，数据delay之类，或者程序启动错误之类的。所以一方面需要用grafana来监控，一方面需要钉钉报警，一方面还需要监控到延迟之后，通过redis或者nsq之类的通知来告知其他系统，暂时不要去获取es或者hbase或者redis的数据！（降级方案！！！）  

监控指标由消息堆积量，还有个同步链路是先监听binlog然后同步到消息队列中，业务消费处理同步到Es和Hbase，可以将整个同步链路监控起来，比如一个消息binlogTime->addMqTime->processTime->addEsOrHbaseTime,这个差值其实就是实时性的一个指标。这些指标都需要用于上面的降级方案。！！！非常重要

每分钟判断是否消息堆积量是否超过了警戒值，以及消息的binlogTime以及处理的time是否超过了某个警戒值不够实时了。

如果需要警戒，就去设置redis某个key为需要降级。

多个系统监听这个key，做好自己的降级逻辑，比如不要信任redis数据之类的需要从数据库取。es的降级逻辑暂时不做，太复杂了，没必要

#### hbase一致性
通过借助 HBase 字段级别版本号帮助每个表保证表内部字段有序，同时 put 写入完数据之后，通过额外字段 version 做 increment 操作，当这两个写入动作完成之后立马 get 操作拿到 HBase 的数据写入到 ES 中，无论并发程度如何，最终至少有一次的 get 请求拿到的版本 version 字段是最大的，用该 version 作为 ES 的外部版本号解决 ES 版本号问题。

Tip-1：为什么采用 ES + HBase 处理搜索和详情？  
一般情况下，公司达到一定规模，有类似全文检索的需求或者高频 key:value 的时候，大家会推荐 ES+HBase 的架构体系去完成搜索和详情的需求，而现实中，绝大多数情况下生产环境不会将数据直接写入到 ES 或者 Hbase，大家都会优先写入数据库，不进行双写的操作是因为增加链路影响业务。当然 Hbase 可能还好一点，ES 本身就是非实时查询系统（为什么是非实时，有兴趣的可以去看看ES读写流程），这种情况下也造就了 ES 和 HBase 的一个准实时系统。针对业务来说，准实时是可以满足相关需求的，比如商家搜索订单并不要求实时。

并且hbase还是业务数据的结合，一个大宽表，是多个mysql表的聚合，可以节省多次查询。

我们的es不存储商品的所有数据，只存储可以检索商品的数据，得出结果的rowkey去db或者hbase中查找。

  
Tip-3：SeqNo 实现方式，为什么不用 binlogoffset？  
因为 cana 实例与 mysql 实例是 1:N（推荐 1:1),而大部分业务场景同一种数据一般会落在同一个实例上，canal 就可以通过该台实例的时间与每秒处理的个数相结合。如：timestamp\*10000+counter++，而不用 binlogoffset 的原因是 mysql 的实例挂了话，binlogoffset 可能会乱序。  





###  可扩展性

### 稳定性
#### golang程序

#### kafka稳定性

#### asynq稳定性
##### asynq会不会导致big key问题？

会的，所以每次要拉取kafka消息前，都需要判断下当前那些list的长度是多少？

因为只要单个list大于5000，就算是大key了，那么就不要往里面插入数据了，就直接预警就行。

bigkey的提出预警后顺序写入mysql保存起来就可以了。为社么要用mysql，首先这个是一个方便查看的存储媒介，我们可以分析通过分析mysql数据来查看为什么redis队列会堆积，而且方便回放和处理。
##### asynq消费者端 crash，任务怎么办
每个消费者拿到任务之后，任务其实会在租约 zset中存在，每隔一段时间就会取出来租约到期的任务，进行重试队列进行重试。

deadline怎么处理？

##### 租约是什么？


每个任务都有一个过期时间，这个是为了防止在redis上有些数据一直不消失，默认30分钟。如果一直不处理，就会交给回收程序（待看 以及 钩子）

每个消费者从队列中获取程序后，会设置一个30s的租约，处理过程中不会去延长租约（一般也没有一个任务会处理超过30s）。但是如果租约过期了，消费者会通过context自动失败。并且有有个程序扫描租约队列，如果租约过期的任务没有超过重试次数，那么就加入重试队列，如果超过了重试次数，那么就加上错误信息打入归档队列。

retryCmd和archive

#### 监控方面的指标
比如 任务的处理数量，任务的失败率等等。队列size大小，占用内存。


#### hbase稳定性
简单计算如下：  
 1.假设Kafka只有一个Topic，且该Topic只有一个Partition，每天写入的数据量刚好是1千亿，那么多长时间之后会出现消费Offset溢出的情况呢？  
 2.Kafka中的消费Offset使用的是java.lang.Long类型，最大值为：9223372036854775807  
 3.按每天的生产量为1千亿算，Kafka的最大消费Offset可以支持：9223372天=9223372036854775807/1千亿 => 25269年  
  
从上述简单的计算结果看，完全不用担心Kafka的消费Offset会有溢出的情况会出现（注：理论上是会溢出的）。

## 观测性

## 速度指标



## kafka架构
kafka分区一定要多，便于后续的可扩容。pod可以少，消费多个分区，然后消费速度上不来就多个pod，直到每个pod都独占一个分区。

这个分片影响了并发数量，也影响了habse的version，但是我们还是不采用全局递增version。还是使用offset作为version，目的是简单。而且分区定为二十个的话已经完全足够未来很长时间的发展了，不会变更分区了。如果后面还是要重新设置分区的话，会通过禁用hbase表然后重新强制设置version或者删除数据重新录入的方式。但是目前暂时不考虑了。或者通过获取最大offset然后改成全局递增offset。

dts服务是可以指定主键分片。

那么对于写入hbase来说，只要根据 offset就行，

因为hbase的cf:order_item:goods_name:123445 命名规则中最后一个数字就是主键id，所以只要根据主键分片天然就是递增的。

## 缓存设计
最后，cdc方案是我们最开始的方案，一开始数据量少的时候我们都是永不过期的数据，不需要caceh aside

大概有什么数据是永不过期的？
比如每个运营商挑选的商品id列表，品类呀之类的，还有一些装修模板呀，访问非常频繁的数据呀之类的，库存变动，商品信息。
很多数据其实是组装起来的，用redis只是可以享受nosql的方便，另外还有就是兼容老系统。

redis我们用的是主从集群，需要主从同步，主从切换过程中的错误通过增量同步和全量同步修复。

需要cdc的数据一般来说都是永不过期的，但是如果真的找不到，除了增量同步和全量同步，我们还会去数据库实时同步确认一下是否真的为空再返回前端是否为空，并设置一个会过期的空占位key。

当然，除了这些key之外，还是有很多key是会过期的，会去查库的。

这些永不过期的key一方面是兼容以前的逻辑，一方面是不同库或者一些复杂逻辑或者耗时逻辑的产物，有些是绝对性能要求。性能比如 布局缓存，复杂逻辑比如 商品定价。还有一些一时半会忘记了。

## es设计
一开始的es采用脚本的方式来写入，现在用ES 可以采用 index 操作，性能更好。

## asynq设计
[asynq](https://github.com/hibiken/asynq)：Golang distributed task queue library，许多设计思想都来自[sidekiq](https://github.com/mperham/sidekiq)。[官方文档](https://github.com/hibiken/asynq/wiki)给出的特点如下（省略了若干）：

- 任务已写入Redis后会持久化（支持Redis Cluster/Sentinels）
- 任务执行失败自动 retry
- 支持任务优先级权重（加权优先级队列）
- 支持定时发送任务
- 可使用 unique-option 來避免任务重复执行
- UI及客户端、metrics支持（CLI检查和远程控制队列和任务）
- 支持任务设置执行时间or最长可运行的时间

![[Pasted image 20240220121412.png]]

#### 优先队列如何实现的
通过给每个通道设置权重，然后根据权重建立一个数组，然后每次拉取请求的时候，判断落在哪个区间就去获取哪个通道的数据。

当然，也有严格优先队列模式，就是一直轮询到权重大的队列没有数据了，才会考虑下一级的队列。但是这个弊端太大，最好是不要。

#### 唯一任务如何实现
设置redis key set ex ns 。然后这个这个任务结束了之后，就把这个唯一key删除。就又可以进入相同的key了。


## hbase设计
### 为什么一定要引入hbase？
首先，kafka那边根据主键或者自定义字段来进行分片，就已经能够保证同一行都能分片到同一个分片。
那么hbase的意义在于
- 不需要所有的分片都要消费原始的kafka数据，不同的业务线消费速度不一致，容易导致 kafka 磁盘的冷数据换入换出影响吞吐
- hbase的数据作为一个大宽表用来支撑所有的业务线，将每个业务线从消费binlog的视角转变成 消费这个大宽表超市，解决了业务角度处理binlog有时候还需要回表的读扩散的问题
- hbase会提供给每次的变更一个唯一的版本号用于写入每个业务线，通过binlog来消费很难获得业务角度递增版本号，毕竟我们不是单表同步，是多表同步，那么多表同步中多行数据谁来确定一个递增版本号是通过hbase解决。或许有人会问，不要hbase可以吗，直接拿那个binlog offset作为es和redis的version。这样是不行的，version必须是表示在这之前没有需要更新的数据比这个小！！！一个product_info的offset为10，一个product_attr的offset为1。如果product_info先插入es,是否product_attr就无法插入了，哪怕他们是同一个事务。

### hbase表设计
针对订单主表，我们写入的数据先获取订单号的后四位，然后以 后四位:订单号作为主键降低热点问题，同时定义单 column family，qualifiy 格式为 表:字段 value为对应的 value 值，timestamp 为 SeqNo  
针对订单商品表，我们写入的数据同样以订单号生成相应的 rowkey，同时定义单 column family，qualifiy 格式为 表:字段:对应记录的 id 值 value 为对应的 value 值，timestamp 为 SeqNo。cf:order_item:goods_name:123445  

这里的话你可以只定义一个列族cf，然后sku就是cf:order_item:goods_name:123445

或者说每个表就是一个列族，然后order_item:goods_name:123445.

这里我们都是选择一个列族cf弄所有，方便简单粗暴。

### hbase操作
通过借助 HBase 字段级别版本号帮助每个表保证表内部字段有序，同时 put 写入完数据之后，通过额外字段 version 做 increment 操作，当这两个写入动作完成之后立马 get 操作拿到 HBase 的数据写入到 ES 中，无论并发程度如何，最终至少有一次的 get 请求拿到的版本 version 字段是最大的，用该 version 作为 ES 的外部版本号解决 ES 版本号问题。  
用此方案会有好处：  
  
HBase 协助管理内部字段版本，同时根据内部操作，协助 ES 拿到对应的版本，且数据能拿到最新数据；  
去掉了顺序队列，HBase 具有良好的吞吐，相对于顺序队列拥有更大的吞吐量；  
横向拓展增大消费速率；  

# 中间件版本写入

## es版本写入
内部版本号，必须通过获取当前的版本号，然后用相同的版本号去更新，如果版本号不相同，就失败。更新成功后，版本号递增

外部版本号，当version_type=external的时候，只有当提供的version比es中的_version大的时候，才能完成修改。

## redis版本写入
![[Pasted image 20240204172846.png]]

singleFight防止缓存雪崩，而且lockutil会让没有获取到锁的协程等待一段时间重试，不会落到库。

缓存穿透，可以对这个key设置nil

这种方式好像集群和单节点都适用。但是呢，我们仍然使用高配的16g大内存的redis单节点。基本不会故障。阿里云只有主从的.

如果是redis cluster的话，使用lua脚本操作多个key会报错，因为多个key可能不是同个slot，但是你可以通过某个关键字让lua脚本中的key都使用第一个key的slot。

这个key应该是map结构，值应该是字符串的。

第一个原因：map结构就不用操作多个key，方便一致性。

list,set,zset,map之类的value为什么不去支持呢，主要是因为上面这些数据结构不需要覆盖全部，如果需要覆盖全部，就说明是一个整存整取的结构，用string合适，上面这些数据结构应该是逐个进逐个出，在单线程redis中没有那么多的一致性问题。

如果真的要做的话，可以分两个key，一个是元数据key，一个是数据key。

# 测试方案

# 上线方案

# 效果评估
目前 每秒每秒写入基本上都是3333，一万数据三秒就能写完。
我们当初定的目标是 40万的数据五分钟内要消费完成。为什么是40万呢？主要是我们通过多次的堆积后的取得一个平均数。为什么是五分钟？这个是业务方面的一个宽松的时间定义。

所有我们看到40万的数据能够在三分钟内消费完成我们就没有再测试了。
当然这个速度是写入hbase的速度，其中写入es基本上最高也就8000每秒，所以我们需要去重后发现写入es也能够五分钟内完成，主要是 hbase写入一个版本后就不会有其他版本能够写入，而且任务会去重。

一开始是每秒写入180条数据，现在每秒3333.提高了18.51倍。这还不是压测的极限。

# 下一步操作
# 总结
## 有序性
通过 字段来确定分片保证 同一行数据的有序性。
在上面的基础上，为了加快消费速度，通过offset来作为version 保证了批量消费乱序插入的有序性。
在上面的基础上，通过hbase自增version保证业务线的有序性。

## 实时性
分片规则选择比较不容易倾斜的，比如id
在offset作为version的前提下，pod批量消费乱序写入
asynq 任务去重降低了业务线写入量
hbase宽表设计屏蔽了多业务线消费速度的差异。
宽表设计不需要回表。
## 一致性
通过增量对比来修复数据
通过全量对比来修复数据
通过监控消费延迟来进行消息通知以便降级

## 讲事情的方式
让其他研发理解你的技术方案的过程是什么？

1、项目背景：讲清楚为什么要做这个事情？这需要使用5why法，论证做这个事情的必要性，描述清楚需求
2、目标与评估：把需求转换成可执行的目标，目标要可量化，也就是要找一组可评估的指标
3、技术方案：选择一个表述清楚的图表把方案画出来，强制自己想出三个方案对比
4、任务分解：将技术拆分为能够产生有效反馈的里程碑任务，回答自己两个问题：交付什么？完成什么？
5、测试方案：清晰描述自测/反测/集成/回归方案，资深和新手最大的区别就是在于对编码质量的把控
6、上线方案：想清楚有什么手段可以验证变更生效又当如何发现异常，如何保证历史逻辑的兼容
7、效果总结：先验的评估不一定符合预期，因此需要评估这个项目上线后真正的收益
8、下一步：在做的好和不好的总结之后，针对这个项目接下来还有什么演进
这个思路就是强调一个做事的闭环。

《金字塔原理》总结了 4 个构建金字塔的基本原则：  
  
结论先行：每篇文章只有一个中心思想，并放在文章的最前面。  
以上统下：每一层次上的思想必须是对下一层次思想的总结概括。  
归类分组：每一组中的思想必须属于同一逻辑范畴。  
逻辑递进：每一组中的思想必须按照逻辑顺序排列。


“5WHY”分析概述  
  所谓“5WHY”分析法，又称“5问法”，就是连续反复使用5次“为什么”方式自问，以打破砂锅问到底方式寻找问题的根本原因的方法。“5WHY”不限定必须或只做5次为什么的提问，以找到问题根因为准，也许是3次，也许是10几次都有可能。一般经验而言，反复提出5次为什么基本就可以寻找到问题的根因。下面通过两个案例，初步了解5WHY分析法。

案例一：大野耐一的5Why分析  
  有一次，大野耐一先生见到生产线上的机器总是停转，虽然修过多次但仍不见好转，便上前询问  现场的工作人员。  
  （1-Why）问：“为什么机器停了？”答：“因为超过了负荷，保险丝就断了。”  
  （2-Why）问：“为什么超负荷呢？”答：“因为轴承的润滑不够。”  
  （3-Why）问：“为什么润滑不够？”答：“因为润滑泵吸不上油来。”  
  （4-Why）问：“为什么吸不上油来？”答：“因为油泵轴磨损、松动了。”  
  （5-Why）问：“为什么磨损了呢？”答：“因为没有安装过滤器，混进了铁屑等杂质。”  
  经过连续五次不停地问“为什么”，找到问题的真正原因（润滑油里面混进了杂质）和真正的解决方案（在油泵轴上安装过滤器）。由现象推其本质，找到永久性解决问题的方案，这就是5-Why。


SCQA模型是一个“结构化表达”工具，是麦肯锡咨询顾问芭芭拉·明托在《金字塔原理》中提出的。  
  
S（Situation）情景——由大家都熟悉的情景、事实引入。  
C（Complication）冲突——实际情况往往和我们的要求有冲突。  
Q（Question）疑问——怎么办？  
A（Answer）回答——我们的解决方案是设么？

  

负责系统的环境部署和整体实施(S)根据用户反馈(Q),进行客户端的多层测试以及站点设置调配，定位系统界面打开失败原因(C),并在相应站点标注，制作相对应用户使用文档(A)

整个叙述结构，其核心是可以形成良好的沟通氛围，然后带出冲突和疑问，最后提供可行的解决方案。  
  
得了灰指甲！——陈述背景S  
一个传染俩！——在这个背景下发生了冲突C  
问我怎么办？——站在对方的角度，提出疑惑Q  
马上用亮甲！——给出解决方案A，这是文案要表达的重点  
「SCQA法则」比「STAR 法则」更有效一点是：会让你的简历看起来对解决某项问题有更高的针对性，能够很容易让人设身处地代入该情景中。  
  
面试官招你进来的最核心目的就是要你帮忙解决他的问题。谁能在简历上反映出你有很强的解决问题的能力，你就能比别人更胜一筹。这样的简历为后续面试的铺垫作用，自然而然就更大了。

异构数据同步平台数据一致性差，消费速度慢  ----S
导致了线上容易堆积，数据错误 ----C
问题的核心是要保证数据一致性的前提下尽可能提高多个业务线的数据同步速度 ----Q
我通过合理的kafka分片策略保证同一行数据变更一致性，然后消费msg输入到hbase做一个大宽表来支撑多个业务，然后通过任务去重的方式降低写入量。 --A

# Reference
https://pandaychen.github.io/2021/08/18/A-GOLANG-ASYNQ-ANALYSIS/