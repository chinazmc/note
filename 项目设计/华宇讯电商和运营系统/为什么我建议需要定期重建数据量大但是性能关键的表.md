一般现在对于业务要查询的数据量以及要保持的并发量高于一定配置的单实例 [MySQL](https://cloud.tencent.com/product/cdb?from_column=20065&from=20065) 的极限的情况，都会采取分库分表的方案解决。当然，现在也有很多 new SQL 的分布式数据库的解决方案，如果你用的是 **MySQL**，那么你可以考虑 **TiDB**（实现了 MySQL 协议，兼容 MySQL 客户端以及 SQL 语句）。如果你用的是的 **PgSQL**，那么你可以考虑使用 **YugaByteDB**（实现了 PgSQL 协议，兼容 PgSQL 客户端以及 SQL 语句），他们目前都有自己的云部署解决方案，你可以试试：

- [TiDB Cloud](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Ftidbcloud.com%2F)
- [YugaByte Cloud](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Fcloud.yugabyte.com%2F)

但是对于传统分库分表的项目，底层的数据库还是基于 MySQL 以及 PgSQL 这样的传统[关系型数据库](https://cloud.tencent.com/product/cdb-overview?from_column=20065&from=20065)。一般在业务刚开始的时候，会考虑按照某个分片键多分一些表，例如订单表，我们估计用户直接要查的订单记录是最近一年内的。如果是一年前的，提供其他入口去查，这时候查的就不是有业务数据库了，而是归档数据库，例如 [HBase](https://cloud.tencent.com/product/hbase?from_column=20065&from=20065) 这样的。例如我们估计一年内用户订单，最多不会超过 10 亿，更新的并发 TPS （非查询 QPS）不会超过 10 万/s。那么我们可以考虑分成 64 张表（个数最好是 2^n，因为 2^n 取余数 = 对 2^n - 1 取与运算，减少分片键运算量）。然后我们还会定时的归档掉一年前的数据，使用类似于 delete from table 这样的语句进行“**彻底删除**”（注意这里是引号的删除）。这样保证业务表的数据量级一直维持在

然而，日久天长以后，会发现，某些带分片键（这里就是用户 id）的普通查询，也会有些慢，有些走错本地索引。

## 查询越来越慢的原因

例如这个 SQL：

```sql
select * from t_pay_record
WHERE
((
	user_id = 'user_id1' 
	AND is_del = 0 
)) 
ORDER BY
	id DESC 
	LIMIT 20
```

复制

这个表的分片键就是 user_id

一方面，正如我在“[为什么我建议在复杂但是性能关键的表上所有查询都加上 force index](https://cloud.tencent.com/developer/tools/blog-entry?target=https%3A%2F%2Fwww.bilibili.com%2Fread%2Fcv15433071)”中说的，数据量可能有些超出我们的预期，导致某些分片表大于一定界限，**导致 MySQL 对于索引的随机采样越来越不准**，由于统计数据不是实时更新，而是更新的行数超过一定比例才会开始更新。并且统计数据不是全量统计，是抽样统计。所以在表的数据量很大的时候，这个统计数据很难非常准确。依靠表本身自动刷新数据机制，参数比较难以调整（主要是 `STATS_SAMPLE_PAGES` 这个参数，`STATS_PERSISTENT` 我们一般不会改，我们不会能接受在内存中保存，这样万一数据库重启，表就要重新分析，这样减慢启动时间，`STATS_AUTO_RECALC` 我们也不会关闭，这样会导致优化器分析的越来越不准确），很难预测出到底调整到什么数值最合适。并且业务的增长，用户的行为导致的数据的倾斜，也是很难预测的。通过 Alter Table 修改某个表的 `STATS_SAMPLE_PAGES` 的时候，会导致和 Analyze 这个 Table 一样的效果，会在表上加读锁，会阻塞表上的更新以及事务。所以不能在这种在线业务关键表上面使用。所以最好一开始就能估计出大表的量级，但是这个很难。

所以，我们考虑对于数据量比较大的表，最好能提前通过分库分表控制每个表的数据量，但是业务增长与产品需求都是不断在迭代并且变复杂的。很难保证不会出现大并且索引比较复杂的表。这种情况下需要我们，在适当调高 `STATS_SAMPLE_PAGES` 的前提下，对于一些用户触发的关键查询 SQL，**使用 force index 引导它走正确的索引**。

但是，**有时候即使索引走对了，查询依然有点慢**。具体去看这个 SQL 扫描的数据行数的时候，发现并没有很多。

```sql
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+-------------+---------+------+-------+----------+-------------+
| id | select_type | table        | partitions | type  | possible_keys                                                                           | key         | key_len | ref  | rows  | filtered | Extra       |
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+-------------+---------+------+-------+----------+-------------+
|  1 | SIMPLE      | t_pay_record | NULL       | index | idx_user_id,idx_user_status_pay,idx_user_id_trade_code_status_amount_create_time_is_del | idx_user_id | 32      | NULL |   16  |     0.01 | Using where |
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+-------------+---------+------+-------+----------+-------------+
```

可能还是会有偶现的这样的慢 SQL，并且随着时间推移越来越多，这个就和 MySQL InnoDB 里面的删除机制有关系了。目前大部分业务表都用的 InnoDB 引擎，并且都用的默认的行格式 Dynamic，在这种行格式下我们在插入一条数据的时候，其结构大概如下所示：

![image](https://ask.qcloudimg.com/http-save/yehe-8494643/7571ecd9805a093a0695370751630ed4.png)

image

记录头中，有删除标记：

![image](https://ask.qcloudimg.com/http-save/yehe-8494643/99135ac252aefc314deab62a318b2550.png)

image

当发生导致记录长度变化的更新时，例如变长字段实际数据变得更长这种，会将原来的记录标记为删除，然后在末尾创建更新后的记录。当删除一条记录的时候，也是只是标记记录头的删除标记。

![image](https://ask.qcloudimg.com/http-save/yehe-8494643/11812be0b8ea9a2d73c7d80bbdc33cf6.png)

image

对于这种可能的碎片化，MySQL InnoDB 也是有期望并且措施的，**即每个页面 InnoDB 引擎只会存储占用 93% 空间的数据，剩下的就是为了能让长度变化的更新不会导致数据跑到其他页面**。但是相对的，如果 Delete 就相当于完全浪费了存储空间了。

一般情况下这种不会造成太大的性能损耗，因为删除一般是删的老的数据，更新一般集中在最近的数据。例如订单发生更新，一般是时间最近的订单才会更新，很少会有很久前的订单基本不会更新，并且归档删除的一般也是很久之前的订单。但是随着业务越来越复杂，归档逻辑也越来越复杂，比如不同类型的订单时效不一样，可能出现一年前还有未结算的预购订单不能归档。久而久之，你的数据可能会变成这样：

![image](https://ask.qcloudimg.com/http-save/yehe-8494643/fc36378b68731bc43c1e3f6dbdb531c3.png)

image

这样导致，原来你需要扫描很少页的数据，随着时间的推移，**碎片越来越多**，要扫描的页越来越多，这样 SQL 执行会越来越慢。

**以上是对于表本身数据存储的影响，对于二级索引，由于 MVCC 机制的存在，导致频繁更新索引字段会对索引也造成很多空洞**。参考文档：https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html

> InnoDB multiversion concurrency control (MVCC) treats secondary indexes differently than clustered indexes. Records in a clustered index are updated in-place, and their hidden system columns point undo log entries from which earlier versions of records can be reconstructed. Unlike clustered index records, secondary index records do not contain hidden system columns nor are they updated in-place.

我们知道，MySQL InnoDB 对于聚簇索引是在索引原始位置上进行更新，对于二级索引，如果二级索引列发生更新则是在原始记录上打上删除标记，然后在新的地方记录。这样和之前一样，会造成很多存储碎片。

综上所述：

1. **MySQL InnoDB 的会改变记录长度的 Dynamic 行格式记录 Update，以及 Delete 语句，其实是原有记录的删除标记打标记。虽然 MySQL InnoDB 对于这个有做预留空间的优化，但是日积月累，随着归档删除数据的增多，会有很多内存碎片降低扫描效率**。
2. **MVCC 机制对于二级索引列的更新，是在原始记录上打上删除标记，然后在新的地方记录，导致二级索引的扫描效率也随着时间积累而变慢**。

## 解决方案 - 重建表

对于这种情况，我们可以通过重建表的方式解决。重建表其实是一举两得的行为：第一可以优化这种存储碎片，减少要扫描的行数；第二可以重新 analyze 让 SQL 优化器采集数据更准确。

在 MySQL 5.6.17 之前，我们需要借助外部工具 pt-online-schema-change 来帮助我们完成表的重建，pt-online-schema-change 工具的原理其实就是内部新建表，在原表上加好触发器同步更新到新建的表，并且同时复制数据到新建的表中，完成后，获取全局锁修改新建的表名字为原来的表名字，之后删除原始表。**MySQL 5.6.17 之后**，Optimize table 命令变成了 Online DDL，仅仅在准备阶段以及最后的提交阶段，需要获取锁，中间的执行阶段，是不需要锁的，也就是不会阻塞业务的更新 DML。参考官网文档：https://dev.mysql.com/doc/refman/5.6/en/optimize-table.html

> Prior to Mysql 5.6.17, OPTIMIZE TABLE does not use online DDL. Consequently, concurrent DML (INSERT, UPDATE, DELETE) is not permitted on a table while OPTIMIZE TABLE is running, and secondary indexes are not created as efficiently.
> 
> As of MySQL 5.6.17, OPTIMIZE TABLE uses online DDL for regular and partitioned InnoDB tables, which reduces downtime for concurrent DML operations. The table rebuild triggered by OPTIMIZE TABLE is completed in place. An exclusive table lock is only taken briefly during the prepare phase and the commit phase of the operation. During the prepare phase, metadata is updated and an intermediate table is created. During the commit phase, table metadata changes are committed.

针对 InnoDB 表使用 Optimize Table 命令需要注意的一些点：

1.针对大部分 InnoDB 表的 Optimize Table，其实等价于重建表 + Analyze命令（等价于语句 `ALTER TABLE ... FORCE`），但是与 Analyze 命令不同的是， Optimize Table 是 online DDL 并且优化了机制，**只会在准备阶段和最后的提交阶段获取表锁，这样大大减少了业务 DML 阻塞时间，也就是说，这是一个可以考虑在线执行的优化语句**(针对 MySQL 5.6.17之后是这样)

```sql
mysql> OPTIMIZE TABLE foo;
+----------+----------+----------+-------------------------------------------------------------------+
| Table    | Op       | Msg_type | Msg_text                                                          |
+----------+----------+----------+-------------------------------------------------------------------+
| test.foo | optimize | note     | Table does not support optimize, doing recreate + analyze instead |
| test.foo | optimize | status   | OK                                                                |
+----------+----------+----------+-------------------------------------------------------------------+
```

2.虽然如此，还是要选择在业务低峰的时候执行 Optimize Table，因为和执行其他的 Online DDL 一样，会创建并记录临时日志文件，该文件记录了DDL操作期间所有 DML 插入、更新、删除的数据，如果是在业务高峰的时候执行，很可能会造成日志过大，超过`innodb_online_alter_log_max_size` 的限制：

```javascript
mysql> OPTIMIZE TABLE foo;
+----------+----------+----------+----------------------------------------------------------------------------------------------------------------------------+
| Table    | Op       | Msg_type | Msg_text                                                                                                                   |
+----------+----------+----------+----------------------------------------------------------------------------------------------------------------------------+
| test.foo | optimize | note     | Table does not support optimize, doing recreate + analyze instead                                                          |
| test.foo | optimize | error    | Creating index 'PRIMARY' required more than 'innodb_online_alter_log_max_size' bytes of modification log. Please try again.|
| test.foo | optimize | status   | OK                                                                                                                         |
+----------+----------+----------+----------------------------------------------------------------------------------------------------------------------------+
```

复制

3.对于这种情况，如果我们已经处于业务低峰时段，但还是报这个错误，我们可以稍微调大 `innodb_online_alter_log_max_size` 的大小，但是不能调太大，建议每次调大 128 MB（默认是 128 MB）。如果这个过大，会可能有两个问题：（1）最后的提交阶段，由于日志太大，提交耗时过长，导致锁时间过长。（2）由于业务压力导致一直不断地写入这个临时文件，但是一直赶不上，导致业务高峰到得时候这个语句还在执行。 4.建议在执行的时候，如果要评估这个对于线上业务的影响，可以针对锁 `wait/synch/sxlock/innodb/dict_sys_lock` 和 `wait/synch/sxlock/innodb/dict_operation_lock` 这两个锁进行监控，如果这两个锁相关锁事件太多，并且线上有明显的慢 SQL，建立还是 kill 掉选其他时间执行 Optimize table 语句。

```javascript
select thread_id,event_id,event_name,timer_wait from events_waits_history where event_name Like "%dict%" order by thread_id;

SELECT event_name,COUNT_STAR FROM events_waits_summary_global_by_event_name 
where event_name Like "%dict%" ORDER BY COUNT_STAR DESC;
```
# 为什么我建议在复杂但是性能关键的表上所有查询都加上 force index

最近，又遇到了慢 SQL，简单的看了下，又是因为 [MySQL](https://cloud.tencent.com/product/cdb?from_column=20065&from=20065) 本身优化器还有查询计划估计不准的问题。SQL 如下：

```javascript
select * from t_pay_record
WHERE
((
	user_id = 'user_id1' 
	AND is_del = 0 
)) 
ORDER BY
	id DESC 
	LIMIT 20
```

复制

这个 SQL 执行了 20 分钟才有结果。但是我们**换一个 user_id，执行就很快**。**从线上业务表现来看，大部分用户的表现都正常**。**我们又用一个数据分布与这个用户相似的用户去查，还是比较快**。

我们先来 EXPLAIN 下这个原始 SQL，结果是：

```javascript
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+---------+---------+------+-------+----------+-------------+
| id | select_type | table        | partitions | type  | possible_keys                                                                           | key     | key_len | ref  | rows  | filtered | Extra       |
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+---------+---------+------+-------+----------+-------------+
|  1 | SIMPLE      | t_pay_record | NULL       | index | idx_user_id,idx_user_status_pay,idx_user_id_trade_code_status_amount_create_time_is_del | PRIMARY | 8       | NULL | 22593 |     0.01 | Using where |
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+---------+---------+------+-------+----------+-------------+
```

复制

然后我们换一些分布差不多的用户但是响应时间正常的用户，EXPLAIN 结果有的是：

```javascript
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+---------------------------------------------------------+---------+------+-------+----------+-------------+
| id | select_type | table        | partitions | type  | possible_keys                                                                           | key                                                     | key_len | ref  | rows  | filtered | Extra       |
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+---------------------------------------------------------+---------+------+-------+----------+-------------+
|  1 | SIMPLE      | t_pay_record | NULL       | index | idx_user_id,idx_user_status_pay,idx_user_id_trade_code_status_amount_create_time_is_del | idx_user_id_trade_code_status_amount_create_time_is_del | 195     | NULL | 107561|     10.00| Using where |
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+---------------------------------------------------------+---------+------+-------+----------+-------------+
```

复制

有的是：

```javascript
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+-------------+---------+------+-------+----------+-------------+
| id | select_type | table        | partitions | type  | possible_keys                                                                           | key         | key_len | ref  | rows  | filtered | Extra       |
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+-------------+---------+------+-------+----------+-------------+
|  1 | SIMPLE      | t_pay_record | NULL       | index | idx_user_id,idx_user_status_pay,idx_user_id_trade_code_status_amount_create_time_is_del | idx_user_id | 195     | NULL |  87514|     10.00| Using where |
+----+-------------+--------------+------------+-------+-----------------------------------------------------------------------------------------+-------------+---------+------+-------+----------+-------------+
```

复制

其实根据这个表现就可以推断出，是走错索引了。**为啥会用错索引呢**？这个是因为多方面的原因导致的，本篇文章将针对这个 SQL 来分析下这个多方面的原因，并给出最后的解决办法。

## 对于 MySQL 慢 SQL 的分析

在之前的文章，我提到过 SQL 调优一般通过下面三个工具：

1. EXPLAIN：这个是比较浅显的分析，并不会真正执行 SQL，分析出来的可能不够准确详细。但是能发现一些关键问题。
2. PROFILING： 通过 `set profiling = 1` 开启的 SQL 执行采样。可以分析 SQL 执行分为哪些阶段，并且每阶段的耗时如何。需要执行并且执行成功 SQL，并且分析出来的阶段不够详细，一般只能通过某些阶段是否存在如何避免这些阶段的出现进行优化（例如避免内存排序的出现等等）。
3. OPTIMIZER TRACE：详细展示优化器的每一步，需要执行并且执行成功 SQL。MySQL 的优化器由于考虑的因素太多，迭代太多，配置相当复杂，默认的配置在大部分情况没问题，但是在某些特殊情况会有问题，需要我们进行人为干预。

这里再说一下在不同的 MySQL 版本， **EXPLAIN 和 OPTIMIZER TRACE 结果可能不同，这是 MySQL 本身设计上的不足导致的，EXPLAIN 更贴近最后的执行结果，OPTIMIZER TRACE 相当于在每一步埋点采集，在 MySQL 不断迭代开发的时候，难免会有疏漏**

对于上面这个 SQL，我们其实 EXPLAIN 就能知道它的原因是走错索引了。但是不能直观的看出来为啥会走错索引，需要通过 OPTIMIZER TRACE 进行进一步定位。但是在进一步定位之前，我想先说一下 MySQL 的 InnoDB 查询优化器数据配置。

## MySQL InnoDB 查询优化器数据配置（MySQL InnoDB Optimizer Statistics）

> 官网文档地址：https://dev.mysql.com/doc/refman/8.0/en/innodb-persistent-stats.html

为了优化用户的 SQL 查询，MySQL 会对所有 SQL 查询进行 SQL 解析、改写和查询计划优化。针对 InnoDB 引擎，制定查询计划的时候要分析：

1. 全表扫描消耗是多大
2. 走索引可以走哪些索引？会考虑 where 条件，以及 order 条件，通过里面的条件找有这些条件的索引
3. 每个索引的查询消耗是多大
4. 选出消耗最小的那个查询计划并执行

每个索引查询消耗，需要通过 InnoDB 查询优化器数据。这个数据是通过采集表以及索引数据得出的，并且并不是全量采集，而是抽样采集。与以下配置相关：

1. `innodb_stats_persistent` 全局变量控制全局默认的数据是否持久化，默认为 ON 即持久化，我们一般不会能接受在内存中保存，这样万一[数据库](https://cloud.tencent.com/solution/database?from_column=20065&from=20065)重启，表就要重新分析，这样减慢启动时间。控制单个表的配置是 `STATS_PERSISTENT`（在 `CREATE TABLE` 以及 `ALTER TABLE` 中使用）。
2. `innodb_stats_auto_recalc` 全局变量全局默认是否自动更新，默认为 ON 即在表中有 10% 以上的行更新后触发后台异步更新采集数据，。控制单个表的配置是 `STATS_AUTO_RECALC`（在 `CREATE TABLE` 以及 `ALTER TABLE` 中使用）。
3. `innodb_stats_persistent_sample_pages` 全局变量控制全局默认的采集页的数量，默认为 20. 即每次更新，随机采集表以及表中的每个索引的 20 页数据，用于**估算每个索引的查询消耗是多大以及全表扫描消耗是多大**，控制单个表的配置是 `STATS_SAMPLE_PAGES`（在 `CREATE TABLE` 以及 `ALTER TABLE` 中使用）。

## 执行时间最慢的 SQL 原因定位

通过之前的 EXPLAIN 的结果，我们知道最后的查询用的索引是 PRIMARY 主键索引，这样的话整个 SQL 的执行过程就是：通过主键倒序遍历表中的每一条数据，直到筛选出 20 条。通过执行耗时我们知道，这个遍历了很多数据才凑满 20 条，效率极其低下。为啥会这样呢？

通过 SQL 语句我们知道，在前面提到的第二步中，考虑的索引包括 where 条件中的 user_id，is_del 相关的索引（通过 EXPLAIN 我们知道有这些索引：`idx_user_id,idx_user_status_pay,idx_user_id_trade_code_status_amount_create_time_is_del`），以及 order by 条件中的 id 索引，也就是主键索引。假设本次随机采集中采集的页数据是这个样子的：

![image](https://ask.qcloudimg.com/http-save/yehe-8494643/3774ccb8ed8c547982e8de54a6d99f33.png)

image

图中蓝色的代表抽样到的页，同一个表内每个索引都会抽样默认 20 页。假设本次采集的结果就是图中所示，其他索引采集的比较均衡，通过其他索引判断用户都要扫描几万行的结果。但是主键采集的最后一页，正好末尾全是这个用户的记录。由于语句最后有 limit 20，如果末尾正好有 20 条记录（并且都符合 where 条件），那么就会认为按照主键倒着找 20 条记录就可以了。这样就会造成优化器认为走主键扫描消耗最少。但是实际上并不是这样，因为这是采样的，没准后面有很多很多不是这个用户的记录，对大表尤其如此。

**如果我们把 limit 去掉，EXPLAIN 就会发现索引走对了，因为不限制 limit，主键索引就要全部扫描一遍，消耗怎么也不可能比 user_id 相关的索引低了**。

## 执行时间正常的 SQL 为啥 user_id 不同也会走分析出走不同索引的原因

同样的，由于所有索引的优化器数据是随机采样的，随着表的不断变大以及索引的不断膨胀，还有就是可能加更复杂的索引，这样会加剧使用不同参数分析索引消耗的差异性（这里就是使用不同的 user_id）。

这也引出了一个新的可能大家也会遇到的问题，我在原有索引的基础上，加了一个复合索引（举个例子就是原来只有 idx_user_id，后来加了 idx_user_status_pay），那么原来的只按照 user_id 去查数据的 SQL，有的可能会使用 idx_user_id，有的可能会使用 idx_user_status_pay，使用 idx_user_status_pay 大概率比使用 idx_user_id， 慢。所以，**添加新的复合索引，可能会导致原来的不是这个复合索引要优化的 SQL 的其他业务 SQL 变慢，所以需要慎重添加**

## 这种设计，在数据量不断增大表越变越复杂的时候，会带来哪些问题

1. 由于统计数据不是实时更新，而是更新的行数超过一定比例才会开始更新。并且统计数据不是全量统计，是抽样统计。所以在表的数据量很大的时候，这个统计数据很难非常准确。
2. 由于统计数据本来就不够准确，表设计如果也比较复杂，存储的数据类型比较多，字段也很多，并且最关键的是有各种复合索引，索引也越来越复杂，这样更加加剧了这个统计数据的不准确性。
3. 顺便说一下：MySQL 表数据量不能很大，需要做好水平拆分，同时字段不能太多，所以需要做好垂直拆分。并且索引不能随便加，想加多少加多少，也有以上说的这两个原因，这样会加剧统计数据的不准确性，导致用错索引。
4. 手动 Analyze Table，会在表上加读锁，会阻塞表上的更新以及事务。所以不能在这种在线业务关键表上面使用。可以考虑在业务低峰的时候，定时 Analyze 业务关键 Table
5. 依靠表本身自动刷新数据机制，参数比较难以调整（主要是 `STATS_SAMPLE_PAGES` 这个参数，`STATS_PERSISTENT` 我们一般不会改，我们不会能接受在内存中保存，这样万一数据库重启，表就要重新分析，这样减慢启动时间，`STATS_AUTO_RECALC` 我们也不会关闭，这样会导致优化器分析的越来越不准确），很难预测出到底调整到什么数值最合适。并且业务的增长，用户的行为导致的数据的倾斜，也是很难预测的。通过 Alter Table 修改某个表的 `STATS_SAMPLE_PAGES` 的时候，会导致和 Analyze 这个 Table 一样的效果，会在表上加读锁，会阻塞表上的更新以及事务。所以不能在这种在线业务关键表上面使用。所以最好一开始就能估计出大表的量级，但是这个很难。

## 结论和建议

综上所述，我建议线上对于数据量比较大的表，最好能提前通过分库分表控制每个表的数据量，但是业务增长与产品需求都是不断在迭代并且变复杂的。很难保证不会出现大并且索引比较复杂的表。这种情况下需要我们，在适当调高 `STATS_SAMPLE_PAGES` 的前提下，对于一些用户触发的关键查询 SQL，使用 force index 引导它走正确的索引，这样就不会出现本文中说的因为 MySQL 优化器表采集数据的不准确导致的某些用户 id 查询走错索引的情况。
# Reference
https://cloud.tencent.com/developer/article/1999970
https://cloud.tencent.com/developer/article/1996954

