# 怎么使用
同一个查询条件，可以将入参什么的作为key，返回值作为value放到redis缓存，如果没有的话，就查询redis和mysql的原始数据然后将回参放到本地缓存中，并加上一个极短的过期时间，目前设置是五分钟，没错就是五分钟，然后设置的过程需要加redis nx分布式锁，用来保证不会重复插入缓存

当然我们完全可以把这个动作放到本地缓存中，可以以此来作为一个渐进式的缓存填充动作，保证准确性和速度的一个平衡，毕竟少点缓存，就少点数据不一致的风险，并且每个缓存可以不在同一个时间失效，而且就算出现了数据不一致的情况，也不会说完全等到一个完整的过期时间窗口才开始修正，毕竟每个pod的缓存时间不是同时开始的，总有会个pod比其他pod更早设置缓存和更早失去缓存。

上面这种情况是可以用于布局的数据，查询商品的数据这种情况。

暂时没有做本地缓存强制失效的情况，因为我们的运营商修改数据之后，我们都是建议会在几分钟内同步，让运营商有反悔的机会

理由是，之前用的是团队比较早期封装的cache(就是下面这个)，我稍微按照freeCache改了一下，让其他人不需要改动协议
并且对freeCache进行了一些特定的优化。
优化方案：freecache 因为其高效的性能获得很多人的喜爱，我也不例外。却因为里面使用了go Mutex导致了在非常高的并发情况下性能无法进一步提高，主要原因就是使用 get 方法中的Mutex.Lock()。 通过跟原作者的沟通后，发现因为 freecache get方法并不是只读方法，所以才动了念头修改一版能够满足自己高并发http平台的cache，使用的是rwmutex

之前的freecache使用mutex来读数据，是因为需要修改accessTime，这个accessTime是用来计算lru淘汰规则的，所以作者就不用读写锁，而且另外一个方面，在并发程度比较低的情况下，rwmutex的性能可能比mutex差，因为rwmutex比mutex做了更多的工作。

但是我公司的场景都是用于比较频繁请求的情况才会去弄本地缓存，而且还有自己的热点检测策略，所以进行了rwmutex的修改，并且将lru规则从
```go
leastRecentUsed := int64(oldHdr.accessTime)*atomic.LoadInt64(&seg.totalCount) <= atomic.LoadInt64(&seg.totalTime)
```
改成
```go
randomKeyDelete := !isExistHot && (oldHdr.expireAt & 3) == 3
```
不存在于热点数据且命中四分之一的话就去干掉


# 如何打造高性能的 Go 缓存库

> 本文会通过写一个简单的缓存库来作为例子让大家看看实现一个高性能缓存库需要怎么做。
> 
> 转载请声明出处哦~，本篇文章发布于luozhiyun的博客：[https://www.luozhiyun.com/archives/531](https://www.luozhiyun.com/archives/531)
> 
> 文中代码位置： [https://github.com/devYun/mycache](https://github.com/devYun/mycache)

我在看一些优秀的开源库的时候看到一个有意思的缓存库 fastcache，在它的介绍主要有以下几点特点：

1.  读写数据要快，即使在并发下；
2.  即使在数 GB 的缓存中，也要保持很好的性能，以及尽可能减少 GC 次数；
3.  设计尽可能简单；

本文会通过模仿它写一个简单的缓存库，从而研究其内核是如何实现这样的目标的。希望各位能有所收获。

## 设计思想

在项目中，我们经常会用到 Go 缓存库比如说 `patrickmn/go-cache`库。但很多缓存库其实都是用一个简单的 Map 来存放数据，这些库在使用的时候，当并发低，数据量少的时候是没有问题的，但是在数据量比较大并发比较高的时候会延长 GC 时间，增加内存分配次数。

比如，我们使用一个简单的例子：

```go
func main() {
    a := make(map[string]string, 1e9) 
    for i := 0; i < 10; i++ {
        runtime.GC()
    } 
    runtime.KeepAlive(a)
}
```

在这个例子中，预分配了大小是`10亿（1e9)` 的 map，然后我们通过 `gctrace` 输出一下 GC 情况：

> 做实验的环境是 Linux，机器配置是 16C 8G ，想要更深入理解 GC，可以看这篇：《 Go语言GC实现原理及源码分析 [https://www.luozhiyun.com/archives/475](https://www.luozhiyun.com/archives/475) 》

```
[root@localhost gotest]# GODEBUG=gctrace=1 go run main.go 
...
gc 6 @13.736s 17%: 0.010+1815+0.004 ms clock, 0.17+0/7254/21744+0.067 ms cpu, 73984->73984->73984 MB, 147968 MB goal, 16 P (forced)
gc 7 @15.551s 18%: 0.012+1796+0.005 ms clock, 0.20+0/7184/21537+0.082 ms cpu, 73984->73984->73984 MB, 147968 MB goal, 16 P (forced)
gc 8 @17.348s 19%: 0.008+1794+0.004 ms clock, 0.14+0/7176/21512+0.070 ms cpu, 73984->73984->73984 MB, 147968 MB goal, 16 P (forced)
gc 9 @19.143s 19%: 0.010+1819+0.005 ms clock, 0.16+0/7275/21745+0.085 ms cpu, 73984->73984->73984 MB, 147968 MB goal, 16 P (forced)
gc 10 @20.963s 19%: 0.011+1844+0.004 ms clock, 0.18+0/7373/22057+0.076 ms cpu, 73984->73984->73984 MB, 147968 MB goal, 16 P (forced)
```

上面展示了最后 5 次 GC 的情况，下面我们看看具体的含义是什么：

```
gc 1 @0.004s 4%: 0.22+1.4+0.021 ms clock, 1.7+0.009/0.40/0.073+0.16 ms cpu, 4->5->1 MB, 5 MB goal, 8 P

gc 10 @20.963s 19%: 0.011+1844+0.004 ms clock, 0.18+0/7373/22057+0.076 ms cpu, 73984->73984->73984 MB, 147968 MB goal, 16 P (forced)

gc 10 ：程序启动以来第10次GC
@20.963s：距离程序启动到现在的时间
19%：当目前为止，GC 的标记工作所用的CPU时间占总CPU的百分比

垃圾回收的时间
0.011 ms：标记开始 STW 时间
1844 ms：并发标记时间
0.004 ms：标记终止 STW 时间

垃圾回收占用cpu时间
0.18 ms：标记开始 STW 时间
0 ms：mutator assists占用的时间
7373 ms：标记线程占用的时间
22057 ms：idle mark workers占用的时间
0.076 ms：标记终止 STW 时间

内存
73984 MB：标记开始前堆占用大小
73984 MB：标记结束后堆占用大小
73984 MB：标记完成后存活堆的大小
147968 MB goal：标记完成后正在使用的堆内存的目标大小

16 P：使用了多少处理器
```

可以从上面的输出看到每次 GC 处理的时间非常的长，占用的 CPU 资源也非常多。那么造成这样的原因是什么呢？

`string` 实际上底层数据结构是由两部分组成，其中包含指向字节数组的指针和数组的大小：

```go
type StringHeader struct {
    Data uintptr
    Len  int
}
```

由于 `StringHeader`中包含指针，所以每次 GC 的时候都会扫描每个指针，那么在这个巨大的 `map`中是包含了非常多的指针的，所以造成了巨大的资源消耗。

在上面的例子 `map a` 中数据大概是这样存储：

![maps](https://img.luozhiyun.com/20210516203637.png)

一个 map 中里面有多个 `bucket` ，`bucket` 里面有一个 `bmap` 数组用来存放数据，但是由于 `key` 和 `value` 都是 `string` 类型的，所以在 GC 的时候还需要根据 `StringHeader`中的 `Data`指针扫描 `string` 数据。

对于这种情况，如果所有的string字节都在一个单一内存片段中，我们就可以通过偏移来追踪某个字符串在这段内存中的开始和结束位置。通过追踪偏移，我们不在需要在我们大数组中存储指针，GC也不在会被困扰。如下：

![maps2](https://img.luozhiyun.com/20210516203645.png)

如同上面所示，如果我们将字符串中的字节数据拷贝到一个连续的字节数组 `chunks` 中，并为这个字节数组提前分配好内存，并且仅存储字符串在数组中的偏移而不是指针。

除了上面所说的优化内容以外，还有其他的方法吗？

其实我们还可以直接从系统 OS 中调用 `mmap syscall` 进行内存分配，这样 GC 就永远不会对这块内存进行内存管理，因此也就不会扫描到它。如下：

```go
func main() { 
    test := "hello syscall"
    data, _ := syscall.Mmap(-1, 0, 13, syscall.PROT_READ|syscall.PROT_WRITE, syscall.MAP_ANON|syscall.MAP_PRIVATE)
    p := (*[13]byte)(unsafe.Pointer(&data[0]))

    for i := 0; i < 13; i++ {
        p[i] = test[i]
    }
    fmt.Println(string(p[:]))
}
```

通过系统调用直接向 OS 申请了 13bytes 的内存，然后将一个字符串写入到申请的内存数组中。

所以我们也可以通过提前向 OS 申请一块内存，而不是用的时候才申请内存，减少频繁的内存分配从而达到提高性能的目的。

## 源码实战

### API

我们在开发前先把这个库的 API 定义一下：

#### func New

```go
func New(maxBytes int) *Cache
```

创建一个 Cache 结构体，传入预设的缓存大小，单位是字节。

#### func (\*Cache) Get

```go
func (c *Cache) Get(k []byte) []byte
```

获取 Cache 中的值，传入的参数是 byte 数组。

#### func (\*Cache) Set

```go
func (c *Cache) Set(k, v []byte)
```

设置键值对到缓存中，k 是键，v 是值，参数都是 byte 数组。

### 结构体

```go
const bucketsCount = 512

type Cache struct { 
    buckets [bucketsCount]bucket
}

type bucket struct {
    // 读写锁
    mu sync.RWMutex

    // 二维数组，存放数据的地方，是一个环形链表
    chunks [][]byte

    // 索引字典
    m map[uint64]uint64

    // 索引值
    idx uint64

    // chunks 被重写的次数，用来校验环形链表中数据有效性
    gen uint64
}
```

通过我们上面的分析，可以看到，实际上真正存放数据的地方是 chunks 二维数组，在实现上是通过 m 字段来映射索引路径，根据 chunks 和 gen 两个字段来构建一个环形链表，环形链表每转一圈 gen 就会加一。

![mycache](https://img.luozhiyun.com/20210516203651.png)

### 初始化

```go
func New(maxBytes int) *Cache {
    if maxBytes <= 0 {
        panic(fmt.Errorf("maxBytes must be greater than 0; got %d", maxBytes))
    }
    var c Cache
    // 算出每个桶的大小 
    maxBucketBytes := uint64((maxBytes + bucketsCount - 1) / bucketsCount)
    for i := range c.buckets[:] {
    // 对桶进行初始化
        c.buckets[i].Init(maxBucketBytes)
    }
    return &c
}
```

我们会设置一个 New 函数来初始化我们 Cache 结构体，在 Cache 结构体中会将缓存的数据大小平均分配到每个桶中，然后对每个桶进行初始化。

```go
const bucketSizeBits = 40
const maxBucketSize uint64 = 1 << bucketSizeBits
const chunkSize = 64 * 1024

func (b *bucket) Init(maxBytes uint64) {
    if maxBytes == 0 {
        panic(fmt.Errorf("maxBytes cannot be zero"))
    }
  // 我们这里限制每个桶最大的大小是 1024 GB
    if maxBytes >= maxBucketSize {
        panic(fmt.Errorf("too big maxBytes=%d; should be smaller than %d", maxBytes, maxBucketSize))
    }
    // 初始化 Chunks 中每个 Chunk 大小为 64 KB，计算 chunk 数量
    maxChunks := (maxBytes + chunkSize - 1) / chunkSize
    b.chunks = make([][]byte, maxChunks)
    b.m = make(map[uint64]uint64)
    // 初始化 bucket 结构体
    b.Reset()
}
```

在这里会将桶里面的内存按 chunk 进行分配，每个 chunk 占用内存约为 64 KB。在最后会调用 bucket 的 Reset 方法对 bucket 结构体进行初始化。

```go
func (b *bucket) Reset() {
    b.mu.Lock()
    chunks := b.chunks
    // 遍历 chunks
    for i := range chunks {
        // 将 chunk 中的内存归还到缓存中
        putChunk(chunks[i])
        chunks[i] = nil
    }
    // 删除索引字典中所有的数据
    bm := b.m
    for k := range bm {
        delete(bm, k)
    }
    b.idx = 0
    b.gen = 1
    b.mu.Unlock()
}
```

Reset 方法十分简单，主要就是清空 chunks 数组、删除索引字典中所有的数据以及重置索引 idx 和 gen 的值。

在上面这个方法中有一个 putChunk ，其实这个就是直接操作我们提前向 OS 申请好的内存，相应的还有一个 getChunk 方法。下面我们具体看看 Chunk 的操作。

### Chunk 操作

#### getChunk

```go
const chunksPerAlloc = 1024
const chunkSize = 64 * 1024

var (
    freeChunks     []*[chunkSize]byte
    freeChunksLock sync.Mutex
)

func getChunk() []byte {
    freeChunksLock.Lock()
    if len(freeChunks) == 0 {
        // 分配  64 * 1024 * 1024 = 64 MB 内存
        data, err := syscall.Mmap(-1, 0, chunkSize*chunksPerAlloc, syscall.PROT_READ|syscall.PROT_WRITE, syscall.MAP_ANON|syscall.MAP_PRIVATE)
        if err != nil {
            panic(fmt.Errorf("cannot allocate %d bytes via mmap: %s", chunkSize*chunksPerAlloc, err))
        }
        // 循环遍历 data 数据
        for len(data) > 0 {
            //将从系统分配的内存分为 64 * 1024 = 64 KB 大小，存放到 freeChunks中
            p := (*[chunkSize]byte)(unsafe.Pointer(&data[0]))
            freeChunks = append(freeChunks, p)
            data = data[chunkSize:]
        }
    }
    //从 freeChunks 获取最后一个元素
    n := len(freeChunks) - 1
    p := freeChunks[n]
    freeChunks[n] = nil
    freeChunks = freeChunks[:n]
    freeChunksLock.Unlock()
    return p[:]
}
```

初次调用 getChunk 函数时会使用系统调用分配 64MB 的内存，然后循环将内存切成 1024 份，每份 64KB 放入到 freeChunks 空闲列表中。然后获取每次都获取 freeChunks 空闲列表最后一个元素 64KB 内存返回。需要注意的是 getChunk 会下下面将要介绍到的 Cache 的 set 方法中使用到，所以需要考虑到并发问题，所以在这里加了锁。

#### putChunk

```go
func putChunk(chunk []byte) {
    if chunk == nil {
        return
    }
    chunk = chunk[:chunkSize]
    p := (*[chunkSize]byte)(unsafe.Pointer(&chunk[0]))

    freeChunksLock.Lock()
    freeChunks = append(freeChunks, p)
    freeChunksLock.Unlock()
}
```

putChunk 函数就是将内存数据还回到 freeChunks 空闲列表中，会在 bucket 的 Reset 方法中被调用。

### Set

```go
const bucketsCount = 512

func (c *Cache) Set(k, v []byte) {
    h := xxhash.Sum64(k)
    idx := h % bucketsCount
    c.buckets[idx].Set(k, v, h)
}
```

Set 方法里面会根据 k 的值做一个 hash，然后取模映射到 buckets 桶中，这里用的 hash 库是 `cespare/xxhash`。

最主要的还是 buckets 里面的 Set 方法：

```go
func (b *bucket) Set(k, v []byte, h uint64) {
    // 限定 k v 大小不能超过 2bytes
    if len(k) >= (1<<16) || len(v) >= (1<<16) {
        return
    }
    // 4个byte 设置每条数据的数据头
    var kvLenBuf [4]byte
    kvLenBuf[0] = byte(uint16(len(k)) >> 8)
    kvLenBuf[1] = byte(len(k))
    kvLenBuf[2] = byte(uint16(len(v)) >> 8)
    kvLenBuf[3] = byte(len(v))
    kvLen := uint64(len(kvLenBuf) + len(k) + len(v))
    // 校验一下大小
    if kvLen >= chunkSize {
        return
    }

    b.mu.Lock()
    // 当前索引位置
    idx := b.idx
    // 存放完数据后索引的位置
    idxNew := idx + kvLen
    // 根据索引找到在 chunks 的位置
    chunkIdx := idx / chunkSize
    chunkIdxNew := idxNew / chunkSize
    // 新的索引是否超过当前索引
    // 因为还有chunkIdx等于chunkIdxNew情况，所以需要先判断一下
    if chunkIdxNew > chunkIdx {
        // 校验是否新索引已到chunks数组的边界
        // 已到边界，那么循环链表从头开始
        if chunkIdxNew >= uint64(len(b.chunks)) {
            idx = 0
            idxNew = kvLen
            chunkIdx = 0
            b.gen++
            // 当 gen 等于 1<<genSizeBits时，才会等于0
            // 也就是用来限定 gen 的边界为1<<genSizeBits
            if b.gen&((1<<genSizeBits)-1) == 0 {
                b.gen++
            }
        } else {
            // 未到 chunks数组的边界,从下一个chunk开始
            idx = chunkIdxNew * chunkSize
            idxNew = idx + kvLen
            chunkIdx = chunkIdxNew
        }
        // 重置 chunks[chunkIdx]
        b.chunks[chunkIdx] = b.chunks[chunkIdx][:0]
    }
    chunk := b.chunks[chunkIdx]
    if chunk == nil {
        chunk = getChunk()
        // 清空切片
        chunk = chunk[:0]
    }
    // 将数据 append 到 chunk 中
    chunk = append(chunk, kvLenBuf[:]...)
    chunk = append(chunk, k...)
    chunk = append(chunk, v...)
    b.chunks[chunkIdx] = chunk
    // 因为 idx 不能超过bucketSizeBits，所以用一个 uint64 同时表示gen和idx
    // 所以高于bucketSizeBits位置表示gen
    // 低于bucketSizeBits位置表示idx
    b.m[h] = idx | (b.gen << bucketSizeBits)
    b.idx = idxNew
    b.mu.Unlock()
}
```

1.  在这段代码开头实际上我会限制键值的大小不能超过 2bytes；
2.  然后将 2bytes 大小长度的键值封装到 4bytes 的 kvLenBuf 作为数据头，数据头和键值的总长度是不能超过一个 chunk 长度，也就是 `64 * 1024`；
3.  然后计算出原索引 chunkIdx 和新索引 chunkIdxNew，用来判断这次添加的数据加上原来的数据有没有超过一个 chunk 长度；
4.  根据新的索引找到对应的 chunks 中的位置，然后将键值以及 kvLenBuf 追加到 chunk 后面；
5.  设置新的 idx 以及 m 字典对应的值，m 字典中存放的是 gen 和 idx 通过取与的放置存放。

在 Set 一个键值对会有 4bytes 的 kvLenBuf 作为数据头，后面的数据会接着 key 和 value ，在 kvLenBuf 中，前两个 byte 分别代表了 key 长度的低位和高位；后两个 byte 分别代表了 value 长度的低位和高位，数据图大致如下：

![mycache2](https://img.luozhiyun.com/20210516203659.png)

下面举个例子来看看是是如何利用 chunks 这个二维数组来实现环形链表的。

我们在 bucket 的 Init 方法中会根据传入 maxBytes 桶字节数来设置 chunks 的长度大小，由于每个 chunk 大小都是 `64 * 1024`bytes，那么我们设置 `3 * 64 * 1024`bytes 大小的桶，那么 chunks 数组长度就为 3。

如果当前算出 chunkIdx 在 chunks 数组为 1 的位置，并且在 chunks[1] 的位置中，还剩下 6bytes 未被使用，那么有如下几种情况：

1.  现在假设放入的键值长度都是 1byte，那么在 chunks[1] 的位置中剩下的 6bytes 刚好可以放下；

![mycache3](https://img.luozhiyun.com/20210516203704.png)

2.  现在假设放入的键值长度超过了 1byte，那么在 chunks[1] 的位置中剩下的位置就放不下，只能放入到 chunks[2] 的位置中。

![mycache4](https://img.luozhiyun.com/20210516203710.png)

如果当前算出 chunkIdx 在 chunks 数组为 2 的位置，并且现在 Set 一个键值，经过计算 chunkIdxNew 为 3，已经超过了 chunks 数组长度，那么会将索引重置，重新将数据从 chunks[0] 开始放置，并将 gen 加一，表示已经跑完一圈了。

![mycache5](https://img.luozhiyun.com/20210516203717.png)

### Get

```go
func (c *Cache) Get(dst, k []byte) []byte {
   h := xxhash.Sum64(k)
   idx := h % bucketsCount
   dst, _ = c.buckets[idx].Get(dst, k, h, true)
   return dst
}
```

这里和 Set 方法是一样的，首先是要找到对应的桶的位置，然后才去桶里面拿数据。需要注意的是，这里的 dst 可以从外部传入一个切片，以达到减少重复分配返回值。

```go
func (b *bucket) Get(dst, k []byte, h uint64,returnDst bool) ([]byte, bool) {
    found := false
    b.mu.RLock()
    v := b.m[h]
    bGen := b.gen & ((1 << genSizeBits) - 1)
    if v > 0 {
        // 高于bucketSizeBits位置表示gen
        gen := v >> bucketSizeBits
        // 低于bucketSizeBits位置表示idx
        idx := v & ((1 << bucketSizeBits) - 1)
        // 这里说明chunks还没被写满
        if gen == bGen && idx < b.idx ||
            // 这里说明chunks已被写满，并且当前数据没有被覆盖
            gen+1 == bGen && idx >= b.idx ||
            // 这里是边界条件gen已是最大，并且chunks已被写满bGen从1开始，，并且当前数据没有被覆盖
            gen == maxGen && bGen == 1 && idx >= b.idx {
            chunkIdx := idx / chunkSize
            // chunk 索引位置不能超过 chunks 数组长度
            if chunkIdx >= uint64(len(b.chunks)) {
                goto end
            }
            // 找到数据所在的 chunk
            chunk := b.chunks[chunkIdx]
            // 通过取模找到该key 对应的数据在 chunk 中的位置
            idx %= chunkSize
            if idx+4 >= chunkSize {
                goto end
            }
            // 前 4bytes 是数据头
            kvLenBuf := chunk[idx : idx+4]
            // 通过数据头算出键值的长度
            keyLen := (uint64(kvLenBuf[0]) << 8) | uint64(kvLenBuf[1])
            valLen := (uint64(kvLenBuf[2]) << 8) | uint64(kvLenBuf[3])
            idx += 4
            if idx+keyLen+valLen >= chunkSize {
                goto end
            }
            // 如果键值是一致的，表示找到该数据
            if string(k) == string(chunk[idx:idx+keyLen]) {
                idx += keyLen
                // 返回该键对应的值
                if returnDst {
                    dst = append(dst, chunk[idx:idx+valLen]...)
                }
                found = true
            }
        }
    }
end:
    b.mu.RUnlock()
    return dst, found
}
```

Get 方法主要是考虑环形链表的边界问题。我们在 Set 方法中会将每一个 key 对应的 gen 和 idx 索引存放到 m 字典中，所以我们通过 hash 获取 m 字典的值之后通过位运算就可以获取到 gen 和 idx 索引。

找到 gen 和 idx 索引之后就是边界条件的判断了，用一个 if 条件来进行判断：

```
gen == bGen && idx < b.idx
```

这里是判断如果是在环形链表的同一次循环中，那么 key 对应的索引应该小于当前桶的索引；

```
gen+1 == bGen && idx >= b.idx
```

这里表示当前桶已经进入到下一个循环中，所以需要判断 key 对应的索引是不是大于当前索引，以表示当前 key 对应的值没有被覆盖；

```
gen == maxGen && bGen == 1 && idx >= b.idx
```

因为 gen 和 idx 索引要塞到 uint64 类型的字段中，所以留给 gen 的最大值只有 `maxGen = 1<< 24 -1`，超过了 maxGen 会让 gen 从1开始。所以这里如果 key 对应 gen 等于 maxGen ，那么当前的 bGen 应该等于1，并且 key 对应的索引还应该大于当前 idx，这样才这个键值对才不会被覆盖。

判断完边界条件之后就会找到对应的 chunk ，然后取模后找到数据位置，通过偏移量找到并取出值。

![mycache6](https://img.luozhiyun.com/20210516203722.png)

### Benchmark

下面我上一下过后的 Benchmark：

> 代码位置： [https://github.com/devYun/mycache/blob/main/cache_timing_test.go](https://github.com/devYun/mycache/blob/main/cache_timing_test.go)

```
GOMAXPROCS=4 go test -bench='Set|Get' -benchtime=10s
goos: linux
goarch: amd64
pkg: gotest
// GoCache
BenchmarkGoCacheSet-4                836          14595822 ns/op           4.49 MB/s     2167340 B/op    65576 allocs/op
BenchmarkGoCacheGet-4               3093           3619730 ns/op          18.11 MB/s        5194 B/op       23 allocs/op
BenchmarkGoCacheSetGet-4             236          54379268 ns/op           2.41 MB/s     2345868 B/op    65679 allocs/op
// BigCache
BenchmarkBigCacheSet-4              1393          12763995 ns/op           5.13 MB/s     6691115 B/op        8 allocs/op
BenchmarkBigCacheGet-4              2526           4342561 ns/op          15.09 MB/s      650870 B/op   131074 allocs/op
BenchmarkBigCacheSetGet-4           1063          11180201 ns/op          11.72 MB/s     4778699 B/op   131081 allocs/op 
// standard map
BenchmarkStdMapSet-4                1484           7299296 ns/op           8.98 MB/s      270603 B/op    65537 allocs/op
BenchmarkStdMapGet-4                4278           2480523 ns/op          26.42 MB/s        2998 B/op       15 allocs/op
BenchmarkStdMapSetGet-4              343          39367319 ns/op           3.33 MB/s      298764 B/op    65543 allocs/op
// sync.map
BenchmarkSyncMapSet-4                756          15951363 ns/op           4.11 MB/s     3420214 B/op   262320 allocs/op
BenchmarkSyncMapGet-4              11826           1010283 ns/op          64.87 MB/s        1075 B/op       33 allocs/op
BenchmarkSyncMapSetGet-4            1910           5507036 ns/op          23.80 MB/s     3412764 B/op   262213 allocs/op
PASS
ok      gotest  215.182s 
```

上面的测试是 GoCache、BigCache、Map、sync.Map 的情况。下面是本篇文章中所开发的缓存库的测试：

```
// myCachce
BenchmarkCacheSet-4                 4371           2723208 ns/op          24.07 MB/s        1306 B/op        2 allocs/op
BenchmarkCacheGet-4                 6003           1884611 ns/op          34.77 MB/s         951 B/op        1 allocs/op
BenchmarkCacheSetGet-4              2044           6611759 ns/op          19.82 MB/s        2797 B/op        5 allocs/op
```

可以看到内存分配是几乎就不存在，操作速度在上面的库中也是佼佼者的存在。

## 总结

在本文中根据其他缓存库，并分析了如果用 Map 作为缓存所存在的问题，然后引出存在这个问题的原因，并提出解决方案；在我们的缓存库中，第一是通过使用索引加内存块的方式来存放缓存数据，再来是通过 OS 系统调用来进行内存分配让我们的缓存数据块脱离了 GC 的控制，从而做到降低 GC 频率提高并发的目的。

其实不只是缓存库，在我们的项目中当遇到需要使用大量的带指针的数据结构并需要长时间保持引用的时候，也是需要注意这样做可能会引发 GC 问题，从而给系统带来隐患。


![](https://zhuanlan.zhihu.com/p/402841754)  
# 深入理解golang内存缓存利器-FreeCache

在低延迟，高并发的系统中，不可避免的会用到本地内存作为缓存，FreeCache 就是使用golang实现的本地缓存系统，良好的特性使得它目前用在我们的生产环境中。一直以来都对他的实现很感兴趣，这次通过分析源码的方式，学习一下。

## **项目地址及特性**

项目地址 [https://github.com/coocood/freecache](https://link.zhihu.com/?target=https%3A//github.com/coocood/freecache)

特性

-   存储数以亿计的条目
-   零 GC 开销
-   高并发线程安全访问
-   纯 Go 实现
-   支持键值过期
-   近似 LRU 的淘汰算法
-   严格限制内存使用
-   迭代器支持

## freecache与Golang Map对比

  github官网给出的数据来看，set操作的性能是Golang内置Map的两倍，get操作是Golang内置Map的1/2。不过这个测试数据是单线程基准测出来的，在高并发的情况下，对比单锁保护的内置Map来说，性能会快好几倍。

## **内部数据结构**

freecache 是如何做到 0 GC 和高并发、低延时的呢，先看一下他的主要结构

```go
const (
  segmentCount = 256
  segmentAndOpVal = 255
)


type Cache struct {
  locks    [segmentCount]sync.Mutex
  segments [segmentCount]segment
}


// 每个分片的数据结构
type segment struct {
  rb            RingBuf   // 环形数组
  segId         int     // hashVal & 255 后的id
  hitCount      int64
  missCount     int64
  entryCount    int64
  totalCount    int64      // 环形数组 ring buffer 中的数据的总条数
  totalTime     int64      // 用于计算 lru 
  totalEvacuate int64
  totalExpired  int64
  overwrites    int64
  // 环形数组可用容量，用于维护环形数组，保证写入新数据而不会覆盖旧数据
  vacuumLen     int64
  // entry 索引每个 slot 的长度的数组。当 slotId 冲突时，对应 slot 的值会+1
  slotLens      [256]int32
  // entry 索引每个 slot 的容量
  //只要有一个 slot 的长度等于 slotCap 时，就会触发扩容
  slotCap       int32
  // 存储 entry 索引的切片，按照 hash16 顺序排列，256个 slot 共用
  slotsData     []entryPtr
}

type RingBuf struct {
  begin int64   // 环形数据的起始位置
  end   int64   // 环形数据的结束位置
  data  []byte  // 存储所有的 entry，容量是固定值
  index int
}
```

光看结构好像不能一目了然，撸个数据结构图

![](https://pic2.zhimg.com/80/v2-d01976dc4c03651c41e1c1cdea42e359_720w.webp)

freecache 数据结构图

通过结构图，可以看出 freecache 是将缓存空间划分为 256 个 segment，每个 segment 都有相同都存储空间，并有一把锁。

每个 segment 包含 256 个索引槽，用来对 key 进行快速检索，通过 uint8(hashVal >> 8) 运算获取到 key 对应索引槽的 slotId。每个槽中又有 n 个索引，每个槽中的索引数量是统一的，由 slotCap 进行控制，当某个槽中的索引的数量大于 slotCap 时，就会触发整个索引的扩容。每个槽的索引数据是存储在 slotsData 这个索引切片中的，256 个槽共用同一个索引切片，每个槽在索引切片中都是按照 hash16 顺序排列的（如结构图显示，同一颜色的 solt 对应同一颜色的 ptr 切片）。根据 slotId 和 slotCap ，可以轻松定位到某个槽下所有的索引切片，提高 key 检索效率。

每个 segment 包含1个环形数组 RingBuf ，用来存储实际的数据。在 freecache 中，将每个 k/v 数据定义为一个 entry ，缓存中有多少个 key ，就有多少个 entry。

## **为什么可以高并发线程安全访问**

当对 key 进行 set、get、del 等操作时，freecache 使用 xxhash 这个 hash 方法，对 key 计算得到一个64位的 hashValue。通过 hashVal & 255 得到 segId，将 key 定位到具体的 segment，并对 segment 加锁。由于每次只对单个 segment 加锁，不同 segment 之间可以并发进行 key 操作。

```go
// 以 set 为例，get、del 等其他操作都是相似的
func (cache *Cache) Set(key, value []byte, expireSeconds int) (err error) {
  hashVal := hashFunc(key)
  segID := hashVal & segmentAndOpVal
  cache.locks[segID].Lock()
  err = cache.segments[segID].set(key, value, hashVal, expireSeconds)
  cache.locks[segID].Unlock()
  return
}
```

## **为什么是零 GC 的开销**

通过结构图和源码，可以看出 freecache 的底层只有 512 个指针(256 个 segment ，每个 segment 包含一个 slotsData 切片和一个 RingBuf)，所以 freecache 的对GC开销几乎为0。
## get操作的具体流程
可以通过一下get(key)操作，来了解freecahe的架构设计。

![freecache整体架构设计](https://img-blog.csdnimg.cn/2020090621042327.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)

-   freecache将缓存划分为256个segment，对于一个key的操作，freecache通过hash方法（xxhash）计算得到一个64位的hashValue，并取低8位作为segId，定位到具体的segment，并对segment加锁。由于只对segment加锁，不同segment之间可以并发进行key操作，所以freecache支持高并发线程安全访问。

```go
const (
	// segmentCount represents the number of segments within a freecache instance.
	segmentCount = 256
	// segmentAndOpVal is bitwise AND applied to the hashVal to find the segment id.
	segmentAndOpVal = 255
	......
)
// Cache is a freecache instance.
type Cache struct {
	locks    [segmentCount]sync.Mutex  // 每个segment都有自己的同步控制锁
	segments [segmentCount]segment     // 缓存划分为256个segment
}

// xxhash算法，算出64位哈希值
func hashFunc(data []byte) uint64 {
	return xxhash.Sum64(data)
}

......

// Get returns the value or not found error.
func (cache *Cache) Get(key []byte) (value []byte, err error) {
	// 1. 算出key的64位哈希值
	hashVal := hashFunc(key)
	// 2. 取低8位，得到segId
	segID := hashVal & segmentAndOpVal
	// 找到对应的segment，只对segment加锁
	// 同个segment的操作是串行进行，不同segment的操作是并行进行的
	cache.locks[segID].Lock()
	value, _, err = cache.segments[segID].get(key, nil, hashVal, false)
	cache.locks[segID].Unlock()
	return
}

......

```

-   segment底层实际上是由两个切片组成的复杂数据结构，其中一个切片用来实现环形缓冲区RingBuf，存储了所有的entry （**entry=24 byte header + key + value**）。另一个切片则是用于查找entry的索引切片slotData，slotData被逻辑上切分为256个slot，每个slot上的entry索引都是按照hash16有序排列的。可以看出，不管freecache缓存了多少数据，底层永远都只会有512个指针，所以freecache的对GC开销几乎为零。

```go
// segment.go文件

type segment struct {
	// 环形缓冲区RingBuf，由一个固定容量的切片实现
	rb            RingBuf
	segId         int
	_             uint32
	missCount     int64
	hitCount      int64
	entryCount    int64
	totalCount    int64
	totalTime     int64
	timer         Timer
	totalEvacuate int64
	totalExpired  int64
	overwrites    int64
	touched       int64
	vacuumLen     int64
	slotLens      [256]int32
	slotCap       int32 
    // entry索引切片，容量动态扩展
	slotsData     []entryPtr
}

// ringbuf.go文件

type RingBuf struct {
	begin int64
	end   int64
	// 存储了所有entry
	// 每个entry由三部分组成：24个字节的头部header、key、value
	data  []byte
	index int
}
```



## **set 操作的具体流程**

话不多说，先上图
这里我给出了set操作的代码流程图，主要的流程都已经画了出来，如果还想了解更多实现细节，可以结合源码进行理解。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200907174210378.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)  
  对于一个key的set操作，首先判断key是否存在，不存在的情况处理比较简单，直接追加到**环尾**；如果存在的话，则看一下原来为entry预留的value容量是否充足，充足的话，直接覆盖，否则删掉原来的entry，并将新的entry追加到环尾，新的entry会给value预留多一点空间。

![](https://pic4.zhimg.com/80/v2-72713d5ed6e1577fdaecaa39f8374b9f_720w.webp)

freecache set 流程图

freecache set 时，先查询当前 key 是否已存在，根据 segId 和 slotId 快速定位到 entry 所在的索引槽。由于索引槽中的索引都是按照 hash16 顺序排列的，可以用二分查找法检索（复杂度 O(log2n)）。

```go
/**
 * 判断 key 是否在索引切片中存在
*/
slotId := uint8(hashVal >> 8)
hash16 := uint16(hashVal >> 16)


// 根据 slotId 和 slotCap
// 从公用的 slotsData 切片中获取第 slotId 个槽所对应的索引切片
slot := seg.getSlot(slotId)
// 在槽对应的索引中，搜索 key 是否存在
idx, match := seg.lookup(slot, hash16, key)


func (seg *segment) getSlot(slotId uint8) []entryPtr {
  slotOff := int32(slotId) * seg.slotCap
  return seg.slotsData[slotOff : slotOff+seg.slotLens[slotId] : slotOff+seg.slotCap]
}


func (seg *segment) lookup(slot []entryPtr, hash16 uint16, key []byte) (idx int, match bool) {
  // 二分查找法获取到第一个符合条件的 hash16
  idx = entryPtrIdx(slot, hash16)
  for idx < len(slot) {
    ptr := &slot[idx]
    if ptr.hash16 != hash16 {
      break
    }
    // 相同的 hash16 ，需要到 RingBuf 比对 key 是否相同
    match = int(ptr.keyLen) == len(key) && seg.rb.EqualAt(key, ptr.offset+ENTRY_HDR_SIZE)
    if match {
      return
    }
    idx++
  }
  return
}


func entryPtrIdx(slot []entryPtr, hash16 uint16) (idx int) {
  high := len(slot)
  for idx < high {
    mid := (idx + high) >> 1
    oldEntry := &slot[mid]
    if oldEntry.hash16 < hash16 {
      idx = mid + 1
    } else {
      high = mid
    }
  }
  return
}


```

简单的画了个图，假设根据 slotId 和 slotCap 获取到 freecache 数据结构图中紫色的索引切片

  

![](https://pic1.zhimg.com/80/v2-a6594fcaddda4267f5205146be184bc4_720w.webp)

freecache 索引检索图

当 key 对应的索引存在时，需要查看 RingBuf 中， entry 以前的容量是多少。如果 entry 容量大于 set 的 value 长度，直接更新原来 entry 的头部和 value (复杂度O(1))。如果 entry 容量不充足的话，为了避免移动 RingBuf 数组的数据，不直接对原来的 entry 进行扩容，而是将原来的 entry 标记为删除（不直接删除，迁移数据，只标记，当 RingBuf 空间不够需要淘汰数据的时候会真正删除），然后在 RingBuf 的环尾追加新的 entry(复杂度O(1)，新 entry 容量如下)。

```go
// 每次扩容原空间的两倍，直到满足插入 value 的空间为止
for hdr.valCap < hdr.valLen {
  hdr.valCap *= 2
}
```

当 key 对应的索引不存在时，要先将索引添加到索引切片中，由于索引是有序的，在插入索引时，可能会对老的索引数据进行迁移(复杂度O(n))，如果索引切片容量不够，还会触发索引切片扩容。索引添加成功后，再将 entry 追加到 RingBuf 的环尾(复杂度O(1))。

```go
/**
 * 将索引插入到索引切片
*/
func (seg *segment) insertEntryPtr(
  slotId uint8, hash16 uint16, offset int64, idx int, keyLen uint16,
) {
  // 只要有一个索引槽的容量大于 slotCap
  // 就会对整个索引切片进行扩容
  // 扩容后容量是扩容前的两倍
  if seg.slotLens[slotId] == seg.slotCap {
    seg.expand()
  }
  seg.slotLens[slotId]++
  atomic.AddInt64(&seg.entryCount, 1)
  slot := seg.getSlot(slotId)
  copy(slot[idx+1:], slot[idx:])
  slot[idx].offset = offset
  slot[idx].hash16 = hash16
  slot[idx].keyLen = keyLen
}


func (seg *segment) expand() {
  newSlotData := make([]entryPtr, seg.slotCap*2*256)
  for i := 0; i < 256; i++ {
    off := int32(i) * seg.slotCap
    copy(newSlotData[off*2:], seg.slotsData[off:off+seg.slotLens[i]])
  }
  seg.slotCap *= 2
  seg.slotsData = newSlotData
}
```

以 freecache 数据结构图中紫色的索引切片为例，当插入索引，不需要扩容时

  

![](https://pic3.zhimg.com/80/v2-ff8a5b78056299e17ed583bf3cb2732e_720w.webp)

freecache 索引插入不需要扩容图

以 freecache 数据结构图中黄色的索引切片为例当插入索引，需要扩容时

  

![](https://pic1.zhimg.com/80/v2-3b20098973265fa04e81b6d6e3b28234_720w.webp)

freecache 索引插入扩容前图

  

![](https://pic4.zhimg.com/80/v2-256e1a4c766bdd60a909bcc7888ae7b3_720w.webp)

freecache 索引插入扩容后图

如果将 entry 追加到 RingBuf 的环尾时，RingBuf 容量不够时，freecache 会根据策略淘汰数据，释放出容量。
## set操作为什么高效

-   采用二分查找，极大的减少查找entry索引的时间开销。slot切片上的entry索引是根据hash16值有序排列的，对于有序集合，可以采用二分查找算法进行搜索，假设缓存了n个key，那么查找entry索引的时间复杂度为log2(n * 2^-16) = log2(n) - 16。
-   对于key不存在的情况下（找不到entry索引）。
    -   如果Ringbuf容量充足，则直接将entry追加到环尾，时间复杂度为O(1)。
    -   如果RingBuf不充足，需要将一些key移除掉，情况会复杂点，后面会单独讲解这块逻辑，不过freecache通过一定的措施，保证了移除数据的时间复杂度为O(1)，所以对于RingBuf不充足时，entry追加操作的时间复杂度也是O(1)。
-   对于已经存在的key（找到entry索引）。
    -   如果原来给entry的value预留的容量充足的话，则直接更新原来entry的头部和value，时间复杂度为O(1)。
    -   如果原来给entry的value预留的容量不足的话，freecache为了避免移动底层数组数据，不直接对原来的entry进行扩容，而是将原来的entry标记为删除（懒删除），然后在环形缓冲区RingBuf的**环尾**追加新的entry，时间复杂度为O(1)。


## **近似 LRU 的淘汰流程**

  前面介绍可以发现，freecache追加新entry时候，如果RingBuf的可用容量不足时，会从环头开始，通过近乎LRU的置换算法，将旧数据删掉，空出足够的空间出来，具体流程如一下流程图所示：  
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200908203131484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)  
  这部分流程可以在segment的evacuate方法找到，这里我们主要关注这一段代码`leastRecentUsed := int64(oldHdr.accessTime)*atomic.LoadInt64(&seg.totalCount) <= atomic.LoadInt64(&seg.totalTime)`

![](https://pic1.zhimg.com/80/v2-99ca0b923ed280278440064dde253588_720w.webp)

freecache lru 图

为什么是近似 LRU 的淘汰呢，先看下源码

```go
func (seg *segment) evacuate(entryLen int64, slotId uint8, now uint32) (slotModified bool) {
	
	......
	
	// RingBuf容量不足的情况
	for seg.vacuumLen < entryLen {
		
		......
		
		// entry是否过期
		expired := oldHdr.expireAt != 0 && oldHdr.expireAt < now
		// LRU entry最近使用情况
		leastRecentUsed := int64(oldHdr.accessTime)*atomic.LoadInt64(&seg.totalCount) <= atomic.LoadInt64(&seg.totalTime)
		if expired || leastRecentUsed || consecutiveEvacuate > 5 {
			
			// entry如果已经过期了，或者满足置换条件，则删除掉entry
			......
			
		} else {
			// 如果不满足置换条件，则将entry从环头调换到环尾
			newOff := seg.rb.Evacuate(oldOff, int(oldEntryLen))
			// 更新entry的索引
			seg.updateEntryPtr(oldHdr.slotId, oldHdr.hash16, oldOff, newOff)
			......
		}
	}
	return
}
```

将上边等式变换一下

```go
//oldHdr.accessTime: RingBuf 中第一个 entry 数据最近一次访问的时间戳
//seg.totalCount: RingBuf 中 entry 的总数，包括过期和标记删除的 entry
//seg.totalTime: RingBuf 中每个 entry 最近一次访问的时间戳总和


leastRecentUsed := int64(oldHdr.accessTime) <= atomic.LoadInt64(&seg.totalTime)/atomic.LoadInt64(&seg.totalCount)
```

`atomic.LoadInt64(&seg.totalTime)/atomic.LoadInt64(&seg.totalCount)` 表示 RingBuf 所有 entry 最近一次访问时间戳的平均值。 freecach 认为当某个 entry 的 accessTime 小于等于这个平均值，则该 entry 是可以被淘汰的。

freecache 选择将 accessTime 小于等于平均 accessTime 的 entry 淘汰，不是严格意义上的 LRU 算法，但是确实会将最近较少使用的 entry 淘汰掉，所以是一种近 LRU 的算法。 当然，此算法也有可能会将较新的 entry 数据淘汰掉。当 RingBuf 头部数据都比较新，并且没有过期时，会导致一直找不到符合条件的 entry 进行淘汰，这样就无法空出足够的空间让新数据写入，程序会无限循环的将数据从头部迁移到尾部导致 cpu 被耗尽。

为了防止这样的意外发生，也为了保证 set 操作的性能，当连续第6次 RingBuf 的第一个 entry 还不符合淘汰条件时，该 entry 会被强制淘汰。

```go

......

 // entry header struct in ring buffer, followed by key and value.
 // entry头部信息，24个字节的开销
type entryHdr struct {
	accessTime uint32 // entry最近一次访问的时间戳
	expireAt   uint32 // entry过期时间点
	keyLen     uint16 // key的长度
	hash16     uint16 // entry的hash16值
	valLen     uint32 // value长度
	valCap     uint32 // entry为value预留的容量，valLen <= valCap 
	deleted    bool   // entry删除标记
	slotId     uint8  // entry索引所在slot的id
	reserved   uint16 // 预留字段，2个字节
}

......

// a segment contains 256 slots, a slot is an array of entry pointers ordered by hash16 value
// the entry can be looked up by hash value of the key.
type segment struct {
	......
	totalCount    int64      // number of entries in ring buffer, including deleted entries.
	totalTime     int64      // used to calculate least recent used entry.
	......
}
```

  所以`atomic.LoadInt64(&seg.totalTime)/atomic.LoadInt64(&seg.totalCount)`表示RingBuf中的entry最近一次访问时间戳的平均值，当一个entry的accessTime小于等于这个平均值，则认为这个entry是可以被置换掉的。这里我简单的总结一下freecache的entry置换算法：

-   最理性的情况下，即消息不过期、没有消息被标记删除、key被set进去之后，就没有再被访问过，在这种情况下，确实可以完全满足LRU算法，不过这种情况是不会发生的。
-   freecache选择将accessTime小于等于平均accessTime的entry进行置换，从大局来看，确实是将**最近较少**使用的缓存置换出去，从某种程度来将，是一种近LRU的置换算法。
-   freecache为什么不完全实现LRU置换算法呢？如果采用hash表+数组来实现LRU算法，维护hash表所带来的空间开销先不说，找出来的entry在环中的位置还是随机的，这种随机置换会产生空间碎片，如果要解决碎片问题性能将会大打折扣。如果不采用hash表来实现，则需要遍历所有entry索引，而且同样也会产生空间碎片。
-   在特殊情况下，环头的数据都比较新时，会导致一直找不到合适的entry进行置换，空出足够的空间，为了不影响set操作的性能，当连续5次出现环头entry不符合置换条件时，第6次置换如果entry还是不满足置换条件，也会被强制置换出去。


## **key 过期后缓存数据的清除策略**

freecache 不会主动清除过期的数据(包括索引和 entry 数据)。当数据过期后，在被标记删除之前，key 被重新 set 进来，如果 entry 的容量充足，是可以进行复用的。当数据过期后，当 get/touch 操作或 LRU 的时候，会将 key 对应的索引删除，entry 不会被直接删除，只会被标记为删除状态，等到 LRU 的时候，才会将 entry 删除，为 RingBuf 腾出空间。
![[Pasted image 20230414170535.png]]


## BingBuf追加entry的例子讲解

  假设某一时刻RingBuf的初始状态如下所示：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200910095734682.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)

  下一个时刻，set了一个新的key，经过判断，需要追加一个新的entry6 (1599652990)，大小为300B，由于RingBuf的容量还是充足，直接追加到环尾就行了，如下图所示:

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020091010002412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)

  接着又来了一个新的key，经过判断，需要追加一个新的entry7 (1599652991)，大小为400B，这次RingBuf的容量不足了，需要置换环头的旧数据，空出足够的空间，置换过程如下：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200910100659329.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)

## 2.3 过期与删除实现

### 2.3.1 key过期

-   对于过期的数据，freecache会让它继续存储在RingBuf中，RingBuf从一开始初始化之后，就固定不变了，是否删掉数据，对RingBuf的实际占用空间不会产生影响。
-   当get到一个过期缓存时，freecache会删掉缓存的entry索引（但是不会将缓存从RingBuf中移除），然后对外报`ErrNotFound`错误。
-   当RingBuf的容量不足时，会从环头开始遍历，如果key已经过期，这时才会将它删除掉。
-   如果一个key已经过期时，在它被freecache删除之前，如果又重新set进来（过期不会主动删除entry索引，理论上有被重新set的可能），过期的entry容量充足的情况下，则会重新复用这个entry。
-   freecache这种过期机制，一方面减少了维护过期数据的工作，另一方面，freecache底层存储是采用数组来实现，要求缓存数据必须连续，缓存过期的剔除会带来空间碎片，挪动数组来维持缓存数据的连续性不是一个很好的选择。

### 2.3.2 key删除

-   freecache有一下两种情况会进行删除key操作：
    -   外部主动调用del接口删除key。
    -   set缓存时，发现key已经存在，但是为entry预留的cap不足时，会选择将旧的数据删掉，然后再环尾追加新的数据。
-   freecache的删除机制也是懒删除，删除缓存时，只会删掉entry索引，但是缓存还是会继续保留在RingBuf中，只是被标记为删除，等到RingBuf容量不足需要置换缓存时，才会对标记为删除的缓存数据做最后的删除工作。
-   freecache删除一个key，需要搜索entry索引和标记缓存数据，搜索entry索引的时间复杂度前面已经分析过了，为O(log2(n) - 16)，而标记缓存数据的时间复杂度为O(1)，所以删除操作性能上还是挺不错的。

## 2.4 entry索引

### 2.4.1 前提说明

  256个slot底层其实是共用同一个entry索引切片seg.slotsData，下面的所有图文描述的数组下标值，都是站在整个entry索引切片seg.slotsData看的，描述的结果可能会和freecache源码计算得到的结果不一致，不过不影响我们理解entry索引相关操作的原理。如果要和代码实际计算的值对应上，在entry索引切片没有扩容之前，可以减掉1024就是代码里slot的下标值；在扩容之后，减掉2048就是代码里slot的下标位置。

### 2.4.2 entry索引二分查找实现

#### 2.4.2.1 源码分析

  entry索引二分查找实现最关键的源码为以下这两个函数，请参考注解给出的源码分析。

```go
// 二分查找实现，找到第一个entryPtr.hash16 >= hash16的entry索引下标
func entryPtrIdx(slot []entryPtr, hash16 uint16) (idx int) {
	high := len(slot)
	for idx < high {
		mid := (idx + high) >> 1
		oldEntry := &slot[mid]
		if oldEntry.hash16 < hash16 {
			idx = mid + 1
		} else {
			high = mid
		}
	}
	return
}

// slot的entryPtr按照hash16从小到大排序，存在哈希冲突，可能会存在多个hash16值一样的entryPtr。
// 查询算法大致如下：
// 1. 调用entryPtrIdx()找到第一个entryPtr.hash16 >= hash16的索引下标（二分查找）：idx。
// 2. 存在哈希冲突，可能会存在多个hash16值一样的entryPtr，需要判断是否命中key的entry索引：
//    2.1 如果slot[idx].hash16 != hash16，找不到key的entry索引，查询结束，返回idx和false；
//        否则继续往下执行。
//    2.2 如果slot[idx].keyLen != len(key)， 哈希冲突，slot[idx]不是key的entry索引，idx++，
//        重新返回到2.1；否则继续往下执行。
//    2.3 读取slot[idx]索引所指entry的key值，如果不等于我们要找的key，出现哈希冲突，slot[idx]
//        不是key的entry索引，idx++，重新返回到2.1；否则说明找到了索引，返回idx和true。
func (seg *segment) lookup(slot []entryPtr, hash16 uint16, key []byte) (idx int, match bool) {
	idx = entryPtrIdx(slot, hash16)
	for idx < len(slot) {
		ptr := &slot[idx]
		if ptr.hash16 != hash16 {
			break
		}
		match = int(ptr.keyLen) == len(key) && seg.rb.EqualAt(key, ptr.offset+ENTRY_HDR_SIZE)
		if match {
			return
		}
		idx++
	}
	return
}
```

#### 2.4.2.1 图文分析

  假设某一时刻entry索引切片seg.slotsData的状态如下：

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020091015281691.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)  
  如果我们要找key(2, 1, “b”)，带入源码，其查询过程如下所示，最终将返回1025和true。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200910174129533.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)  
  如果我们要找的key(2, s, “bb”)呢？16位的hash16允许哈希冲突的存在，查找key(2, s, “bb”)的索引过程，除了hash16要对上，所指向entry的key长度和值也都要一样。最终可以看到，其实找不到key(2, s, “bb”)的索引，如下所示，最终将返回1026和false。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200910181344180.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)

### 2.4.3 插入新的entry索引

  freecache每set一个新的key，都会创建对应的entry索引，并添加到索引切片相应的slot上。前面已经介绍过set操作的流程，假设我们要set一个key(3, 2, “cc”)，会调用`lookup`方法判断这个key(3, 2, “cc”)是否已经存在了，查找key(3, 2, “cc”)索引的过程如下图所示，最终`lookup`将会返回1029和false。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200910182448124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)  
  根据前面的介绍，由于key(3, 2, “cc”)不存在entry索引，说明这个key不存在，可以直接追加新的entry到环尾，并在slot上插入对应的entry索引。  
  我们知道slot上的entry索引都是按照hash16值有序排列的，那么要在那个位置进行插入呢？如何插入呢？  
  如果仔细观察查找key(3, 2 “cc”)的索引的过程，可以发现，当`lookup`返回true时，返回的下标是key(3, 2 “cc”)的entry索引在slot中的位置；当`lookup`返回false时，返回的下标是第一个hash16值大于key(3, 2 “cc”)的hash16值的entry索引下标，这个下标值正是新的entry索引要插入的位置。  
  要插入的位置找到了，那如何插入呢？为了保证slot上entry索引按照hash16值有序排列，freecache在插入新的entry索引之前，会将插入位置及之后的数据向后移动一个位置，让再将新的entry索引插入到对应的位置。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200910213853783.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoaXpoZW5saWFu,size_16,color_FFFFFF,t_70#pic_center)

### 2.4.3 entry索引切片的自动扩容机制

  接着上面，假设又set了一个新的key(3, 2, “cd”)，经过二分查找搜索，发现是一个新的key(3, 2, “cd”)，追加对应的entry到RingBuf之后，需要插入新的entry索引，插入位置为1030。  
  这时，不能简单的将1030及之后的索引往后挪动一个位置，要知道，256个slot都是共用一个索引切片的seg.slotsData的，当slot满了时，如果直接往后挪动一个位置，会覆盖掉下一个slot的数据，导致数据错乱。  
  对此，当slot容量满时，freecache会进行扩容，只不过是整个索引切片的容量扩到原来的两倍，然后将每个slot上的数据挪动新的位置，之后在重新将新的entry索引插入进去。

```go
func (seg *segment) insertEntryPtr(slotId uint8, hash16 uint16, offset int64, idx int, keyLen uint16) {
	// slot满了时，整个entry索引切片进行扩容
	if seg.slotLens[slotId] == seg.slotCap {
		seg.expand()
	}
	// 添加新的entry索引
	seg.slotLens[slotId]++
	atomic.AddInt64(&seg.entryCount, 1)
	slot := seg.getSlot(slotId)
	// slot上，idx当前位置的entry索引及之后的所有entry索引都往后挪动一个位置
	copy(slot[idx+1:], slot[idx:])
	// 插入新的entry索引
	slot[idx].offset = offset
	slot[idx].hash16 = hash16
	slot[idx].keyLen = keyLen
}


func (seg *segment) expand() {
	newSlotData := make([]entryPtr, seg.slotCap*2*256)
	for i := 0; i < 256; i++ {
		off := int32(i) * seg.slotCap
		copy(newSlotData[off*2:], seg.slotsData[off:off+seg.slotLens[i]])
	}
	seg.slotCap *= 2
	seg.slotsData = newSlotData
}
```

# 3. 总结

## 3.1 freecache的不足

-   需要一次性申请所有缓存空间。用于实现segment的RingBuf切片，从缓存被创建之后，其容量就是固定不变的，申请的内存也会一直被占用着，空间换时间，确实避免不了。
-   freecache的entry置换算法不是完全LRU，而且在某些情况下，可能会把最近经常被访问的缓存置换出去。
-   entry索引切片slotsData无法一次性申请足够的容量，当slotsData容量不足时，会进行空间容量x2的扩容，这种自动扩容机制，会带来一定的性能开销。
-   由于entry过期时，不会主动清理缓存数据，这些过期缓存的entry索引还会继续保存slot切片中，这种机制会加快entry索引切片提前进行扩容，而实际上除掉这些过期缓存的entry索引，entry索引切片的容量可能还是完全充足的。
-   为了保证LRU置换能够正常进行，freecache要求entry的大小不能超过缓存大小的1/1024，而且这个限制还不给动态修改，具体可以参考github上的[issues](https://github.com/coocood/freecache/issues/28)。

## 3.2 使用freecache的注意事项

-   缓存的数据如果可以的话，大小尽量均匀一点，可以减少RingBuf容量不足时的置换工作开销。
-   缓存的数据不易过大，这样子才能缓存更多的key，提高缓存命中率。

# 顺便贴一下热点检测算法的代码实现
```go
https://github.com/go-kratos/aegis

package topk  
const LOOKUP_TABLE = 256  
  
// Topk implement by heavykeeper algorithm.
type HeavyKeeper struct {  
   k           uint32  
   width       uint32  
   depth       uint32  
   decay       float64  
   lookupTable []float64  
   minCount    uint32  
  
   r        *rand.Rand  
   buckets  [][]bucket  
   minHeap  *minheap.Heap  
   expelled chan Item  
   total    uint64  
}  
  
func NewHeavyKeeper(k, width, depth uint32, decay float64, min uint32) Topk {  
   arrays := make([][]bucket, depth)  
   for i := range arrays {  
      arrays[i] = make([]bucket, width)  
   }  
  
   topk := &HeavyKeeper{  
      k:           k,  
      width:       width,  
      depth:       depth,  
      decay:       decay,  
      lookupTable: make([]float64, LOOKUP_TABLE),  
      buckets:     arrays,  
      r:           rand.New(rand.NewSource(0)),  
      minHeap:     minheap.NewHeap(k),  
      expelled:    make(chan Item, 32),  
      minCount:    min,  
   }  
   for i := 0; i < LOOKUP_TABLE; i++ {  
      topk.lookupTable[i] = math.Pow(decay, float64(i))  
   }  
   return topk  
}  
  
func (topk *HeavyKeeper) Expelled() <-chan Item {  
   return topk.expelled  
}  
  
func (topk *HeavyKeeper) List() []Item {  
   items := topk.minHeap.Sorted()  
   res := make([]Item, 0, len(items))  
   for _, item := range items {  
      res = append(res, Item{Key: item.Key, Count: item.Count})  
   }  
   return res  
}  
  
// Add add item into heavykeeper and return if item had beend add into minheap.// if item had been add into minheap and some item was expelled, return the expelled item.  
// 将Add项添加到heavykeeper中，如果已将项添加到minheap中则返回。  
// 如果项已添加到minheap中，并且某个项已被驱逐，则返回被驱逐的项。  
func (topk *HeavyKeeper) Add(key string, incr uint32) (string, bool) {  
   keyBytes := []byte(key)  
   itemFingerprint := murmur3.Sum32(keyBytes)  
   var maxCount uint32  
  
   // compute d hashes  
   for i, row := range topk.buckets {  
  
      bucketNumber := murmur3.SeedSum32(uint32(i), keyBytes) % uint32(topk.width)  
      fingerprint := row[bucketNumber].fingerprint  
      count := row[bucketNumber].count  
  
      if count == 0 {  
         row[bucketNumber].fingerprint = itemFingerprint  
         row[bucketNumber].count = incr  
         maxCount = max(maxCount, incr)  
  
      } else if fingerprint == itemFingerprint {  
         row[bucketNumber].count += incr  
         maxCount = max(maxCount, row[bucketNumber].count)  
  
      } else {  
         for localIncr := incr; localIncr > 0; localIncr-- {  
            var decay float64  
            curCount := row[bucketNumber].count  
            if row[bucketNumber].count < LOOKUP_TABLE {  
               decay = topk.lookupTable[curCount]  
            } else {  
               // decr pow caculate cost  
               decay = topk.lookupTable[LOOKUP_TABLE-1]  
            }  
            if topk.r.Float64() < decay {  
               row[bucketNumber].count--  
               if row[bucketNumber].count == 0 {  
                  row[bucketNumber].fingerprint = itemFingerprint  
                  row[bucketNumber].count = localIncr  
                  maxCount = max(maxCount, localIncr)  
                  break  
               }  
            }  
         }  
      }  
   }  
   topk.total += uint64(incr)  
   if maxCount < topk.minCount {  
      return "", false  
   }  
   minHeap := topk.minHeap.Min()  
   if len(topk.minHeap.Nodes) == int(topk.k) && maxCount < minHeap {  
      return "", false  
   }  
   // update minheap  
   itemHeapIdx, itemHeapExist := topk.minHeap.Find(key)  
   if itemHeapExist {  
      topk.minHeap.Fix(itemHeapIdx, maxCount)  
      return "", true  
   }  
   var exp string  
   expelled := topk.minHeap.Add(&minheap.Node{Key: key, Count: maxCount})  
   if expelled != nil {  
      topk.expell(Item{Key: expelled.Key, Count: expelled.Count})  
      exp = expelled.Key  
   }  
  
   return exp, true  
}  
  
func (topk *HeavyKeeper) expell(item Item) {  
   select {  
   case topk.expelled <- item:  
   default:  
   }  
}  
  
type bucket struct {  
   fingerprint uint32  
   count       uint32  
}  
  
func (b *bucket) Get() (uint32, uint32) {  
   return b.fingerprint, b.count  
}  
  
func (b *bucket) Set(fingerprint, count uint32) {  
   b.fingerprint = fingerprint  
   b.count = count  
}  
  
func (b *bucket) Inc(val uint32) uint32 {  
   b.count += val  
   return b.count  
}  
  
func max(x, y uint32) uint32 {  
   if x > y {  
      return x  
   }  
   return y  
}  
  
func (topk *HeavyKeeper) Fading() {  
   for _, row := range topk.buckets {  
      for i := range row {  
         row[i].count = row[i].count >> 1  
      }  
   }  
   for i := 0; i < len(topk.minHeap.Nodes); i++ {  
      topk.minHeap.Nodes[i].Count = topk.minHeap.Nodes[i].Count >> 1  
   }  
   topk.total = topk.total >> 1  
}  
  
func (topk *HeavyKeeper) Total() uint64 {  
   return topk.total  
}
```


# Reference
https://www.luozhiyun.com/archives/531
https://zhuanlan.zhihu.com/p/402841754
https://juejin.cn/post/7101994349252050980#heading-46
https://blog.csdn.net/chizhenlian/article/details/108435024