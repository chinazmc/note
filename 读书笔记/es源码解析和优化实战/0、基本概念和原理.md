#es

# 基本概念和原理
Elasticsearch是实时的分布式搜索分析引擎，内部使用Lucene做索引与搜索。何谓实时？新增到 ES 中的数据在1秒后就可以被检索到，这种新增数据对搜索的可见性称为“准实时搜索”。分布式意味着可以动态调整集群规模，弹性扩容，而这一切操作起来都非常简便，用户甚至不必了解集群原理就可以实现。按官方的描述，集群规模支持“上百”个节点，相比HDFS等上千台的集群，这个规模“小了点”。影响集群规模上限的原因将在后续的章节中分析。因此，目前我们认为ES适合中等数据量的业务，不适合存储海量数据。

Lucene是Java语言编写的全文搜索框架，用于处理纯文本的数据，但它只是一个库，提供建立索引、执行搜索等接口，但不包含分布式服务，这些正是 ES 做的。什么是全文？对全部的文本内容进行分析，建立索引，使之可以被搜索，因此称为全文。
基于ES，你可以很容易地搭建自己的搜索引擎，用于分析日志，或者配合开源爬虫建立某个垂直领域的搜索引擎。ES 易用的产品设计使得它很容易上手。除了搜索，ES 还提供了大量的聚合功能，所以它不单单是一个搜索引擎，还可以进行数据分析、统计，生成指标数据。而这些功能都在快速迭代，目前每2周左右就会发布新版本。

## 分片
在分布式系统中，单机无法存储规模巨大的数据，要依靠大规模集群处理和存储这些数据，一般通过增加机器数量来提高系统水平扩展能力。因此，需要将数据分成若干小块分配到各个机器上。然后通过某种路由策略找到某个数据块所在的位置。
`除了将数据分片以提高水平扩展能力，分布式存储中还会把数据复制成多个副本，放置到不同的机器中，这样一来可以增加系统可用性，同时数据副本还可以使读操作并发执行，分担集群压力。但是多数据副本也带来了一致性的问题：部分副本写成功，部分副本写失败。我们随后讨论。`
为了应对并发更新问题，ES将数据副本分为主从两部分，即主分片（primary shard）和副分片（replica shard）。主数据作为权威数据，写过程中先写主分片，成功后再写副分片，恢复阶段以主分片为准。
数据分片和数据副本的关系如下图所示。
![[Pasted image 20220301220125.png]]
分片（shard）是底层的基本读写单元，分片的目的是分割巨大索引，让读写可以并行操作，由多台机器共同完成。读写请求最终落到某个分片上，分片可以独立执行读写工作。ES利用分片将数据分发到集群内各处。分片是数据的容器，文档保存在分片内，不会跨分片存储。分片又被分配到集群内的各个节点里。当集群规模扩大或缩小时，ES会自动在各节点中迁移分片，使数据仍然均匀分布在集群里。
索引与分片的关系如下图所示
![[Pasted image 20220301220344.png]]
`一个ES索引包含很多分片，一个分片是一个Lucene的索引，它本身就是一个完整的搜索引擎，可以独立执行建立索引和搜索任务。Lucene索引又由很多分段组成，每个分段都是一个倒排索引。ES每次“refresh”都会生成一个新的分段，其中包含若干文档的数据。在每个分段内部，文档的不同字段被单独建立索引。每个字段的值由若干词（Term）组成，Term是原文本内容经过分词器处理和语言处理后的最终结果（例如，去除标点符号和转换为词根）。`
索引建立的时候就需要确定好主分片数，在较老的版本中（5.x 版本之前），主分片数量不可以修改，副分片数可以随时修改。现在（5.x～6.x 版本之后）,ES 已经支持在一定条件的限制下，对某个索引的主分片进行拆分（Split）或缩小（Shrink）。但是，我们仍然需要在一开始就尽量规划好主分片数量：先依据硬件情况定好单个分片容量，然后依据业务场景预估数据量和增长量，再除以单个分片容量。分片数不够时，可以考虑新建索引，搜索1个有着50个分片的索引与搜索50个每个都有1个分片的索引完全等价，或者使用_split API来拆分索引（6.1版本开始支持）。

在实际应用中，我们不应该向单个索引持续写数据，直到它的分片巨大无比。巨大的索引会在数据老化后难以删除，以_id 为单位删除文档不会立刻释放空间，删除的 doc 只在 Lucene分段合并时才会真正从磁盘中删除。即使手工触发分段合并，仍然会引起较高的 I/O 压力，并且可能因为分段巨大导致在合并过程中磁盘空间不足（分段大小大于磁盘可用空间的一半）。因此，我们建议周期性地创建新索引。例如，每天创建一个。假如有一个索引website，可以将它命名为website_20180319。然后创建一个名为website的索引别名来关联这些索引。这样，对于业务方来说，读取时使用的名称不变，当需要删除数据的时候，可以直接删除整个索引。索引别名就像一个快捷方式或软链接，不同的是它可以指向一个或多个索引。可以用于实现索引分组，或者索引间的无缝切换。
`现在我们已经确定好了主分片数量，并且保证单个索引的数据量不会太大，周期性创建新索引带来的一个新问题是集群整体分片数量较多，集群管理的总分片数越多压力就越大。在每天生成一个新索引的场景中，可能某天产生的数据量很小，实际上不需要这么多分片，甚至一个就够。这时，可以使用_shrink API来缩减主分片数量，降低集群负载。`

## 动态更新索引
为文档建立索引，使其每个字段都可以被搜索，通过关键词检索文档内容，会使用倒排索引的数据结构。倒排索引一旦被写入文件后就具有不变性，不变性具有许多好处：对文件的访问不需要加锁，读取索引时可以被文件系统缓存等。那么索引如何更新，让新添加的文档可以被搜索到？答案是使用更多的索引，新增内容并写到一个新的倒排索引中，查询时，每个倒排索引都被轮流查询，查询完再对结果进行合并。每次内存缓冲的数据被写入文件时，会产生一个新的Lucene段，每个段都是一个倒排索引。在一个记录元信息的文件中描述了当前Lucene索引都含有哪些分段。由于分段的不变性，更新、删除等操作实际上是将数据标记为删除，记录到单独的位置，这种方式称为标记删除。因此删除部分数据不会释放磁盘空间。

## 近实时搜索
在写操作中，一般会先在内存中缓冲一段数据，再将这些数据写入硬盘，每次写入硬盘的这批数据称为一个分段，如同任何写操作一样。一般情况下（direct方式除外），通过操作系统write接口写到磁盘的数据先到达系统缓存（内存）,write函数返回成功时，数据未必被刷到磁盘。通过手工调用flush，或者操作系统通过一定策略将系统缓存刷到磁盘。这种策略大幅提升了写入效率。从write函数返回成功开始，无论数据有没有被刷到磁盘，该数据已经对读取可见。ES正是利用这种特性实现了近实时搜索。每秒产生一个新分段，新段先写入文件系统缓存，但稍后再执行flush刷盘操作，写操作很快会执行完，一旦写成功，就可以像其他文件一样被打开和读取了。由于系统先缓冲一段数据才写，且新段不会立即刷入磁盘，这两个过程中如果出现某些意外情况（如主机断电），则会存在丢失数据的风险。通用的做法是记录事务日志，每次对ES进行操作时均记录事务日志，当ES启动的时候，重放translog中所有在最后一次提交后发生的变更操作。比如HBase等都有自己的事务日志。
## 段合并
在ES中，每秒清空一次写缓冲，将这些数据写入文件，这个过程称为refresh，每次refresh会创建一个新的Lucene 段。但是分段数量太多会带来较大的麻烦，每个段都会消耗文件句柄、内存。每个搜索请求都需要轮流检查每个段，查询完再对结果进行合并；所以段越多，搜索也就越慢。因此需要通过一定的策略将这些较小的段合并为大的段，常用的方案是选择大小相似的分段进行合并。在合并过程中，标记为删除的数据不会写入新分段，当合并过程结束，旧的分段数据被删除，标记删除的数据才从磁盘删除。HBase、Cassandra等系统都有类似的分段机制，写过程中先在内存缓冲一批数据，不时地将这些数据写入文件作为一个分段，分段具有不变性，再通过一些策略合并分段。分段合并过程中，新段的产生需要一定的磁盘空间，我们要保证系统有足够的剩余可用空间。Cassandra系统在段合并过程中的一个问题就是，当持续地向一个表中写入数据，如果段文件大小没有上限，当巨大的段达到磁盘空间的一半时，剩余空间不足以进行新的段合并过程。如果段文件设置一定上限不再合并，则对表中部分数据无法实现真正的物理删除。ES存在同样的问题。

# 集群内部原理
分布式系统的集群方式大致可以分为主从（Master-Slave）模式和无主模式。ES、HDFS、HBase使用主从模式，Cassandra使用无主模式。主从模式可以简化系统设计，Master作为权威节点，部分操作仅由Master执行，并负责维护集群元信息。缺点是Master节点存在单点故障，需要解决灾备问题，并且集群规模会受限于Master节点的管理能力。因此，从集群节点角色的角度划分，至少存在主节点和数据节点，另外还有协调节点、预处理节点和部落节点，下面分别介绍各种类型节点的职能。
## 集群节点角色
### 1． 主节点（Master node）
主节点负责集群层面的相关操作，管理集群变更。通过配置 node.master: true（默认）使节点具有被选举为Master 的资格。主节点是全局唯一的，将从有资格成为Master的节点中进行选举。

主节点也可以作为数据节点，但尽可能做少量的工作，因此生产环境应尽量分离主节点和数据节点，创建独立主节点的配置：
node.master: true
node.data: false
为了防止数据丢失，每个主节点应该知道有资格成为主节点的数量，默认为1，为避免网络分区时出现多主的情况，配置discovery.zen.minimum_master_nodes原则上最小值应该是：（master_eligible_nodes / 2）+ 1
### 2． 数据节点（Data node）
负责保存数据、执行数据相关操作：CRUD、搜索、聚合等。数据节点对CPU、内存、I/O要求较高。一般情况下（有一些例外，后续章节会给出），数据读写流程只和数据节点交互，不会和主节点打交道（异常情况除外）。
通过配置node.data: true（默认）来使一个节点成为数据节点，也可以通过下面的配置创建一个数据节点：
node.master: false
node.data: true
node.ingest: false
### 3.预处理节点（Ingest node）
这是从5.0版本开始引入的概念。预处理操作允许在索引文档之前，即写入数据之前，通过事先定义好的一系列的processors（处理器）和pipeline（管道），对数据进行某种转换、富化。processors和pipeline拦截bulk和index请求，在应用相关操作后将文档传回给index或bulk API。默认情况下，在所有的节点上启用ingest，如果想在某个节点上禁用ingest，则可以添加配置node.ingest: false，也可以通过下面的配置创建一个仅用于预处理的节点：
node.master: false
node.data: false
node.ingest: true
### 4． 协调节点（Coordinating node）
客户端请求可以发送到集群的任何节点，每个节点都知道任意文档所处的位置，然后转发这些请求，收集数据并返回给客户端，处理客户端请求的节点称为协调节点。协调节点将请求转发给保存数据的数据节点。每个数据节点在本地执行请求，并将结果返回协调节点。协调节点收集完数据后，将每个数据节点的结果合并为单个全局结果。对结果收集和排序的过程可能需要很多CPU和内存资源。通过下面的配置创建一个仅用于协调的节点：
node.master: false
node.data: false
node.ingest: false
### 5． 部落节点（Tribe node）
tribes（部落）功能允许部落节点在多个集群之间充当联合客户端。在ES 5.0之前还有一个客户端节点（Node Client）的角色，客户端节点有以下属性：
node.master: false
node.data: false
它不做主节点，也不做数据节点，仅用于路由请求，本质上是一个智能负载均衡器（从负载均衡器的定义来说，智能和非智能的区别在于是否知道访问的内容存在于哪个节点），从5.0版本开始，这个角色被协调节点（Coordinating only node）取代。

## 集群健康状态
从数据完整性的角度划分，集群健康状态分为三种：
· Green，所有的主分片和副分片都正常运行。
· Yellow，所有的主分片都正常运行，但不是所有的副分片都正常运行。这意味着存在单点故障风险。
· Red，有主分片没能正常运行。
每个索引也有上述三种状态，假设丢失了一个副分片，该分片所属的索引和整个集群变为Yellow状态，其他索引仍为Green。

## 集群状态
集群状态元数据是全局信息，元数据包括内容路由信息、配置信息等，其中最重要的是内容路由信息，它描述了“哪个分片位于哪个节点”这种信息。集群状态由主节点负责维护，如果主节点从数据节点接收更新，则将这些更新广播到集群的其他节点，让每个节点上的集群状态保持最新。ES 2.0版本之后，更新的集群状态信息只发增量内容，并且是被压缩的。

## 集群扩容
当扩容集群、添加节点时，分片会均衡地分配到集群的各个节点，从而对索引和搜索过程进行负载均衡，这些都是系统自动完成的。分片副本实现了数据冗余，从而防止硬件故障导致的数据丢失。下面演示了当集群只有一个节点，到变成两个节点、三个节点时的shard迁移过程示例（图片来自官网）。起初，在NODE1上有三个主分片，没有副分片，如下图所示。
![[Pasted image 20220305150156.png]]
其中，P代表Primary shard;R代表Replica shard。以后出现的内容使用相同的简称。添加第二个节点后，副分片被分配到NODE2，如下图所示。
![[Pasted image 20220305150213.png]]
添加第三个节点后，索引的六个分片被平均分配到集群的三个节点，如下图所示。
![[Pasted image 20220305150227.png]]
分片分配过程中除了让节点间均匀存储，还要保证不把主分片和副分片分配到同一节点，避免单个节点故障引起数据丢失。分布式系统中难免出现故障，当节点异常时，ES会自动处理节点异常。当主节点异常时，集群会重新选举主节点。当某个主分片异常时，会将副分片提升为主分片。


# 主要内部模块简介
在分析内部模块流程之前，我们先了解一下ES中几个基础模块的功能。
## Cluster
Cluster模块是主节点执行集群管理的封装实现，管理集群状态，维护集群层面的配置信息。主要功能如下：
· 管理集群状态，将新生成的集群状态发布到集群所有节点。
· 调用allocation模块执行分片分配，决策哪些分片应该分配到哪个节点
· 在集群各节点中直接迁移分片，保持数据平衡。
## allocation
封装了分片分配相关的功能和策略，包括主分片的分配和副分片的分配，本模块由主节点调用。创建新索引、集群完全重启都需要分片分配的过程。
## Discovery
发现模块负责发现集群中的节点，以及选举主节点。当节点加入或退出集群时，主节点会采取相应的行动。从某种角度来说，发现模块起到类似ZooKeeper的作用，选主并管理集群拓扑。

## gateway
负责对收到Master广播下来的集群状态（cluster state）数据的持久化存储，并在集群完全重启时恢复它们。
## Indices
索引模块管理全局级的索引设置，不包括索引级的（索引设置分为全局级和每个索引级）。它还封装了索引数据恢复功能。集群启动阶段需要的主分片恢复和副分片恢复就是在这个模块实现的。
## HTTP
HTTP模块允许通过JSON over HTTP的方式访问ES的API,HTTP模块本质上是完全异步的，这意味着没有阻塞线程等待响应。使用异步通信进行 HTTP 的好处是解决了 C10k 问题（10k量级的并发连接）。在部分场景下，可考虑使用HTTP keepalive以提升性能。注意：不要在客户端使用HTTP chunking。
## Transport
传输模块用于集群内节点之间的内部通信。从一个节点到另一个节点的每个请求都使用传输模块。如同HTTP模块，传输模块本质上也是完全异步的。传输模块使用 TCP 通信，每个节点都与其他节点维持若干 TCP长连接。内部节点间的所有通信都是本模块承载的。
## Engine
Engine模块封装了对Lucene的操作及translog的调用，它是对一个分片读写操作的最终提供者。ES使用Guice框架进行模块化管理。Guice是Google开发的轻量级依赖注入框架（IoC）。软件设计中经常说要依赖于抽象而不是具象，IoC 就是这种理念的实现方式，并且在内部实现了对象的创建和管理。


# ElasticSearch整体结构

> 通过上文，在通过图解了解了ES整体的原理后，我们梳理下ES的整体结构
![[Pasted image 20230404110810.png]]
-   一个 ES Index 在集群模式下，有多个 Node （节点）组成。每个节点就是 ES 的Instance (实例)。
-   每个节点上会有多个 shard （分片）， P1 P2 是主分片, R1 R2 是副本分片
-   每个分片上对应着就是一个 Lucene Index（底层索引文件）
-   Lucene Index 是一个统称
    -   由多个 Segment （段文件，就是倒排索引）组成。每个段文件存储着就是 Doc 文档。
    -   commit point记录了所有 segments 的信息

##   补充:Lucene索引结构

> 上图中Lucene的索引结构中有哪些文件呢？
![[Pasted image 20230404110825.png]]

文件的关系如下：
![[Pasted image 20230404110840.png]]
## 补充:Lucene处理流程

> 上文图解过程，还需要理解Lucene处理流程, 这将帮助你更好的索引文档和搜索文档。
![[Pasted image 20230404111437.png]]
创建索引的过程：

-   准备待索引的原文档，数据来源可能是文件、数据库或网络
-   对文档的内容进行分词组件处理，形成一系列的Term
-   索引组件对文档和Term处理，形成字典和倒排表

搜索索引的过程：

-   对查询语句进行分词处理，形成一系列Term
-   根据倒排索引表查找出包含Term的文档，并进行合并形成符合结果的文档集
-   比对查询语句与各个文档相关性得分，并按照得分高低返回

##   补充:ElasticSearch分析器

> 上图中很重要的一项是**语法分析/语言处理**, 所以我们还需要补充ElasticSearch分析器知识点。

分析 包含下面的过程：

-   首先，将一块文本分成适合于倒排索引的独立的 词条 ，
-   之后，将这些词条统一化为标准格式以提高它们的“可搜索性”，或者 recall

分析器执行上面的工作。 分析器 实际上是将三个功能封装到了一个包里：

-   **字符过滤器** 首先，字符串按顺序通过每个 字符过滤器 。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉HTML，或者将 & 转化成 and。
    
-   **分词器** 其次，字符串被 分词器 分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。
    
-   **Token 过滤器** 最后，词条按顺序通过每个 token 过滤器 。这个过程可能会改变词条（例如，小写化 Quick ），删除词条（例如， 像 a， and， the 等无用词），或者增加词条（例如，像 jump 和 leap 这种同义词）。
    

Elasticsearch提供了开箱即用的字符过滤器、分词器和token 过滤器。 这些可以组合起来形成自定义的分析器以用于不同的目的。

##  内置分析器

Elasticsearch还附带了可以直接使用的预包装的分析器。接下来我们会列出最重要的分析器。为了证明它们的差异，我们看看每个分析器会从下面的字符串得到哪些词条：

```
"Set the shape to semi-transparent by calling set_trans(5)"
```

-   **标准分析器**

标准分析器是Elasticsearch默认使用的分析器。它是分析各种语言文本最常用的选择。它根据 Unicode 联盟 定义的 **单词边界** 划分文本。删除绝大部分标点。最后，将词条小写。它会产生

```
set, the, shape, to, semi, transparent, by, calling, set_trans, 5
```

-   **简单分析器**

简单分析器在任何不是字母的地方分隔文本，将词条小写。它会产生

```
set, the, shape, to, semi, transparent, by, calling, set, trans
```

-   **空格分析器**

空格分析器在空格的地方划分文本。它会产生

```
Set, the, shape, to, semi-transparent, by, calling, set_trans(5)
```

-   **语言分析器**

特定语言分析器可用于 很多语言。它们可以考虑指定语言的特点。例如， 英语 分析器附带了一组英语无用词（常用单词，例如 and 或者 the ，它们对相关性没有多少影响），它们会被删除。 由于理解英语语法的规则，这个分词器可以提取英语单词的 词干 。

英语 分词器会产生下面的词条：

```
set, shape, semi, transpar, call, set_tran, 5
```

注意看 transparent、 calling 和 set_trans 已经变为词根格式。

##  什么时候使用分析器

当我们 索引 一个文档，它的全文域被分析成词条以用来创建倒排索引。 但是，当我们在全文域 搜索 的时候，我们需要将查询字符串通过 相同的分析过程 ，以保证我们搜索的词条格式与索引中的词条格式一致。

全文查询，理解每个域是如何定义的，因此它们可以做正确的事：

-   当你查询一个 全文 域时， 会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。
-   当你查询一个 精确值 域时，不会分析查询字符串，而是搜索你指定的精确值。


自定义词库就是加在分词器的某个文件上